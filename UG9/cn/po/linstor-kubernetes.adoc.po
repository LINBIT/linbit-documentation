# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"Report-Msgid-Bugs-To: documentation@linbit.com\n"
"POT-Creation-Date: 2023-10-31 19:39+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: Plain text
#: UG9/en/linstor-administration.adoc:2005 UG9/en/linstor-kubernetes.adoc:2711
msgid ""
"This ensures that LINSTOR will not place resources from a node that you are "
"evacuating onto another node that you plan on evacuating."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-administration.adoc:2031 UG9/en/linstor-kubernetes.adoc:2019
#, fuzzy, no-wrap
#| msgid "Creating a snapshot"
msgid "Creating a Snapshot"
msgstr "创建快照"

#. type: Title =====
#: UG9/en/linstor-administration.adoc:2057 UG9/en/linstor-kubernetes.adoc:2087
#, fuzzy, no-wrap
#| msgid "Restoring a snapshot"
msgid "Restoring a Snapshot"
msgstr "还原快照"

#. type: Title ==
#: UG9/en/linstor-kubernetes.adoc:2
#, no-wrap
msgid "LINSTOR Volumes in Kubernetes"
msgstr "Kubernetes的LINSTOR卷"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:7
#, fuzzy
#| msgid ""
#| "indexterm:[Kubernetes]This chapter describes the usage of LINSTOR in "
#| "Kubernetes as managed by the operator and with volumes provisioned using "
#| "the https://github.com/LINBIT/linstor-csi[LINSTOR CSI plugin]."
msgid ""
"indexterm:[Kubernetes]This chapter describes the usage of LINSTOR(R) in "
"Kubernetes (K8s)  as managed by the operator and with volumes provisioned "
"using the https://github.com/LINBIT/linstor-csi[LINSTOR CSI plugin]."
msgstr ""
"indexterm:[Kubernetes]本章描述了在Kubernetes中由操作员管理的LINSTOR的使用，以"
"及使用 https://github.com/LINBIT/linstor-csi[LINSTOR CSI plugin] 配置卷的情"
"况。"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:11
msgid ""
"This chapter goes into great detail regarding all the install time options "
"and various configurations possible with LINSTOR and Kubernetes. The chapter "
"begins with some explanatory remarks and then moves onto deployment "
"instructions. After that, there are instructions for getting started with "
"LINSTOR to configure storage within a Kubernetes deployment. Following that, "
"more advanced topics and configurations, such as snapshots and monitoring, "
"are covered."
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:13
#, fuzzy, no-wrap
#| msgid "Kubernetes Overview"
msgid "Kubernetes Introduction"
msgstr "Kubernetes 概述"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:19
#, fuzzy
#| msgid ""
#| "_Kubernetes_ is a container orchestrator. Kubernetes defines the behavior "
#| "of containers and related services via declarative specifications. In "
#| "this guide, we'll focus on on using `kubectl` to manipulate `.yaml` files "
#| "that define the specifications of Kubernetes objects."
msgid ""
"_Kubernetes_ is a container orchestrator. Kubernetes defines the behavior of "
"containers and related services, using declarative specifications. In this "
"guide, we will focus on using `kubectl` to manipulate YAML files that define "
"the specifications of Kubernetes objects."
msgstr ""
"_Kubernetes_ 是一个容器编排系统。Kubernetes通过声明性规范定义容器和相关服务的"
"行为。在本指南中，我们将重点介绍如何使用 `kubectl` 来操作定义Kubernetes对象规"
"范的 `.yaml` 文件。"

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:21
#, no-wrap
msgid "Deploying LINSTOR on Kubernetes"
msgstr "在Kubernetes上部署LINSTOR"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:26
#, fuzzy
#| msgid ""
#| "LINBIT provides a LINSTOR operator to commercial support customers.  The "
#| "operator eases deployment of LINSTOR on Kubernetes by installing DRBD, "
#| "managing Satellite and Controller pods, and other related functions."
msgid ""
"LINBIT(R) provides a LINSTOR Operator to commercial support customers.  The "
"Operator eases deployment of LINSTOR on Kubernetes by installing DRBD(R), "
"managing satellite and controller pods, and other related functions."
msgstr ""
"LINBIT为商业支持客户提供LINSTOR Operator。Operator通过安装DRBD、管理"
"Satellite/Controller Pods以及其他相关功能，简化了LINSTOR在Kubernetes上的部"
"署。"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:33
msgid ""
"LINBIT's container image repository (https://drbd.io), used by LINSTOR "
"Operator, is only available to LINBIT customers or through LINBIT customer "
"trial accounts.  link:https://linbit.com/contact-us/[Contact LINBIT for "
"information on pricing or to begin a trial]. Alternatively, you can use the "
"LINSTOR SDS upstream project named link:https://github.com/piraeusdatastore/"
"piraeus-operator[Piraeus], without being a LINBIT customer."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:37
msgid ""
"LINSTOR Operator v2 is the recommended way of deploying LINBIT SDS for "
"Kubernetes on new clusters.  Users of existing Operator v1 deployments "
"should continue to use their Helm deployments and skip to the, <<s-"
"kubernetes-deploy-linstor-operator-v1,Operator v1 deployment instructions>>."
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:39
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Deploying LINSTOR Operator v2"
msgstr "使用LINSTOR Operator部署"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:44
msgid ""
"LINSTOR Operator v2 is deployed using link:https://kubernetes.io/docs/tasks/"
"manage-kubernetes-objects/kustomization[the Kustomize tool], integrated with "
"`kubectl`."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:47
#, fuzzy, no-wrap
#| msgid "Creating the configuration file"
msgid "Creating the Operator"
msgstr "创建配置文件"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:53
msgid ""
"To deploy the Operator, create a `kustomization.yaml` file. This will "
"declare your pull secret for `drbd.io` and allow you to pull in the Operator "
"deployment. The Operator will be deployed in a new namespace `linbit-sds`.  "
"Make sure to replace `MY_LINBIT_USER` and `MY_LINBIT_PASSWORD` with your own "
"credentials. You can find the latest releases on link:https://charts.linstor."
"io/[charts.linstor.io]."
msgstr ""

#. type: Block title
#: UG9/en/linstor-kubernetes.adoc:54
#: UG9/en/linstor-kubernetes-upgrade-guide.adoc:19
#: UG9/en/linstor-openshift.adoc:42
#, no-wrap
msgid "kustomization.yaml"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:69
#, no-wrap
msgid ""
"apiVersion: kustomize.config.k8s.io/v1beta1\n"
"kind: Kustomization\n"
"namespace: linbit-sds\n"
"resources:\n"
"  - https://charts.linstor.io/static/v2.2.0.yaml # <1>\n"
"generatorOptions:\n"
"  disableNameSuffixHash: true\n"
"secretGenerator:\n"
"  - name: drbdio-pull-secret\n"
"    type: kubernetes.io/dockerconfigjson\n"
"    literals:\n"
"      - .dockerconfigjson={\"auths\":{\"drbd.io\":{\"username\":\"MY_LINBIT_USER\",\"password\":\"MY_LINBIT_PASSWORD\"}}} # <2>\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:71
msgid ""
"Replace with the latest release manifest from link:https://charts.linstor.io/"
"[charts.linstor.io]."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:72
msgid ""
"Replace `MY_LINBIT_USER` and `MY_LINBIT_PASSWORD` with your link:https://my."
"linbit.com/[my.linbit.com] credentials."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:74
msgid ""
"Then, apply the `kustomization.yaml` file, by using `kubectl` command, and "
"wait for the Operator to start:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:81
#, no-wrap
msgid ""
"$ kubectl apply -k .\n"
"namespace/linbit-sds created\n"
"...\n"
"$ kubectl -n linbit-sds  wait pod --for=condition=Ready --all\n"
"pod/linstor-operator-controller-manager-6d9847d857-zc985 condition met\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:84
msgid "The Operator is now ready to deploy LINBIT SDS for Kubernetes."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:86
#, fuzzy, no-wrap
#| msgid "Deploying LINSTOR on Kubernetes"
msgid "Deploying LINBIT SDS for Kubernetes"
msgstr "在Kubernetes上部署LINSTOR"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:90
msgid ""
"Deploying LINBIT SDS for Kubernetes with the Operator is as simple as "
"creating a new `LinstorCluster` resource and waiting for the Operator to "
"complete the setup:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:106
#, no-wrap
msgid ""
"$ kubectl create -f - <<EOF\n"
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec: {}\n"
"EOF\n"
"$ kubectl wait pod --for=condition=Ready -n linbit-sds --timeout=3m --all\n"
"pod/ha-controller-4tgcg condition met\n"
"pod/k8s-1-26-10.test condition met\n"
"pod/linstor-controller-76459dc6b6-tst8p condition met\n"
"pod/linstor-csi-controller-75dfdc967d-dwdx6 condition met\n"
"pod/linstor-csi-node-9gcwj condition met\n"
"pod/linstor-operator-controller-manager-6d9847d857-zc985 condition met\n"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:109
#, fuzzy, no-wrap
#| msgid "Configuring quorum"
msgid "Configuring Storage"
msgstr "配置仲裁"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:113
msgid ""
"By default, LINBIT SDS for Kubernetes does not configure any storage. To add "
"storage, you can configure a `LinstorSatelliteConfiguration`, which the "
"Operator uses to configure one or more satellites."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:115
msgid ""
"The following example creates a simple `FILE_THIN` pool and it does not "
"require any additional set up on the host:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:128
#, no-wrap
msgid ""
"$ kubectl apply -f - <<EOF\n"
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: storage-pool\n"
"spec:\n"
"  storagePools:\n"
"    - name: pool1\n"
"      fileThinPool:\n"
"        directory: /var/lib/linbit-sds/pool1\n"
"EOF\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:132
msgid ""
"Other types of storage pools can be configured as well. Refer to link:"
"https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/reference/"
"linstorsatelliteconfiguration.md#specstoragepools[the examples upstream]."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:134
#, fuzzy, no-wrap
#| msgid "Terminating Helm deployment"
msgid "Securing Operator v2 Deployment"
msgstr "终止Helm部署"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:137
msgid ""
"By configuring key and certificate based encryption, you can make "
"communication between certain LINSTOR components, for example, between "
"LINSTOR satellite nodes and a LINSTOR controller node, or between the "
"LINSTOR client and the LINSTOR API, more secure."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:139
#, fuzzy, no-wrap
#| msgid "Configuring the Nodes"
msgid "Configuring TLS Between the LINSTOR Controller and Satellite"
msgstr "配置节点"

#.  https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/how-to/api-tls.md#how-to-configure-tls-for-the-linstor-api
#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:144
msgid ""
"To secure traffic between the LINSTOR controller and satellite nodes, you "
"can configure TLS, either by using link:https://cert-manager.io/[cert-"
"manager] or link:https://www.openssl.org/[OpenSSL] to create TLS "
"certificates to encrypt the traffic."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:147
msgid "====== Provisioning Keys and Certificates By Using cert-manager"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:149
msgid ""
"This method requires a working cert-manager deployment in your cluster. For "
"an alternative way to provision keys and certificates, see the <<s-"
"kubernetes-provision-tls-using-openssl-v2,OpenSSL>> section below."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:151
msgid ""
"The LINSTOR controller and satellite only need to trust each other. For that "
"reason, you should only have a certificate authority (CA) for those "
"components. Apply the following YAML configuration to your deployment to "
"create a new cert-manager link:https://cert-manager.io/docs/concepts/issuer/"
"[Issuer] resource:"
msgstr ""

#. type: Block title
#: UG9/en/linstor-kubernetes.adoc:152
#, fuzzy, no-wrap
#| msgid "linstor-basic-sc.yaml"
msgid "linstor-cert-manager.yaml"
msgstr "linstor-basic-sc.yaml"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:155 UG9/en/linstor-kubernetes.adoc:197
#: UG9/en/linstor-kubernetes.adoc:270 UG9/en/linstor-kubernetes.adoc:349
#: UG9/en/linstor-kubernetes.adoc:389 UG9/en/linstor-kubernetes.adoc:544
#: UG9/en/linstor-kubernetes.adoc:2143 UG9/en/linstor-kubernetes.adoc:2202
#, no-wrap
msgid "---\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:163 UG9/en/linstor-kubernetes.adoc:357
#, no-wrap
msgid ""
"apiVersion: cert-manager.io/v1\n"
"kind: Issuer\n"
"metadata:\n"
"  name: ca-bootstrapper\n"
"  namespace: linbit-sds\n"
"spec:\n"
"  selfSigned: { }\n"
"---\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:181
#, no-wrap
msgid ""
"apiVersion: cert-manager.io/v1\n"
"kind: Certificate\n"
"metadata:\n"
"  name: linstor-internal-ca\n"
"  namespace: linbit-sds\n"
"spec:\n"
"  commonName: linstor-internal-ca\n"
"  secretName: linstor-internal-ca\n"
"  duration: 87600h # 10 years\n"
"  isCA: true\n"
"  usages:\n"
"    - signing\n"
"    - key encipherment\n"
"    - cert sign\n"
"  issuerRef:\n"
"    name: ca-bootstrapper\n"
"    kind: Issuer\n"
"---\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:190
#, no-wrap
msgid ""
"apiVersion: cert-manager.io/v1\n"
"kind: Issuer\n"
"metadata:\n"
"  name: linstor-internal-ca\n"
"  namespace: linbit-sds\n"
"spec:\n"
"  ca:\n"
"    secretName: linstor-internal-ca\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:193
msgid ""
"Next, configure the new issuer resource to let the LINSTOR Operator "
"provision the certificates needed to encrypt the controller and satellite "
"traffic, by applying the following YAML configuration:"
msgstr ""

#. type: Block title
#: UG9/en/linstor-kubernetes.adoc:194
#, fuzzy, no-wrap
#| msgid "linstor-basic-sc.yaml"
msgid "linstor-ca-issuer.yaml"
msgstr "linstor-basic-sc.yaml"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:207
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  internalTLS:\n"
"    certManager:\n"
"      name: linstor-internal-ca\n"
"      kind: Issuer\n"
"---\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:217
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: internal-tls\n"
"spec:\n"
"  internalTLS:\n"
"    certManager:\n"
"      name: linstor-internal-ca\n"
"      kind: Issuer\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:220
msgid ""
"After applying the configurations above to your deployment, you can <<s-"
"kubernetes-tls-configuration-verifying-v2,verify that TLS traffic encryption "
"is working>>."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:223
msgid "====== Provisioning Keys and Certificates By Using OpenSSL"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:225
msgid ""
"If you completed the <<s-kubernetes-provision-tls-using-cert-manager-v2, "
"Provisioning Keys and Certificates By Using cert-manager>> section above, "
"you can skip this section and go to the <<s-kubernetes-tls-configuration-"
"verifying-v2, Verifying TLS Configuration>> section."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:227
msgid "This method requires the `openssl` program on the command line."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:229
msgid ""
"First, create a new CA by using a new key and a self-signed certificate. You "
"can change options such as the encryption algorithm and expiry time to suit "
"the requirements of your deployment."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:234
#, no-wrap
msgid ""
"# openssl req -new -newkey rsa:4096 -days 3650 -nodes -x509 \\\n"
"-subj \"/CN=linstor-internal-ca\" \\\n"
"-keyout ca.key -out ca.crt\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:237
msgid ""
"Next, create two new keys, one for the LINSTOR controller, one for all "
"satellites:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:241
#, no-wrap
msgid ""
"# openssl genrsa -out controller.key 4096\n"
"# openssl genrsa -out satellite.key 4096\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:244
msgid ""
"Next, create a certificate for each key, valid for 10 years, signed by the "
"CA that you created earlier:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:252
#, no-wrap
msgid ""
"# openssl req -new -sha256 -key controller.key -subj \"/CN=linstor-controller\" -out controller.csr\n"
"# openssl req -new -sha256 -key satellite.key -subj \"/CN=linstor-satellite\" -out satellite.csr\n"
"# openssl x509 -req -in controller.csr -CA ca.crt -CAkey ca.key \\\n"
"-CAcreateserial -out controller.crt -days 3650 -sha256\n"
"# openssl x509 -req -in satellite.csr -CA ca.crt -CAkey ca.key \\\n"
"-CAcreateserial -out satellite.crt -days 3650 -sha256\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:255
msgid "Next, create Kubernetes secrets from the created keys and certificates:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:263
#, no-wrap
msgid ""
"# kubectl create secret generic linstor-controller-internal-tls -n linbit-sds \\\n"
"--type=kubernetes.io/tls --from-file=ca.crt=ca.crt --from-file=tls.crt=controller.crt \\\n"
"--from-file=tls.key=controller.key\n"
"# kubectl create secret generic linstor-satellite-internal-tls -n linbit-sds \\\n"
"--type=kubernetes.io/tls --from-file=ca.crt=ca.crt --from-file=tls.crt=satellite.crt \\\n"
"--from-file=tls.key=satellite.key\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:266
msgid ""
"Finally, configure the Operator resources to reference the newly created "
"secrets, by applying the following YAML configuration to your deployment:"
msgstr ""

#. type: Block title
#: UG9/en/linstor-kubernetes.adoc:267
#, fuzzy, no-wrap
#| msgid "linstor-basic-sc.yaml"
msgid "linstor-internal-tls-secret.yaml"
msgstr "linstor-basic-sc.yaml"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:278
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  internalTLS:\n"
"    secretName: linstor-controller-internal-tls\n"
"---\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:286
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: internal-tls\n"
"spec:\n"
"  internalTLS:\n"
"    secretName: linstor-satellite-internal-tls\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:290
msgid "====== Verifying TLS Configuration"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:292
msgid ""
"After configuring LINSTOR controller and satellite traffic encryption, you "
"can next verify the secure TLS connection between the LINSTOR controller and "
"a satellite by examining the output of a `kubectl linstor node list` "
"command. If TLS is enabled, the output will show `(SSL)` next to an active "
"satellite address."
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:302
#, no-wrap
msgid ""
"# kubectl linstor node list\n"
"+---------------------------------------------------------------------+\n"
"| Node               | NodeType  | Addresses                 | State  |\n"
"| node01.example.com | SATELLITE | 10.116.72.142:3367 (SSL)  | Online |\n"
"| node02.example.com | SATELLITE | 10.127.183.140:3367 (SSL) | Online |\n"
"| node03.example.com | SATELLITE | 10.125.97.50:3367 (SSL)   | Online |\n"
"+---------------------------------------------------------------------+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:310
#, no-wrap
msgid ""
"NOTE: The above command relies on the `kubectl-linstor` command to simplify entering LINSTOR client commands in Kubernetes. You can install the tool by following the instructions in <<s-kubernetes-kubectl-linstor-utility,Simplifying LINSTOR Client Command Entry>>.\n"
"\n"
"If the output shows `(PLAIN)` rather than `(SSL)`, this indicates that the TLS configuration was not applied successfully. Check the status of the `LinstorCluster` and `LinstorSatellite` resources.\n"
"\n"
"If the output shows `(SSL)`, but the node remains offline, this usually indicates that a certificate is not trusted by the other party. Verify that the controller's `tls.crt` is trusted by the satellite's `ca.crt` and vice versa. The following shell function provides a quick way to verify that one TLS certificate is trusted by another:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:321
#, no-wrap
msgid ""
"function k8s_secret_trusted_by() {\n"
"\tkubectl get secret -n linbit-sds \\\n"
"    -ogo-template='{{ index .data \"tls.crt\" | base64decode }}' \\\n"
"    \"$1\" > $1.tls.crt\n"
"\tkubectl get secret -n linbit-sds \\\n"
"    -ogo-template='{{ index .data \"ca.crt\" | base64decode }}' \\\n"
"    \"$2\" > $2.ca.crt\n"
"\topenssl verify -CAfile $2.ca.crt $1.tls.crt\n"
"}\n"
"# k8s_secret_trusted_by satellite-tls controller-tls\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:325 UG9/en/linstor-kubernetes.adoc:517
#, no-wrap
msgid ""
"If TLS encryption was properly configured, output from running the above function should be:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:327 UG9/en/linstor-kubernetes.adoc:519
#, no-wrap
msgid ""
"satellite-tls.tls.crt: OK\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:331
msgid ""
"The upstream Piraeus project's reference documentation shows all available "
"link:https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/"
"reference/linstorcluster.md#specinternaltls[`LinstorCluster`] and link:"
"https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/reference/"
"linstorsatelliteconfiguration."
"md#specinternaltls[`LinstorSatelliteConfiguration`] resources options "
"related to TLS."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:331
#, fuzzy, no-wrap
#| msgid "Configuration using LINSTOR"
msgid "Configuring TLS for the LINSTOR API"
msgstr "使用LINSTOR配置"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:348
#, no-wrap
msgid ""
"// https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/how-to/internal-tls.md\n"
"\n"
"This section describes how to set up TLS for the LINSTOR API. The API, served by the LINSTOR controller, is used by clients such as the CSI Driver and the Operator itself to control the LINSTOR cluster.\n"
"\n"
"To follow the instructions in this section, you should be familiar with:\n"
"\n"
"    - Editing `LinstorCluster` resources\n"
"    - Using either link:https://cert-manager.io/[cert-manager] or OpenSSL to create TLS certificates\n"
"\n"
"[[s-kubernetes-securing-linstor-api-provisioning-keys-cert-manager-v2]]\n"
"====== Provisioning Keys and Certificates By Using cert-manager\n"
"\n"
"This method requires a working link:https://cert-manager.io/[cert-manager] deployment in your cluster. For an alternative way to provision keys and certificates, see the <<s-kubernetes-securing-linstor-api-provisioning-keys-openssl-v2,OpenSSL>> section below.\n"
"\n"
"When using TLS, the LINSTOR API uses client certificates for authentication. It is good practice to have a separate CA just for these certificates. To do this, first apply the following YAML configuration to your deployment to create a certificate issuer.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:375
#, no-wrap
msgid ""
"apiVersion: cert-manager.io/v1\n"
"kind: Certificate\n"
"metadata:\n"
"  name: linstor-api-ca\n"
"  namespace: linbit-sds\n"
"spec:\n"
"  commonName: linstor-api-ca\n"
"  secretName: linstor-api-ca\n"
"  duration: 87600h # 10 years\n"
"  isCA: true\n"
"  usages:\n"
"    - signing\n"
"    - key encipherment\n"
"    - cert sign\n"
"  issuerRef:\n"
"    name: ca-bootstrapper\n"
"    kind: Issuer\n"
"---\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:384
#, no-wrap
msgid ""
"apiVersion: cert-manager.io/v1\n"
"kind: Issuer\n"
"metadata:\n"
"  name: linstor-api-ca\n"
"  namespace: linbit-sds\n"
"spec:\n"
"  ca:\n"
"    secretName: linstor-api-ca\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:388
#, no-wrap
msgid ""
"Next, configure this issuer to let the Operator provision the needed certificates, by applying the following configuration.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:399
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  apiTLS:\n"
"    certManager:\n"
"      name: linstor-api-ca\n"
"      kind: Issuer\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:410
#, no-wrap
msgid ""
"This completes the necessary steps for securing the LINSTOR API with TLS by using cert-manager. Skip to the <<s-kubernetes-securing-linstor-api-verifying-tls-configuration-v2,Verifying LINSTOR API TLS Configuration>> section to verify that TLS is working.\n"
"\n"
"[[s-kubernetes-securing-linstor-api-provisioning-keys-openssl-v2]]\n"
"====== Provisioning Keys and Certificates By Using OpenSSL\n"
"\n"
"This method requires the `openssl` program on the command line. For an alternative way to provision keys and certificates, see the <<s-kubernetes-securing-linstor-api-provisioning-keys-cert-manager-v2,cert-manager>> section above.\n"
"\n"
"First, create a new certificate authority (CA) by using a new key and a self-signed certificate. You can change options such as the encryption algorithm and expiry time to suit the requirements of your deployment.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:414
#, no-wrap
msgid ""
"# openssl req -new -newkey rsa:4096 -days 3650 -nodes -x509 \\\n"
"-subj \"/CN=linstor-api-ca\" \\\n"
"-keyout ca.key -out ca.crt\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:418
#, no-wrap
msgid ""
"Next, create two new keys, one for the LINSTOR API server, and one for all LINSTOR API clients:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:421
#, no-wrap
msgid ""
"# openssl genrsa -out api-server.key 4096\n"
"# openssl genrsa -out api-client.key 4096\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:425
#, no-wrap
msgid ""
"Next, create a certificate for the server. Because the clients might use different shortened service names, you need to specify multiple subject names:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:442
#, no-wrap
msgid ""
"# cat /etc/ssl/openssl.cnf > api-csr.cnf\n"
"# cat >> api-csr.cnf <<EOF\n"
"[ v3_req ]\n"
"subjectAltName = @alt_names\n"
"[ alt_names ]\n"
"DNS.0 = linstor-controller.linbit-sds.svc.cluster.local\n"
"DNS.1 = linstor-controller.linbit-sds.svc\n"
"DNS.2 = linstor-controller\n"
"EOF\n"
"# openssl req -new -sha256 -key api-server.key \\\n"
"-subj \"/CN=linstor-controller\" -config api-csr.cnf \\\n"
"-extensions v3_req -out api-server.csr\n"
"# openssl x509 -req -in api-server.csr -CA ca.crt -CAkey ca.key \\\n"
"-CAcreateserial -config api-csr.cnf \\\n"
"-extensions v3_req -out api-server.crt \\\n"
"-days 3650 -sha256\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:446
#, no-wrap
msgid ""
"For the client certificate, setting one subject name is enough.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:453
#, no-wrap
msgid ""
"# openssl req -new -sha256 -key api-client.key \\\n"
"-subj \"/CN=linstor-client\" -out api-client.csr\n"
"# openssl x509 -req -in api-client.csr \\\n"
"-CA ca.crt -CAkey ca.key -CAcreateserial \\\n"
"-out api-client.crt \\\n"
"-days 3650 -sha256\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:457
#, no-wrap
msgid ""
"Next, create Kubernetes secrets from the created keys and certificates.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:464
#, no-wrap
msgid ""
"# kubectl create secret generic linstor-api-tls -n linbit-sds \\\n"
"--type=kubernetes.io/tls --from-file=ca.crt=ca.crt --from-file=tls.crt=api-server.crt \\\n"
"--from-file=tls.key=api-server.key\n"
"# kubectl create secret generic linstor-client-tls -n linbit-sds \\\n"
"--type=kubernetes.io/tls --from-file=ca.crt=ca.crt --from-file=tls.crt=api-client.crt \\\n"
"--from-file=tls.key=api-client.key\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:468
#, no-wrap
msgid ""
"Finally, configure the Operator resources to reference the newly created secrets. For simplicity, you can configure the same client secret for all components.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:479
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  apiTLS:\n"
"    apiSecretName: linstor-api-tls\n"
"    clientSecretName: linstor-client-tls\n"
"    csiControllerSecretName: linstor-client-tls\n"
"    csiNodeSecretName: linstor-client-tls\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:486
#, no-wrap
msgid ""
"[[s-kubernetes-securing-linstor-api-verifying-tls-configuration-v2]]\n"
"====== Verifying LINSTOR API TLS Configuration\n"
"\n"
"You can verify that the API is running, secured by TLS, by manually connecting to the HTTPS endpoint using a `curl` command.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:492
#, no-wrap
msgid ""
"# kubectl exec -n linbit-sds deploy/linstor-controller -- \\\n"
"curl --key /etc/linstor/client/tls.key \\\n"
"--cert /etc/linstor/client/tls.crt \\\n"
"--cacert /etc/linstor/client/ca.crt \\\n"
"https://linstor-controller.linbit-sds.svc:3371/v1/controller/version\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:496
#, no-wrap
msgid ""
"If the command is successful, the API is using HTTPS, clients are able to connect to the controller with their certificates, and the command output should show something similar to this:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:498
#, no-wrap
msgid ""
"{\"version\":\"1.20.2\",\"git_hash\":\"58a983a5c2f49eb8d22c89b277272e6c4299457a\",\"build_time\":\"2022-12-14T14:21:28+00:00\",\"rest_api_version\":\"1.16.0\"}%\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:502
#, no-wrap
msgid ""
"If the command output shows an error, verify that the client certificates are trusted by the API secret, and vice versa. The following shell function provides a quick way to verify that one TLS certificate is trusted by another:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:513
#, no-wrap
msgid ""
"function k8s_secret_trusted_by() {\n"
"    kubectl get secret -n linbit-sds \\\n"
"    -ogo-template='{{ index .data \"tls.crt\" | base64decode }}' \\\n"
"    \"$1\" > $1.tls.crt\n"
"    kubectl get secret -n linbit-sds \\\n"
"    -ogo-template='{{ index .data \"ca.crt\" | base64decode }}' \\\n"
"    \"$2\" > $2.ca.crt\n"
"    openssl verify -CAfile $2.ca.crt $1.tls.crt\n"
"}\n"
"# k8s_secret_trusted_by satellite-tls controller-tls\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:524
#, no-wrap
msgid ""
"Another issue might be the API endpoint using a certificate that is not using the expected service name. A typical error message for this issue would be:\n"
"\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:526
#, no-wrap
msgid ""
"curl: (60) SSL: no alternative certificate subject name matches target host name 'linstor-controller.piraeus-datastore.svc'\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:532
msgid ""
"In this case, make sure you have specified the right subject names when "
"provisioning the certificates.  All available options are documented in the "
"upstream Piraeus project's reference documentation for link:https://github."
"com/piraeusdatastore/piraeus-operator/blob/v2/docs/reference/linstorcluster."
"md#specapitls[`LinstorCluster`]."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:532
#, fuzzy, no-wrap
#| msgid "Create a new backend type for LINSTOR"
msgid "Creating a Passphrase For LINSTOR"
msgstr "为LINSTOR创建新的后端类型"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:543
#, no-wrap
msgid ""
"// https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/reference/linstorcluster.md#speclinstorpassphrasesecret\n"
"\n"
"LINSTOR can use a passphrase for operations such as <<s-linstor-encrypted-volumes,encrypting volumes>> and storing access credentials for backups.\n"
"\n"
"To configure a LINSTOR passphrase in a Kubernetes deployment, the referenced secret must exist in the same namespace as the operator (by default `linbit-sds`), and have a `MASTER_PASSPHRASE` entry.\n"
"\n"
"The following example YAML configuration for the `.spec.linstorPassphraseSecret` configures a passphrase `example-passphrase`.\n"
"\n"
"IMPORTANT: Choose a different passphrase for your deployment.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:554
#, no-wrap
msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: linstor-passphrase\n"
"  namespace: linbit-sds\n"
"data:\n"
"  # CHANGE THIS TO USE YOUR OWN PASSPHRASE!\n"
"  # Created by: echo -n \"example-passphrase\" | base64\n"
"  MASTER_PASSPHRASE: ZXhhbXBsZS1wYXNzcGhyYXNl\n"
"---\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:561
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  linstorPassphraseSecret: linstor-passphrase\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:564
msgid "[[s-kubernetes-using-crds-v2]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:564
#, no-wrap
msgid "Using CustomResourceDefinitions in Operator v2 Deployments"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:577
msgid ""
"Within LINSTOR Operator v2 deployments, you can change the cluster state by "
"modifying LINSTOR related Kubernetes `CustomResourceDefinitions` (CRDs) or "
"check the status of a resource. An overview list of these resources follows. "
"Refer to the upstream Piraeus project's API reference (linked for each "
"resource below) for more details.  link:https://github.com/piraeusdatastore/"
"piraeus-operator/blob/v2/docs/reference/linstorcluster."
"md[`LinstorCluster`]:: This resource controls the state of the LINSTOR "
"cluster and integration with Kubernetes.  link:https://github.com/"
"piraeusdatastore/piraeus-operator/blob/v2/docs/reference/"
"linstorsatelliteconfiguration.md[`LinstorSatelliteConfiguration`]:: This "
"resource controls the state of the LINSTOR satellites, optionally applying "
"it to only a subset of nodes.  link:https://github.com/piraeusdatastore/"
"piraeus-operator/blob/v2/docs/reference/linstorsatellite."
"md[`LinstorSatellite`]:: This resource controls the state of a single "
"LINSTOR satellite. This resource is not intended to be changed directly, "
"rather it is created by the LINSTOR Operator by merging all matching "
"`LinstorSatelliteConfiguration` resources.  link:https://github.com/"
"piraeusdatastore/piraeus-operator/blob/v2/docs/reference/"
"linstornodeconnection.md[`LinstorNodeConnection`]:: This resource controls "
"the state of the LINSTOR node connections.  [[s-kubernetes-next-steps-after-"
"deploying-operator-v2]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:577
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Next Steps After Deploying LINSTOR Operator v2"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:584
msgid ""
"After deploying LINBIT SDS for Kubernetes, you can continue with the <<s-"
"kubernetes-basic-configuration-and-deployment>>, <<s-kubernetes-drbd-module-"
"loader-configuring-v2>>, <<s-kubernetes-drbd-replication-via-host-network-"
"v2>> sections in this chapter, or refer to the available link:https://github."
"com/piraeusdatastore/piraeus-operator/tree/v2/docs/tutorial[tutorials] in "
"the upstream Piraeus project.  [[s-kubernetes-deploy-linstor-operator-v1]]"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:584
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Deploying LINSTOR Operator v1"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:593
#, no-wrap
msgid ""
"IMPORTANT: If you plan to deploy LINSTOR Operator on a new cluster, you should use\n"
"<<s-kubernetes-deploy-linstor-operator-v2, Operator v2>>. If you have already deployed the LINSTOR Operator v2, you can skip this section and proceed to other topics in the chapter, beginning with <<s-kubernetes-deploy-external-controller>>.\n"
"\n"
"The Operator v1 is installed using a Helm v3 chart as follows:\n"
"\n"
"* Create a Kubernetes secret containing your my.linbit.com credentials:\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:596
#, fuzzy, no-wrap
#| msgid "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
msgid ""
"kubectl create secret docker-registry drbdiocred --docker-server=drbd.io \\\n"
"  --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
"----\n"
msgstr "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:618
#, no-wrap
msgid ""
"+\n"
"The name of this secret must match the one specified in the Helm values,\n"
"by default `drbdiocred`.\n"
"\n"
"* Configure the LINSTOR database back end. By default, the chart configures etcd as database\n"
"back end. The Operator can also configure LINSTOR to use\n"
"<<s-kubernetes-linstor-k8s-backend,Kubernetes as datastore>> directly. If you go the etcd\n"
"route, you should configure persistent storage for it:\n"
"** Use an existing storage provisioner with a default `StorageClass`.\n"
"** <<s-kubernetes-etcd-hostpath-persistence,Use `hostPath` volumes>>.\n"
"** Disable persistence, **for basic testing only**. This can be done by adding\n"
"   `--set etcd.persistentVolume.enabled=false` to the `helm install` command below.\n"
"\n"
"* Read <<s-kubernetes-storage, the storage guide>> and configure a basic storage setup for LINSTOR\n"
"\n"
"* Read the <<s-kubernetes-securing-deployment-v1,section on securing the deployment>> and configure as needed.\n"
"\n"
"* Select the appropriate kernel module injector using `--set` with the `helm install` command in the final step.\n"
"\n"
"** Choose the injector according to the distribution you are using. Select the latest version from one of `drbd9-rhel7`, `drbd9-rhel8`,...  from http://drbd.io/ as appropriate. The drbd9-rhel8 image should also be used for RHCOS (OpenShift). For the SUSE CaaS Platform use the SLES injector that matches the base system of the CaaS Platform you are using (e.g., `drbd9-sles15sp1`). For example:\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:620
#, fuzzy, no-wrap
#| msgid "operator.nodeSet.spec.kernelModImage=drbd.io/drbd9-rhel7\n"
msgid ""
"operator.satelliteSet.kernelModuleInjectionImage=drbd.io/drbd9-rhel8:v9.1.8\n"
"----\n"
msgstr "operator.nodeSet.spec.kernelModImage=drbd.io/drbd9-rhel7\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:624
#, no-wrap
msgid ""
"** Only inject modules that are already present on the host machine. If a module is not found, it will be skipped.\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:626
#, fuzzy, no-wrap
#| msgid "operator.nodeSet.spec.drbdKernelModuleInjectionMode=None\n"
msgid ""
"operator.satelliteSet.kernelModuleInjectionMode=DepsOnly\n"
"----\n"
msgstr "operator.nodeSet.spec.drbdKernelModuleInjectionMode=None\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:630
#, fuzzy, no-wrap
#| msgid "Disable kernel module injection if you are installing DRBD by other means."
msgid ""
"** Disable kernel module injection if you are installing DRBD by other means. Deprecated by `DepsOnly`\n"
"+\n"
"----\n"
msgstr "如果通过其他方式安装DRBD，请禁用内核模块注入。"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:632
#, fuzzy, no-wrap
#| msgid "operator.nodeSet.spec.drbdKernelModuleInjectionMode=None\n"
msgid ""
"operator.satelliteSet.kernelModuleInjectionMode=None\n"
"----\n"
msgstr "operator.nodeSet.spec.drbdKernelModuleInjectionMode=None\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:636
#, fuzzy, no-wrap
#| msgid "Finally create a Helm deployment named `linstor-op` that will set up everything."
msgid ""
"* Finally create a Helm deployment named `linstor-op` that will set up everything.\n"
"+\n"
"----\n"
msgstr "最后创建一个名为 `linstor-op` 的Helm部署，它将设置所有内容。"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:639
#, fuzzy, no-wrap
#| msgid ""
#| "helm repo add linstor https://charts.linstor.io\n"
#| "helm install linstor-op linstor/linstor\n"
msgid ""
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-op linstor/linstor\n"
"----\n"
msgstr ""
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-op linstor/linstor\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:643
msgid ""
"Further deployment customization is discussed in the <<s-kubernetes-advanced-"
"deployments,advanced deployment section>> [[s-kubernetes-linstor-k8s-"
"backend]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:643
#, fuzzy, no-wrap
#| msgid "Create a new backend type for LINSTOR"
msgid "Kubernetes Back End for LINSTOR"
msgstr "为LINSTOR创建新的后端类型"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:650
#, no-wrap
msgid ""
"The LINSTOR controller can use the Kubernetes API directly to persist its cluster state. To enable\n"
"this back end, use the following override file during the chart installation:\n"
"\n"
".k8s-backend.yaml\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:656
#, no-wrap
msgid ""
"etcd:\n"
"  enabled: false\n"
"operator:\n"
"  controller:\n"
"    dbConnectionURL: k8s\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:661
msgid ""
"NOTE: It is **NOT** possible to migrate from an existing cluster with etcd "
"back end to the Kubernetes back end.  [[s-kubernetes-etcd-hostpath-"
"persistence]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:661
#, no-wrap
msgid "Creating Persistent Storage Volumes"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:670
#, fuzzy, no-wrap
#| msgid "You can use the `pv-hostpath` Helm templates to create `hostPath` persistent volumes. Create as many PVs as needed to satisfy your configured etcd `replicaCount` (default 3)."
msgid ""
"You can use the `pv-hostpath` Helm templates to create `hostPath` persistent\n"
"volumes. Create as many PVs as needed to satisfy your configured etcd\n"
"`replicas` (default 1).\n"
"\n"
"Create the `hostPath` persistent volumes, substituting cluster node\n"
"names accordingly in the `nodes=` option:\n"
"\n"
"----\n"
msgstr "可以使用 `pv-hostpath` Helm模板创建 `hostpath` 持久卷。根据需要创建尽可能多的pv以满足配置的etcd的 `replicaccount`（默认值为3）。"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:673
#, fuzzy, no-wrap
#| msgid ""
#| "helm repo add linstor https://charts.linstor.io\n"
#| "helm install linstor-op linstor/linstor\n"
msgid ""
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-etcd linstor/pv-hostpath\n"
"----\n"
msgstr ""
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-op linstor/linstor\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:682
msgid ""
"By default, a PV is created on every `control-plane` node. You can manually "
"select the storage nodes by passing `--set \"nodes={<NODE0>,<NODE1>,"
"<NODE2>}\"` to the install command.  NOTE: The correct value to reference "
"the node is the value of the `kubernetes.io/hostname` label. You can list "
"the value for all nodes by running `kubectl get nodes -o custom-"
"columns=\"Name:{.metadata.name},NodeName:{.metadata.labels['kubernetes\\.io/"
"hostname']}\"` [[s-kubernetes-existing-database]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:682
#, no-wrap
msgid "Using an Existing Database"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:687
#, no-wrap
msgid ""
"LINSTOR can connect to an existing PostgreSQL, MariaDB or etcd database. For\n"
"instance, for a PostgreSQL instance with the following configuration:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:691
#, no-wrap
msgid ""
"POSTGRES_DB: postgresdb\n"
"POSTGRES_USER: postgresadmin\n"
"POSTGRES_PASSWORD: admin123\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:696
#, no-wrap
msgid ""
"The Helm chart can be configured to use this database rather than deploying an\n"
"etcd cluster, by adding the following to the Helm install command:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:698
#, no-wrap
msgid ""
"--set etcd.enabled=false --set \"operator.controller.dbConnectionURL=jdbc:postgresql://postgres/postgresdb?user=postgresadmin&password=admin123\"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:701
msgid "[[s-kubernetes-configuring-storage-v1]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:701
#, fuzzy, no-wrap
#| msgid "Configuring the rate of synchronization"
msgid "Configuring Storage With Operator v1"
msgstr "配置同步速率"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:705
msgid ""
"The LINSTOR Operator v1 can automate some basic storage set up for LINSTOR."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:705
#, fuzzy, no-wrap
#| msgid "Configuring the rate of synchronization"
msgid "Configuring Storage Pool Creation"
msgstr "配置同步速率"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:711
#, no-wrap
msgid ""
"The LINSTOR Operator can be used to create LINSTOR storage pools. Creation is under control of the\n"
"`LinstorSatelliteSet` resource:\n"
"\n"
"[source]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:730
#, no-wrap
msgid ""
"$ kubectl get LinstorSatelliteSet.linstor.linbit.com linstor-op-ns -o yaml\n"
"kind: LinstorSatelliteSet\n"
"metadata:\n"
"[...]\n"
"spec:\n"
"  [...]\n"
"  storagePools:\n"
"    lvmPools:\n"
"    - name: lvm-thick\n"
"      volumeGroup: drbdpool\n"
"    lvmThinPools:\n"
"    - name: lvm-thin\n"
"      thinVolume: thinpool\n"
"      volumeGroup: \"\"\n"
"    zfsPools:\n"
"    - name: my-linstor-zpool\n"
"      zPool: for-linstor\n"
"      thin: true\n"
"----\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:732
#, no-wrap
msgid "Creating Storage Pools at Installation Time"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:739
#, no-wrap
msgid ""
"At installation time, by setting the value of `operator.satelliteSet.storagePools` when running the `helm install` command.\n"
"\n"
"First create a file with the storage configuration such as:\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:746
#, no-wrap
msgid ""
"operator:\n"
"  satelliteSet:\n"
"    storagePools:\n"
"      lvmPools:\n"
"      - name: lvm-thick\n"
"        volumeGroup: drbdpool\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:751
#, no-wrap
msgid ""
"This file can be passed to the Helm installation by entering the following command:\n"
"\n"
"[source]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:753
#, fuzzy, no-wrap
#| msgid "# yum install linstor-satellite  linstor-client\n"
msgid ""
"helm install -f <file> linstor-op linstor/linstor\n"
"----\n"
msgstr "# yum install linstor-satellite  linstor-client\n"

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:755
#, no-wrap
msgid "Creating Storage Pools After Installation"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:761
#, no-wrap
msgid ""
"On a cluster with the operator already configured (that is, after `helm install`),\n"
"you can edit the `LinstorSatelliteSet` configuration by entering the following command:\n"
"\n"
"[source]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:763
#, no-wrap
msgid ""
"$ kubectl edit LinstorSatelliteSet.linstor.linbit.com <satellitesetname>\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:767
msgid "The storage pool configuration can be updated as in the example above."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:767
#, no-wrap
msgid "Preparing Physical Devices"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:780
#, no-wrap
msgid ""
"By default, LINSTOR expects the referenced VolumeGroups, ThinPools and so on to be present. You can use the\n"
"`devicePaths: []` option to let LINSTOR automatically prepare devices for the pool. Eligible for automatic configuration\n"
"are block devices that:\n"
"\n"
"* Are a root device (no partition)\n"
"* do not contain partition information\n"
"* have more than 1 GiB\n"
"\n"
"To enable automatic configuration of devices, set the `devicePaths` key on `storagePools` entries:\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:794
#, no-wrap
msgid ""
"  storagePools:\n"
"    lvmPools:\n"
"    - name: lvm-thick\n"
"      volumeGroup: drbdpool\n"
"      devicePaths:\n"
"      - /dev/vdb\n"
"    lvmThinPools:\n"
"    - name: lvm-thin\n"
"      thinVolume: thinpool\n"
"      volumeGroup: linstor_thinpool\n"
"      devicePaths:\n"
"      - /dev/vdc\n"
"      - /dev/vdd\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:798
#, fuzzy
#| msgid "Snapshots are supported with thin LVM and ZFS storage pools."
msgid ""
"Currently, this method supports creation of LVM and LVMTHIN storage pools."
msgstr "精简LVM和ZFS存储池支持快照。"

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:798
#, fuzzy, no-wrap
#| msgid "Configuring the Nodes"
msgid "Configuring LVM Storage Pools"
msgstr "配置节点"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:818
msgid ""
"The available keys for `lvmPools` entries are: * `name` name of the LINSTOR "
"storage pool. [Required] * `volumeGroup` name of the VG to create. "
"[Required] * `devicePaths` devices to configure for this pool. Must be empty "
"and >= 1GiB to be recognized. [Optional] * `raidLevel` LVM raid level. "
"[Optional] * `vdo` Enable [VDO] (requires VDO tools in the satellite). "
"[Optional] * `vdoLogicalSizeKib` Size of the created VG (expected to be "
"bigger than the backing devices by using VDO). [Optional] * `vdoSlabSizeKib` "
"Slab size for VDO. [Optional] [VDO]: https://www.redhat.com/en/blog/look-vdo-"
"new-linux-compression-layer"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:818
#, fuzzy, no-wrap
#| msgid "Configuring the Nodes"
msgid "Configuring LVM Thin Pools"
msgstr "配置节点"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:830
#, no-wrap
msgid ""
"* `name` name of the LINSTOR storage pool. [Required]\n"
"\n"
"* `volumeGroup` VG to use for the thin pool. If you want to use `devicePaths`, you must set this to `\"\"`.  This is required because LINSTOR does not allow configuration of the VG name when preparing devices.  `thinVolume` name of the thin pool. [Required]\n"
"\n"
"* `devicePaths` devices to configure for this pool. Must be empty and >= 1GiB to be recognized. [Optional]\n"
"\n"
"* `raidLevel` LVM raid level. [Optional]\n"
"\n"
"NOTE: The volume group created by LINSTOR for LVM thin pools will always follow the scheme \"linstor_$THINPOOL\".\n"
"\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:830
#, fuzzy, no-wrap
#| msgid "Configuring the Nodes"
msgid "Configuring ZFS Storage Pools"
msgstr "配置节点"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:836
#, no-wrap
msgid ""
"* `name` name of the LINSTOR storage pool. [Required]\n"
"* `zPool` name of the `zpool` to use. Must already be present on all machines. [Required]\n"
"* `thin` `true` to use thin provisioning, `false` otherwise. [Required]\n"
"\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:836
#, no-wrap
msgid "Automatic Storage Type Provisioning (DEPRECATED)"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:850
msgid ""
"_ALL_ eligible devices will be prepared according to the value of `operator."
"satelliteSet.automaticStorageType`, unless they are already prepared using "
"the `storagePools` section. Devices are added to a storage pool based on the "
"device name (that is, all `/dev/nvme1` devices will be part of the pool "
"`autopool-nvme1`)  The possible values for `operator.satelliteSet."
"automaticStorageType`: * `None` no automatic set up (default)  * `LVM` "
"create a LVM (thick) storage pool * `LVMTHIN` create a LVM thin storage pool "
"* `ZFS` create a ZFS based storage pool (**UNTESTED**)  [[s-kubernetes-"
"securing-deployment-v1]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:850
#, fuzzy, no-wrap
#| msgid "Terminating Helm deployment"
msgid "Securing Operator v1 Deployment"
msgstr "终止Helm部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:855
msgid ""
"This section describes the different options for enabling security features "
"available when using a LINSTOR Operator v1 deployment (<<s-kubernetes-deploy-"
"linstor-operator-v1,using Helm>>) in Kubernetes."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:855
#, no-wrap
msgid "Secure Communication with an Existing etcd Instance"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:862
#, no-wrap
msgid ""
"Secure communication to an `etcd` instance can be enabled by providing a CA certificate to the operator in form of a\n"
"Kubernetes secret. The secret has to contain the key `ca.pem` with the PEM encoded CA certificate as value.\n"
"\n"
"The secret can then be passed to the controller by passing the following argument to `helm install`\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:864
#, no-wrap
msgid ""
"--set operator.controller.dbCertSecret=<secret name>\n"
"----\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:866
#, no-wrap
msgid "Authentication with `etcd` Using Certificates"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:871
#, no-wrap
msgid ""
"If you want to use TLS certificates to authenticate with an `etcd` database, you need to set the following option on\n"
"Helm install:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:873
#, no-wrap
msgid ""
"--set operator.controller.dbUseClientCert=true\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:882
#, no-wrap
msgid ""
"If this option is active, the secret specified in the above section must contain two additional keys:\n"
"\n"
"* `client.cert` PEM formatted certificate presented to `etcd` for authentication\n"
"* `client.key` private key **in PKCS8 format**, matching the above client certificate.\n"
"\n"
"Keys can be converted into PKCS8 format using `openssl`:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:884
#, no-wrap
msgid ""
"openssl pkcs8 -topk8 -nocrypt -in client-key.pem -out client-key.pkcs8\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:887
msgid "[[s-kubenetes-secure-communication-between-linstor-components-v1]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:887
#, no-wrap
msgid "Configuring Secure Communication Between LINSTOR Components in Operator v1 Deployments"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:894
msgid ""
"The default communication between LINSTOR components is not secured by TLS. "
"If this is needed for your setup, choose one of three methods: // \"cert-"
"manager\" is a product name so keep the original case"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:894
#, no-wrap
msgid "Generating Keys and Certificates Using cert-manager"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:901
#, no-wrap
msgid ""
"Requires https://cert-manager.io/docs/[cert-manager] to be installed in your cluster.\n"
"\n"
"Set the following options in your Helm override file:\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:904
#, no-wrap
msgid ""
"linstorSslMethod: cert-manager\n"
"linstorHttpsMethod: cert-manager\n"
"----\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:906
#, no-wrap
msgid "Generate Keys and Certificates Using Helm"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:911
#, no-wrap
msgid ""
"Set the following options in your Helm override file:\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:914
#, no-wrap
msgid ""
"linstorSslMethod: helm\n"
"linstorHttpsMethod: helm\n"
"----\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:916
#, no-wrap
msgid "Generating Keys and Certificates Manually"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:920
#, no-wrap
msgid ""
"Create a private key and self-signed certificate for your certificate authorities:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:925
#, no-wrap
msgid ""
"openssl req -new -newkey rsa:2048 -days 5000 -nodes -x509 -keyout ca.key \\\n"
"  -out ca.crt -subj \"/CN=linstor-system\"\n"
"openssl req -new -newkey rsa:2048 -days 5000 -nodes -x509 -keyout client-ca.key \\\n"
"  -out client-ca.crt -subj \"/CN=linstor-client-ca\"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:929
#, no-wrap
msgid ""
"Create private keys, two for the controller, one for all nodes and one for all clients:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:934
#, no-wrap
msgid ""
"openssl genrsa -out linstor-control.key 2048\n"
"openssl genrsa -out linstor-satellite.key 2048\n"
"openssl genrsa -out linstor-client.key 2048\n"
"openssl genrsa -out linstor-api.key 2048\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:938
#, fuzzy, no-wrap
#| msgid "Then we import this certificate to our controller truststore:"
msgid ""
"Create trusted certificates for controller and nodes:\n"
"\n"
"----\n"
msgstr "然后我们将此证书导入controller信任库："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:957
#, no-wrap
msgid ""
"openssl req -new -sha256 -key linstor-control.key -subj \"/CN=system:control\" \\\n"
"  -out linstor-control.csr\n"
"openssl req -new -sha256 -key linstor-satellite.key -subj \"/CN=system:node\" \\\n"
"  -out linstor-satellite.csr\n"
"openssl req -new -sha256 -key linstor-client.key -subj \"/CN=linstor-client\" \\\n"
"  -out linstor-client.csr\n"
"openssl req -new -sha256 -key linstor-api.key -subj \"/CN=linstor-controller\" \\\n"
"  -out  linstor-api.csr\n"
"openssl x509 -req -in linstor-control.csr -CA ca.crt -CAkey ca.key -CAcreateserial \\\n"
"  -out linstor-control.crt -days 5000 -sha256\n"
"openssl x509 -req -in linstor-satellite.csr -CA ca.crt -CAkey ca.key -CAcreateserial \\\n"
"  -out linstor-satellite.crt -days 5000 -sha256\n"
"openssl x509 -req -in linstor-client.csr -CA client-ca.crt -CAkey client-ca.key \\\n"
"  -CAcreateserial -out linstor-client.crt -days 5000 -sha256\n"
"openssl x509 -req -in linstor-api.csr -CA client-ca.crt -CAkey client-ca.key \\\n"
"  -CAcreateserial -out linstor-api.crt -days 5000 -sha256 -extensions 'v3_req' \\\n"
"  -extfile <(printf '%s\\n' '[v3_req]' extendedKeyUsage=serverAuth \\\n"
"  subjectAltName=DNS:linstor-op-cs.default.svc)\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:964
#, no-wrap
msgid ""
"NOTE: `linstor-op-cs.default.svc` in the last command needs to match create service name. With Helm, this is always\n"
"`<release-name>-cs.<namespace>.svc`.\n"
"\n"
"Create Kubernetes secrets that can be passed to the controller and node pods:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:977
#, no-wrap
msgid ""
"kubectl create secret generic linstor-control --type=kubernetes.io/tls \\\n"
"  --from-file=ca.crt=ca.crt --from-file=tls.crt=linstor-control.crt \\\n"
"  --from-file=tls.key=linstor-control.key\n"
"kubectl create secret generic linstor-satellite --type=kubernetes.io/tls \\\n"
"  --from-file=ca.crt=ca.crt --from-file=tls.crt=linstor-satellite.crt \\\n"
"  --from-file=tls.key=linstor-satellite.key\n"
"kubectl create secret generic linstor-api --type=kubernetes.io/tls \\\n"
"  --from-file=ca.crt=client-ca.crt --from-file=tls.crt=linstor-api.crt \\\n"
"  --from-file=tls.key=linstor-api.key\n"
"kubectl create secret generic linstor-client --type=kubernetes.io/tls \\\n"
"  --from-file=ca.crt=client-ca.crt --from-file=tls.crt=linstor-client.crt \\\n"
"  --from-file=tls.key=linstor-client.key\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:982
#, no-wrap
msgid ""
"Pass the names of the created secrets to `helm install`:\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:990
#, no-wrap
msgid ""
"linstorHttpsControllerSecret: linstor-api\n"
"linstorHttpsClientSecret: linstor-client\n"
"operator:\n"
"  controller:\n"
"    sslSecret: linstor-control\n"
"  satelliteSet:\n"
"    sslSecret: linstor-satellite\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:993
msgid "[[s-kubernetes-linstor-master-passphrase-v1]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:993
#, no-wrap
msgid "Automatically Set the Passphrase for LINSTOR"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1000
#, no-wrap
msgid ""
"LINSTOR needs to store confidential data to support encrypted information. This data is protected by a master\n"
"passphrase. A passphrase is automatically generated on the first chart install.\n"
"\n"
"If you want to use a custom passphrase, store it in a secret:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1002
#, no-wrap
msgid ""
"kubectl create secret generic linstor-pass --from-literal=MASTER_PASSPHRASE=<password>\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1006
#, no-wrap
msgid ""
"On install, add the following arguments to the Helm command:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1008
#, no-wrap
msgid ""
"--set operator.controller.luksSecret=linstor-pass\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1011
msgid "[[s-kubernetes-helm-install-examples-v1]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1011
#, no-wrap
msgid "Helm Installation Examples for Operator v1"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1017
#, no-wrap
msgid ""
"All the below examples use the following `sp-values.yaml` file. Feel\n"
"free to adjust this for your uses and environment. See <<Configuring storage pool creation>>\n"
"for further details.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1027
#, no-wrap
msgid ""
"operator:\n"
"  satelliteSet:\n"
"    storagePools:\n"
"      lvmThinPools:\n"
"      - name: lvm-thin\n"
"        thinVolume: thinpool\n"
"        volumeGroup: \"\"\n"
"        devicePaths:\n"
"        - /dev/sdb\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1034
#, no-wrap
msgid ""
"NOTE: Default install. This does not setup any persistence for\n"
"the backing etcd key-value store.\n"
"\n"
"WARNING: This is not suggested for any use outside of testing.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1039
#, fuzzy, no-wrap
#| msgid "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
msgid ""
"kubectl create secret docker-registry drbdiocred --docker-server=drbd.io \\\n"
"  --docker-username=<YOUR_LOGIN> --docker-password=<YOUR_PASSWORD>\n"
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-op linstor/linstor\n"
"----\n"
msgstr "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1058
#, no-wrap
msgid ""
"IMPORTANT: LINBIT's container image repository (http://drbd.io), used in the previous and\n"
"upcoming `kubectl create` commands, is only available to LINBIT customers or through LINBIT\n"
"customer trial accounts. link:https://linbit.com/contact-us/[Contact LINBIT for information on\n"
"pricing or to begin a trial]. Alternatively, you can use the LINSTOR SDS upstream project named\n"
"link:https://github.com/piraeusdatastore/piraeus-operator[Piraeus], without being a LINBIT\n"
"customer.\n"
"\n"
"Install with LINSTOR storage-pools defined at install through\n"
"`sp-values.yaml`, persistent `hostPath` volumes, three etcd replicas, and by\n"
"compiling the DRBD kernel modules for the host kernels.\n"
"\n"
"This should be adequate for most basic deployments. Note that\n"
"this deployment is not using the pre-compiled DRBD kernel modules just\n"
"to make this command more portable. Using the pre-compiled binaries\n"
"will make for a much faster install and deployment. Using the\n"
"`Compile` option would not be suggested for use in a large Kubernetes clusters.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1065
#, fuzzy, no-wrap
#| msgid "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
msgid ""
"kubectl create secret docker-registry drbdiocred --docker-server=drbd.io \\\n"
"  --docker-username=<YOUR_LOGIN> --docker-password=<YOUR_PASSWORD>\n"
"helm repo add linstor https://charts.linstor.io\n"
"helm install linstor-etcd linstor/pv-hostpath --set \"nodes={<NODE0>,<NODE1>,<NODE2>}\"\n"
"helm install -f sp-values.yaml linstor-op linstor/linstor --set etcd.replicas=3 \\\n"
"  --set operator.satelliteSet.kernelModuleInjectionMode=Compile\n"
"----\n"
msgstr "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1077
#, no-wrap
msgid ""
"Install with LINSTOR storage-pools defined at install through\n"
"`sp-values.yaml`, use an already created PostgreSQL DB (preferably\n"
"clustered), rather than etcd, and use already compiled kernel modules for\n"
"DRBD.\n"
"\n"
"The PostgreSQL database in this particular example is reachable through a\n"
"service endpoint named `postgres`. PostgreSQL itself is configured with\n"
"`POSTGRES_DB=postgresdb`, `POSTGRES_USER=postgresadmin`, and\n"
"`POSTGRES_PASSWORD=admin123`\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1083
#, fuzzy, no-wrap
#| msgid "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
msgid ""
"kubectl create secret docker-registry drbdiocred --docker-server=drbd.io \\\n"
"  --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"
"helm repo add linstor https://charts.linstor.io\n"
"helm install -f sp-values.yaml linstor-op linstor/linstor --set etcd.enabled=false \\\n"
"  --set \"operator.controller.dbConnectionURL=jdbc:postgresql://postgres/postgresdb?user=postgresadmin&password=admin123\"\n"
"----\n"
msgstr "kubectl create secret docker-registry drbdiocred --docker-server=drbd.io --docker-username=<YOUR_LOGIN> --docker-email=<YOUR_EMAIL> --docker-password=<YOUR_PASSWORD>\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1086
msgid "[[s-kubernetes-helm-terminate]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1086
#, fuzzy, no-wrap
#| msgid "Terminating Helm deployment"
msgid "Terminating Helm Deployment"
msgstr "终止Helm部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1092
#, no-wrap
msgid ""
"To protect the storage infrastructure of the cluster from accidentally deleting vital components, it is necessary to perform some manual steps before deleting a Helm deployment.\n"
"\n"
"1. Delete all volume claims managed by LINSTOR components. You can use the following command to get a list of volume claims managed by LINSTOR. After checking that none of the listed volumes still hold needed data, you can delete them using the generated `kubectl delete` command.\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1097
#, no-wrap
msgid ""
"$ kubectl get pvc --all-namespaces -o=jsonpath='{range .items[?(@.metadata.annotations.volume\\.beta\\.kubernetes\\.io/storage-provisioner==\"linstor.csi.linbit.com\")]}kubectl delete pvc --namespace {.metadata.namespace} {.metadata.name}{\"\\n\"}{end}'\n"
"kubectl delete pvc --namespace default data-mysql-0\n"
"kubectl delete pvc --namespace default data-mysql-1\n"
"kubectl delete pvc --namespace default data-mysql-2\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1105
#, no-wrap
msgid ""
"+\n"
"WARNING: These volumes, once deleted, cannot be recovered.\n"
"\n"
"2. Delete the LINSTOR controller and satellite resources.\n"
"+\n"
"Deployment of LINSTOR satellite and controller is controlled by the `LinstorSatelliteSet` and `LinstorController` resources. You can delete the resources associated with your deployment by using `kubectl`\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1108
#, no-wrap
msgid ""
"kubectl delete linstorcontroller <helm-deploy-name>-cs\n"
"kubectl delete linstorsatelliteset <helm-deploy-name>-ns\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1116
#, no-wrap
msgid ""
"+\n"
"After a short wait, the controller and satellite pods should terminate. If they continue to run, you can check the above resources for errors (they are only removed after all associated pods have terminated).\n"
"\n"
"3. Delete the Helm deployment.\n"
"+\n"
"If you removed all PVCs and all LINSTOR pods have terminated, you can uninstall the Helm deployment\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1118
#, fuzzy, no-wrap
#| msgid "helm delete linstor-op\n"
msgid ""
"helm uninstall linstor-op\n"
"----\n"
msgstr "helm delete linstor-op\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1124
#, fuzzy, no-wrap
#| msgid "More information regarding Helm’s current position on CRD’s can be found https://helm.sh/docs/topics/chart_best_practices/custom_resource_definitions/#method-1-let-helm-do-it-for-you[here]."
msgid ""
"+\n"
"NOTE: Due to the Helm's current policy, the Custom Resource Definitions named `LinstorController` and `LinstorSatelliteSet` will not be deleted by the command.\n"
" More information regarding Helm's current position on CRDs can be found https://helm.sh/docs/chart_best_practices/custom_resource_definitions/#method-1-let-helm-do-it-for-you[here].\n"
"\n"
"[[s-kubernetes-advanced-deployments-v1]]\n"
msgstr "有关Helm目前在CRD上的位置的更多信息，请访问 https://Helm.sh/docs/topics/chart_best_practices/custom_resource_definitions/#method-1-let-Helm-do-it-for-you[这里]。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1124
#, fuzzy, no-wrap
#| msgid "Deployment Options"
msgid "Advanced Deployment Options for Operator v1"
msgstr "部署选项"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1131
#, no-wrap
msgid ""
"The Helm charts provide a set of further customization options for advanced use cases.\n"
"\n"
"IMPORTANT: LINBIT's container image repository (http://drbd.io), used in the Helm chart below, is only available to LINBIT customers or through LINBIT customer trial accounts. link:https://linbit.com/contact-us/[Contact LINBIT for information on pricing or to begin a trial]. Alternatively, you can use the LINSTOR SDS upstream project named link:https://github.com/piraeusdatastore/piraeus-operator[Piraeus], without being a LINBIT customer.\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1262
#, no-wrap
msgid ""
"global:\n"
"  imagePullPolicy: IfNotPresent # empty pull policy means k8s default is used (\"always\" if tag == \":latest\", \"ifnotpresent\" else) <1>\n"
"  setSecurityContext: true # Force non-privileged containers to run as non-root users\n"
"# Dependency charts\n"
"etcd:\n"
"  enabled: true\n"
"  persistentVolume:\n"
"    enabled: true\n"
"    storage: 1Gi\n"
"  replicas: 1 # How many instances of etcd will be added to the initial cluster. <2>\n"
"  resources: {} # resource requirements for etcd containers <3>\n"
"  image:\n"
"    repository: gcr.io/etcd-development/etcd\n"
"    tag: v3.4.15\n"
"stork:\n"
"  enabled: false\n"
"  storkImage: docker.io/openstorage/stork:2.8.2\n"
"  schedulerImage: registry.k8s.io/kube-scheduler\n"
"  schedulerTag: \"\"\n"
"  replicas: 1 <2>\n"
"  storkResources: {} # resources requirements for the stork plugin containers <3>\n"
"  schedulerResources: {} # resource requirements for the kube-scheduler containers <3>\n"
"  podsecuritycontext: {}\n"
"csi:\n"
"  enabled: true\n"
"  pluginImage: \"drbd.io/linstor-csi:v1.1.0\"\n"
"  csiAttacherImage: registry.k8s.io/sig-storage/csi-attacher:v4.3.0\n"
"  csiLivenessProbeImage: registry.k8s.io/sig-storage/livenessprobe:v2.10.0\n"
"  csiNodeDriverRegistrarImage: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.8.0\n"
"  csiProvisionerImage: registry.k8s.io/sig-storage/csi-provisioner:v3.5.0\n"
"  csiSnapshotterImage: registry.k8s.io/sig-storage/csi-snapshotter:v6.2.1\n"
"  csiResizerImage: registry.k8s.io/sig-storage/csi-resizer:v1.8.0\n"
"  csiAttacherWorkerThreads: 10 <9>\n"
"  csiProvisionerWorkerThreads: 10 <9>\n"
"  csiSnapshotterWorkerThreads: 10 <9>\n"
"  csiResizerWorkerThreads: 10 <9>\n"
"  controllerReplicas: 1 <2>\n"
"  nodeAffinity: {} <4>\n"
"  nodeTolerations: [] <4>\n"
"  controllerAffinity: {} <4>\n"
"  controllerTolerations: [] <4>\n"
"  enableTopology: true\n"
"  resources: {} <3>\n"
"  customLabels: {}\n"
"  customAnnotations: {}\n"
"  kubeletPath: /var/lib/kubelet <7>\n"
"  controllerSidecars: []\n"
"  controllerExtraVolumes: []\n"
"  nodeSidecars: []\n"
"  nodeExtraVolumes: []\n"
"priorityClassName: \"\"\n"
"drbdRepoCred: drbdiocred\n"
"linstorSslMethod: \"manual\" # <- If set to 'helm' or 'cert-manager' the certificates will be generated automatically\n"
"linstorHttpsMethod: \"manual\" # <- If set to 'helm' or 'cert-manager' the certificates will be generated automatically\n"
"linstorHttpsControllerSecret: \"\" # <- name of secret containing linstor server certificates+key. See docs/security.md\n"
"linstorHttpsClientSecret: \"\" # <- name of secret containing linstor client certificates+key. See docs/security.md\n"
"controllerEndpoint: \"\" # <- override to the generated controller endpoint. use if controller is not deployed via operator\n"
"psp:\n"
"  privilegedRole: \"\"\n"
"  unprivilegedRole: \"\"\n"
"operator:\n"
"  replicas: 1 # <- number of replicas for the operator deployment <2>\n"
"  image: \"drbd.io/linstor-operator:v1.10.4\"\n"
"  affinity: {} <4>\n"
"  tolerations: [] <4>\n"
"  resources: {} <3>\n"
"  customLabels: {}\n"
"  customAnnotations: {}\n"
"  podsecuritycontext: {}\n"
"  args:\n"
"    createBackups: true\n"
"    createMonitoring: true\n"
"  sidecars: []\n"
"  extraVolumes: []\n"
"  controller:\n"
"    enabled: true\n"
"    controllerImage: \"drbd.io/linstor-controller:v1.23.0\"\n"
"    dbConnectionURL: \"\"\n"
"    luksSecret: \"\"\n"
"    dbCertSecret: \"\"\n"
"    dbUseClientCert: false\n"
"    sslSecret: \"\"\n"
"    affinity: {} <4>\n"
"    httpBindAddress: \"\"\n"
"    httpsBindAddress: \"\"\n"
"    tolerations: <4>\n"
"      - key: node-role.kubernetes.io/master\n"
"        operator: Exists\n"
"        effect: NoSchedule\n"
"      - key: node-role.kubernetes.io/control-plane\n"
"        operator: Exists\n"
"        effect: NoSchedule\n"
"    resources: {} <3>\n"
"    replicas: 1 <2>\n"
"    additionalEnv: [] <5>\n"
"    additionalProperties: {} <6>\n"
"    sidecars: []\n"
"    extraVolumes: []\n"
"    customLabels: {}\n"
"    customAnnotations: {}\n"
"  satelliteSet:\n"
"    enabled: true\n"
"    satelliteImage: \"drbd.io/linstor-satellite:v1.23.0\"\n"
"    storagePools: {}\n"
"    sslSecret: \"\"\n"
"    automaticStorageType: None\n"
"    affinity: {} <4>\n"
"    tolerations: [] <4>\n"
"    resources: {} <3>\n"
"    monitoringImage: \"drbd.io/drbd-reactor:v1.2.0\"\n"
"    monitoringBindAddress: \"\"\n"
"    kernelModuleInjectionImage: \"drbd.io/drbd9-rhel7:v9.1.14\"\n"
"    kernelModuleInjectionMode: ShippedModules\n"
"    kernelModuleInjectionAdditionalSourceDirectory: \"\" <8>\n"
"    kernelModuleInjectionResources: {} <3>\n"
"    kernelModuleInjectionExtraVolumeMounts: []\n"
"    additionalEnv: [] <5>\n"
"    sidecars: []\n"
"    extraVolumes: []\n"
"    customLabels: {}\n"
"    customAnnotations: {}\n"
"haController:\n"
"  enabled: false\n"
"  image: drbd.io/linstor-k8s-ha-controller:v0.3.0\n"
"  affinity: {} <4>\n"
"  tolerations: [] <4>\n"
"  resources: {} <3>\n"
"  replicas: 1 <2>\n"
"  customLabels: {}\n"
"  customAnnotations: {}\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1305
#, no-wrap
msgid ""
"<1> Sets the pull policy for all images.\n"
"\n"
"<2> Controls the number of replicas for each component.\n"
"\n"
"<3> Set container resource requests and limits. See https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/[the Kubernetes docs].\n"
" Most containers need a minimal amount of resources, except for:\n"
"    * `etcd.resources` See the https://etcd.io/docs/v3.4.0/op-guide/hardware/[etcd docs]\n"
"    * `operator.controller.resources` Around `700MiB` memory is required\n"
"    * `operater.satelliteSet.resources` Around `700MiB` memory is required\n"
"    * `operator.satelliteSet.kernelModuleInjectionResources` If kernel modules are compiled,\n"
"1GiB of memory is required.\n"
"\n"
"<4> Affinity and toleration determine where pods are scheduled on the cluster. See the\n"
"https://kubernetes.io/docs/concepts/scheduling-eviction/[Kubernetes docs on affinity and\n"
"toleration]. This might be especially important for the `operator.satelliteSet` and `csi.node*`\n"
"values. To schedule a pod using a LINSTOR persistent volume, the node requires a running\n"
"LINSTOR satellite and LINSTOR CSI pod.\n"
"\n"
"<5> Sets additional environments variables to pass to the LINSTOR controller and satellites.\n"
"Uses the same format as https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/[the\n"
"`env` value of a container]\n"
"\n"
"<6> Sets additional properties on the LINSTOR controller. Expects a simple mapping of `<property-key>: <value>`.\n"
"\n"
"<7> kubelet expects every CSI plugin to mount volumes under a specific subdirectory of its own state directory. By default, this state directory is `/var/lib/kubelet`. Some Kubernetes distributions use a different directory:\n"
"\n"
"* microk8s: `/var/snap/microk8s/common/var/lib/kubelet`\n"
"\n"
"<8> Directory on the host that is required for building kernel modules. Only needed if using the `Compile` injection method. Defaults to `/usr/src`, which is where the actual kernel sources are stored on most distributions. Use `\"none\"` to not mount any additional directories.\n"
"\n"
"<9> Set the number of worker threads used by the CSI driver. Higher values put more load on the LINSTOR controller, which might lead to instability when creating many volumes at once.\n"
"\n"
"<10> If set to true, the satellite containers will have the following files and directories mounted from the host operating system:\n"
"+\n"
"* `/etc/drbd/drbd.conf` (file)\n"
"* `/etc/drbd.d` (directory)\n"
"* `/var/lib/drbd` (directory)\n"
"* `/var/lib/linstor.d` (directory)\n"
"+\n"
"All files and directories must already exist on the host.\n"
"\n"
"[[s-kubernetes-ha-deployment]]\n"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1305
#, no-wrap
msgid "High-Availability Deployment in Operator v1"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1314
msgid ""
"To create a high-availability deployment of all components within a LINSTOR "
"Operator v1 deployment, consult the https://github.com/piraeusdatastore/"
"piraeus-operator/blob/b00fd34/doc/scheduling.md[upstream guide] The default "
"values are chosen so that scaling the components to multiple replicas "
"ensures that the replicas are placed on different nodes. This ensures that a "
"single node failures will not interrupt the service.  NOTE: If you have "
"deployed LINBIT SDS in Kubernetes by using the LINSTOR Operator v2, high "
"availability is built into the deployment by default.  [[s-kubernetes-ha-"
"controller-v1]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:1314
#, no-wrap
msgid "Fast Workload Failover Using the High Availability Controller"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1328
#, no-wrap
msgid ""
"When node failures occur, Kubernetes is very conservative in rescheduling stateful workloads. This means it can\n"
"take more than 15 minutes for Pods to be moved from unreachable nodes. With the information available to DRBD and\n"
"LINSTOR, this process can be sped up significantly.\n"
"\n"
"The LINSTOR High Availability Controller (HA Controller) speeds up the failover process for stateful workloads using\n"
"LINSTOR for storage. It monitors and manages any Pod that is attached to at least one DRBD resource.\n"
"\n"
"For the HA Controller to work properly, you need quorum, that is at least three replicas (or two replicas + one diskless\n"
"tiebreaker). If using lower replica counts, attached Pods will be ignored and are not eligible for faster failover.\n"
"\n"
"The HA Controller is packaged as a Helm chart, and can be deployed using:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1331
#, fuzzy, no-wrap
#| msgid "# zypper install linstor-controller linstor-satellite  linstor-client\n"
msgid ""
"$ helm repo update\n"
"$ helm install linstor-ha-controller linstor/linstor-ha-controller\n"
"----\n"
msgstr "# zypper install linstor-controller linstor-satellite  linstor-client\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1337
#, no-wrap
msgid ""
"If you are using the HA Controller in your cluster you can set additional parameters in all StorageClasses. These\n"
"parameters ensure that the volume is not accidentally remounted as read-only, leading to degraded Pods.\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1343
#, no-wrap
msgid ""
"parameters:\n"
"  property.linstor.csi.linbit.com/DrbdOptions/auto-quorum: suspend-io\n"
"  property.linstor.csi.linbit.com/DrbdOptions/Resource/on-no-data-accessible: suspend-io\n"
"  property.linstor.csi.linbit.com/DrbdOptions/Resource/on-suspended-primary-outdated: force-secondary\n"
"  property.linstor.csi.linbit.com/DrbdOptions/Net/rr-conflict: retry-connect\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1347
#, no-wrap
msgid ""
"To exempt a Pod from management by the HA Controller, add the following annotation to the Pod:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1349
#, no-wrap
msgid ""
"$ kubectl annotate pod <podname> drbd.linbit.com/ignore-fail-over=\"\"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1352
msgid "[[s-kubernetes-etcd-backup]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1352
#, fuzzy, no-wrap
#| msgid "Changing the meta-data"
msgid "Backing up the etcd Database"
msgstr "更改元数据"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1357
#, no-wrap
msgid ""
"To create a backup of the etcd database (in LINSTOR Operator v1 deployments) and store it on your control host, enter the following commands:\n"
"\n"
"[source]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1360
#, no-wrap
msgid ""
"kubectl exec linstor-op-etcd-0 -- etcdctl snapshot save /tmp/save.db\n"
"kubectl cp linstor-op-etcd-0:/tmp/save.db save.db\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1365
msgid ""
"These commands will create a file `save.db` on the machine you are running "
"`kubectl` from.  [[s-kubernetes-deploy-external-controller]]"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:1365
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Deploying with an External LINSTOR Controller"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1372
msgid ""
"The Operator can configure the satellites and CSI plugin to use an existing "
"LINSTOR setup. This can be useful in cases where the storage infrastructure "
"is separate from the Kubernetes cluster. Volumes can be provisioned in "
"diskless mode on the Kubernetes nodes while the storage nodes will provide "
"the backing disk storage.  [[s-kubernetes-external-linstor-controller-"
"deployment-v2]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1372
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Operator v2 Deployment with an External LINSTOR Controller"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1381
msgid ""
"// see this GL issue: // https://gitlab.at.linbit.com/linbit/linbit-"
"documentation/-/issues/88 The instructions in this section describe how you "
"can connect an Operator v2 LINBIT SDS deployment to an existing LINBIST SDS "
"cluster that you manage outside Kubernetes.  To follow the steps in this "
"section you should be familiar with editing link:https://github.com/"
"piraeusdatastore/piraeus-operator/blob/v2/docs/reference/linstorcluster."
"md[`LinstorCluster`] resources.  [[s-kubernetes-external-linstor-controller-"
"deployment-configuring-linstorcluster-v2]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:1381
#, fuzzy, no-wrap
#| msgid "Configuring your resource"
msgid "Configuring the `LinstorCluster` Resource"
msgstr "配置资源"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1385
#, no-wrap
msgid ""
"To use an externally managed LINSTOR cluster, specify the URL of the LINSTOR controller in the `LinstorCluster` resource in a YAML configuration and apply it to your deployment. In the following example, the LINSTOR controller is reachable at `http://linstor-controller.example.com:3370`.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1393
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorCluster\n"
"metadata:\n"
"  name: linstorcluster\n"
"spec:\n"
"  externalController:\n"
"    url: http://linstor-controller.example.com:3370\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1398
msgid ""
"NOTE: You can also specify an IP address rather than a hostname and domain "
"for the controller.  [[s-kubernetes-external-linstor-controller-deployment-"
"configuring-host-networking-v2]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:1398
#, fuzzy, no-wrap
#| msgid "Configuration using LINSTOR"
msgid "Configuring Host Networking for LINSTOR Satellites"
msgstr "使用LINSTOR配置"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1404
#, no-wrap
msgid ""
"Normally the pod network is not reachable from outside the Kubernetes cluster. In this case the external LINSTOR controller would not be able to communicate with the satellites in the Kubernetes cluster. For this reason, you need to configure your satellites to use host networking.\n"
"\n"
"To use host networking, deploy a `LinstorSatelliteConfiguration` resource by applying the following YAML configuration to your deployment:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1421
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: host-network\n"
"spec:\n"
"  patches:\n"
"    - target:\n"
"        kind: Pod\n"
"        name: satellite\n"
"      patch: |\n"
"        apiVersion: v1\n"
"        kind: Pod\n"
"        metadata:\n"
"          name: satellite\n"
"        spec:\n"
"          hostNetwork: true\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1424
#, fuzzy
#| msgid "linstor-controller"
msgid "[[s-kubernetes-external-linstor-controller-deployment-verifying-v2]]"
msgstr "linstor-controller"

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:1424
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Verifying an External LINSTOR Controller Configuration"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1432
#, no-wrap
msgid ""
"You can verify that you have correctly configured your Kubernetes deployment to use an external LINSTOR controller by verifying the following:\n"
"\n"
"- The `Available` condition on the `LinstorCluster` resource reports the expected URL for the\n"
"  external LINSTOR controller:\n"
"+\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1435
#, no-wrap
msgid ""
"$ kubectl get LinstorCluster -ojsonpath='{.items[].status.conditions[?(@.type==\"Available\")].message}{\"\\n\"}'\n"
"Controller 1.20.3 (API: 1.16.0, Git: 8d19a891df018f6e3d40538d809904f024bfe361) reachable at 'http://linstor-controller.example.com:3370'\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1440
#, no-wrap
msgid ""
"- The `linstor-csi-controller` deployment uses the expected URL:\n"
"+\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1443
#, no-wrap
msgid ""
"$ kubectl get -n linbit-sds deployment linstor-csi-controller -ojsonpath='{.spec.template.spec.containers[?(@.name==\"linstor-csi\")].env[?(@.name==\"LS_CONTROLLERS\")].value}{\"\\n\"}'\n"
"http://linstor-controller.example.com:3370\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1448
#, no-wrap
msgid ""
"- The `linstor-csi-node` deployment uses the expected URL:\n"
"+\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1451
#, no-wrap
msgid ""
"$ kubectl get -n linbit-sds daemonset linstor-csi-node -ojsonpath='{.spec.template.spec.containers[?(@.name==\"linstor-csi\")].env[?(@.name==\"LS_CONTROLLERS\")].value}{\"\\n\"}'\n"
"http://linstor-controller.example.com:3370\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1456
#, no-wrap
msgid ""
"- The Kubernetes nodes are registered as satellite nodes on the LINSTOR controller:\n"
"+\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1461
#, no-wrap
msgid ""
"$ kubectl get nodes -owide\n"
"NAME               STATUS   ROLES           AGE   VERSION   INTERNAL-IP      [...]\n"
"k8s-1-26-10.test   Ready    control-plane   22m   v1.26.3   192.168.122.10   [...]\n"
"[...]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1465
#, no-wrap
msgid ""
"+\n"
"After getting the node names from the output of the above command, verify that the node names are also LINSTOR satellites by entering a LINSTOR `node list` command on your LINSTOR controller node.\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1472
#, no-wrap
msgid ""
"$ linstor node list\n"
"╭─────────────────────────────────────────────────────────────────────╮\n"
"┊ Node             ┊ NodeType  ┊ Addresses                   ┊ State  ┊\n"
"╞═════════════════════════════════════════════════════════════════════╡\n"
"┊ k8s-1-26-10.test ┊ SATELLITE ┊ 192.168.122.10:3366 (PLAIN) ┊ Online ┊\n"
"[...]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1475
#, fuzzy
#| msgid "linstor-controller"
msgid "[[s-kubernetes-external-linstor-controller-deployment-v1]]"
msgstr "linstor-controller"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1475
#, fuzzy, no-wrap
#| msgid "Deploying with the LINSTOR Operator"
msgid "Operator v1 Deployment with an External LINSTOR Controller"
msgstr "使用LINSTOR Operator部署"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1494
#, no-wrap
msgid ""
"To skip the creation of a LINSTOR controller deployment and configure the other components to use your existing LINSTOR\n"
"controller, use the following options when running `helm install`:\n"
"\n"
"* `operator.controller.enabled=false` This disables creation of the `LinstorController`\n"
"resource\n"
"* `operator.etcd.enabled=false` Since no LINSTOR controller will run on Kubernetes, no\n"
"database is required.\n"
"* `controllerEndpoint=<url-of-linstor-controller>` The HTTP endpoint of the existing LINSTOR\n"
"controller. For example: `http://linstor.storage.cluster:3370/`\n"
"\n"
"After all pods are ready, you should see the Kubernetes cluster nodes as satellites in your LINSTOR setup.\n"
"\n"
"IMPORTANT: Your Kubernetes nodes must be reachable using their IP by the controller and storage nodes.\n"
"\n"
"Create a storage class referencing an existing storage pool on your storage nodes.\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1504
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
#| "kind: VolumeSnapshot\n"
#| "metadata:\n"
#| "  name: my-first-linstor-snapshot\n"
#| "spec:\n"
#| "  snapshotClassName: my-first-linstor-snapshot-class\n"
#| "  source:\n"
#| "    name: my-first-linstor-volume\n"
#| "    kind: PersistentVolumeClaim\n"
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  name: linstor-on-k8s\n"
"provisioner: linstor.csi.linbit.com\n"
"parameters:\n"
"  autoPlace: \"3\"\n"
"  storagePool: existing-storage-pool\n"
"  resourceGroup: linstor-on-k8s\n"
"----\n"
msgstr ""
"apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: my-first-linstor-snapshot\n"
"spec:\n"
"  snapshotClassName: my-first-linstor-snapshot-class\n"
"  source:\n"
"    name: my-first-linstor-volume\n"
"    kind: PersistentVolumeClaim\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1511
msgid ""
"You can provision new volumes by creating PVCs using your storage class. The "
"volumes will first be placed only on nodes with the given storage pool, that "
"is, your storage infrastructure. Once you want to use the volume in a pod, "
"LINSTOR CSI will create a diskless resource on the Kubernetes node and "
"attach over the network to the diskful resource.  [[s-kubernetes-linstor-"
"interacting]]"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:1511
#, no-wrap
msgid "Interacting with LINSTOR in Kubernetes"
msgstr "在Kubernetes中与LINSTOR互动"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1516
#, fuzzy, no-wrap
#| msgid "The Controller pod includes a LINSTOR Client, making it easy to interact directly with LINSTOR.  For instance:"
msgid ""
"The controller pod includes a LINSTOR Client, making it easy to interact directly with LINSTOR.\n"
"For instance:\n"
"\n"
"----\n"
msgstr "Controller pod包括LINSTOR客户端，使得直接与LINSTOR交互变得容易。例如："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1518
#, fuzzy, no-wrap
#| msgid "kubectl exec linstor-op-cs-controller-0 -- linstor storage-pool list\n"
msgid ""
"kubectl exec deployment/linstor-op-cs-controller -- linstor storage-pool list\n"
"----\n"
msgstr "kubectl exec linstor-op-cs-controller-0 -- linstor storage-pool list\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1521
msgid "[[s-kubernetes-kubectl-linstor-utility]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1521
#, fuzzy, no-wrap
#| msgid "Deploying LINSTOR on Kubernetes"
msgid "Simplifying LINSTOR Client Command Entry"
msgstr "在Kubernetes上部署LINSTOR"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1528
#, no-wrap
msgid ""
"To simplify entering LINSTOR client commands within a Kubernetes deployment, you can use the\n"
"`kubectl-linstor` utility. This utility is available from the upstream Piraeus datastore\n"
"project. To download it, enter the following commands on your Kubernetes control plane node:\n"
"\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1533
#, no-wrap
msgid ""
"# KL_VERS=0.2.1 <1>\n"
"# KL_ARCH=linux-amd64 <2>\n"
"# curl -L -O \\\n"
"https://github.com/piraeusdatastore/kubectl-linstor/releases/download/v$KL_VERS/kubectl-linstor-v$KL_VERS-$KL_ARCH.tar.gz\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1548
#, no-wrap
msgid ""
"<1> Set the shell variable `KL_VERS` to the latest release version of the `kubectl-linstor`\n"
"utility, as shown on the\n"
"https://github.com/piraeusdatastore/kubectl-linstor/releases[`kubectl-linstor` releases page].\n"
"<2> Set the shell variable `KL_ARCH` to the architecture appropriate to your deployment and\n"
"supported by the utility's available releases.\n"
"\n"
"IMPORTANT: If your deployment uses the LINSTOR Operator v2, you must use version 0.2.0 or higher\n"
"of the `kubectl-linstor` utility.\n"
"\n"
"To install the utility, first extract it and then move the extracted executable file to a\n"
"directory in your `$PATH`, for example, `/usr/bin`. Then you can use `kubectl-linstor` to get\n"
"access to the complete LINSTOR CLI.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1558
#, no-wrap
msgid ""
"$ kubectl linstor node list\n"
"╭────────────────────────────────────────────────────────────────────────────────────╮\n"
"┊ Node                           ┊ NodeType   ┊ Addresses                   ┊ State  ┊\n"
"╞════════════════════════════════════════════════════════════════════════════════════╡\n"
"┊ kube-node-01.test              ┊ SATELLITE  ┊ 10.43.224.26:3366 (PLAIN)   ┊ Online ┊\n"
"┊ kube-node-02.test              ┊ SATELLITE  ┊ 10.43.224.27:3366 (PLAIN)   ┊ Online ┊\n"
"┊ kube-node-03.test              ┊ SATELLITE  ┊ 10.43.224.28:3366 (PLAIN)   ┊ Online ┊\n"
"┊ linstor-op-cs-controller-[...] ┊ CONTROLLER ┊ 172.24.116.114:3366 (PLAIN) ┊ Online ┊\n"
"╰────────────────────────────────────────────────────────────────────────────────────╯\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1562
#, no-wrap
msgid ""
"It also expands references to PVCs to the matching LINSTOR resource.\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1572
#, no-wrap
msgid ""
"$ kubectl linstor resource list -r pvc:my-namespace/demo-pvc-1 --all\n"
"pvc:my-namespace/demo-pvc-1 -> pvc-2f982fb4-bc05-4ee5-b15b-688b696c8526\n"
"╭─────────────────────────────────────────────────────────────────────────────────────────────╮\n"
"┊ ResourceName ┊ Node              ┊ Port ┊ Usage  ┊ Conns ┊    State   ┊ CreatedOn           ┊\n"
"╞═════════════════════════════════════════════════════════════════════════════════════════════╡\n"
"┊ pvc-[...]    ┊ kube-node-01.test ┊ 7000 ┊ Unused ┊ Ok    ┊   UpToDate ┊ 2021-02-05 09:16:09 ┊\n"
"┊ pvc-[...]    ┊ kube-node-02.test ┊ 7000 ┊ Unused ┊ Ok    ┊ TieBreaker ┊ 2021-02-05 09:16:08 ┊\n"
"┊ pvc-[...]    ┊ kube-node-03.test ┊ 7000 ┊ InUse  ┊ Ok    ┊   UpToDate ┊ 2021-02-05 09:16:09 ┊\n"
"╰─────────────────────────────────────────────────────────────────────────────────────────────╯\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1581
#, fuzzy
msgid ""
"It also expands references of the form `pod:[<namespace>/]<podname>` into a "
"list resources in use by the pod.  This should only be necessary for "
"investigating problems and accessing advanced functionality.  Regular "
"operation such as creating volumes should be achieved through the <<s-"
"kubernetes-basic-configuration-and-deployment,Kubernetes integration>>.  [[s-"
"kubernetes-basic-configuration-and-deployment]]"
msgstr ""
"这应该只是调研问题和访问高级功能所必需的。常规操作（如创建卷）应通过<<s-"
"kubernetes-basic-configuration-and-deployment,Kubernetes integration>>实现。"

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:1581
#, fuzzy, no-wrap
#| msgid "Deploying LINSTOR on Kubernetes"
msgid "Getting Started with LINBIT SDS Storage in Kubernetes"
msgstr "在Kubernetes上部署LINSTOR"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1595
#, no-wrap
msgid ""
"Once all linstor-csi __Pod__s are up and running, you can provision volumes\n"
"using the usual Kubernetes workflows.\n"
"\n"
"Configuring the behavior and properties of LINSTOR volumes deployed through Kubernetes\n"
"is accomplished using link:https://kubernetes.io/docs/concepts/storage/storage-classes/[Kubernetes __StorageClass__] objects.\n"
"\n"
"IMPORTANT: The `resourceGroup` parameter is mandatory. Usually you want it to be unique and the same as the storage class name.\n"
"\n"
"Here below is the simplest practical _StorageClass_ that can be used to deploy volumes:\n"
"\n"
".linstor-basic-sc.yaml\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1613
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: storage.k8s.io/v1beta1\n"
#| "kind: StorageClass\n"
#| "metadata:\n"
#| "  # The name used to identify this StorageClass.\n"
#| "  name: linstor-basic-storage-class\n"
#| "  # The name used to match this StorageClass with a provisioner.\n"
#| "  # linstor.csi.linbit.com is the name that the LINSTOR CSI plugin uses to identify itself\n"
#| "provisioner: linstor.csi.linbit.com\n"
#| "parameters:\n"
#| "  # LINSTOR will provision volumes from the drbdpool storage pool configured\n"
#| "  # On the satellite nodes in the LINSTOR cluster specified in the plugin's deployment\n"
#| "  storagePool: \"drbdpool\"\n"
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  # The name used to identify this StorageClass.\n"
"  name: linstor-basic-storage-class\n"
"  # The name used to match this StorageClass with a provisioner.\n"
"  # linstor.csi.linbit.com is the name that the LINSTOR CSI plugin uses to identify itself\n"
"provisioner: linstor.csi.linbit.com\n"
"volumeBindingMode: WaitForFirstConsumer\n"
"parameters:\n"
"  # LINSTOR will provision volumes from the drbdpool storage pool configured\n"
"  # On the satellite nodes in the LINSTOR cluster specified in the plugin's deployment\n"
"  storagePool: \"lvm-thin\"\n"
"  resourceGroup: \"linstor-basic-storage-class\"\n"
"  # Setting a fstype is required for \"fsGroup\" permissions to work correctly.\n"
"  # Currently supported: xfs/ext4\n"
"  csi.storage.k8s.io/fstype: xfs\n"
"----\n"
msgstr ""
"apiVersion: storage.k8s.io/v1beta1\n"
"kind: StorageClass\n"
"metadata:\n"
"  # The name used to identify this StorageClass.\n"
"  name: linstor-basic-storage-class\n"
"  # The name used to match this StorageClass with a provisioner.\n"
"  # linstor.csi.linbit.com is the name that the LINSTOR CSI plugin uses to identify itself\n"
"provisioner: linstor.csi.linbit.com\n"
"parameters:\n"
"  # LINSTOR will provision volumes from the drbdpool storage pool configured\n"
"  # On the satellite nodes in the LINSTOR cluster specified in the plugin's deployment\n"
"  storagePool: \"drbdpool\"\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1619
#, no-wrap
msgid ""
"IMPORTANT: The `storagePool` value, `lvm-thin` in the example YAML configuration file above, must match an available LINSTOR _StoragePool_. You can list storage pool information using the `linstor storage-pool list` command, executed within the running `linstor-op-cs-controller` pod, or by using the `kubectl linstor storage-pool list` command if you have installed the <<s-kubernetes-kubectl-linstor-utility,`kubectl-linstor` utility>>.\n"
"\n"
"You can create the storage class with the following command:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1621
#, fuzzy, no-wrap
#| msgid "kubectl create -f linstor-basic-sc.yaml\n"
msgid ""
"kubectl create -f linstor-basic-sc.yaml\n"
"----\n"
msgstr "kubectl create -f linstor-basic-sc.yaml\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1628
#, fuzzy, no-wrap
#| msgid "Now that our _StorageClass_ is created, we can now create a _PersistentVolumeClaim_ which can be used to provision volumes known both to Kubernetes and LINSTOR:"
msgid ""
"Now that your storage class is created, you can now create a persistent volume claim (PVC)\n"
"which can be used to provision volumes known both to Kubernetes and LINSTOR:\n"
"\n"
".my-first-linstor-volume-pvc.yaml\n"
"[source,yaml]\n"
"----\n"
msgstr "现在，我们的存储类已经创建，我们现在可以创建一个 _PersistentVolumeClaim_ ，它可以用来提供Kubernetes和LINSTOR都知道的卷："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1640
#, fuzzy, no-wrap
#| msgid ""
#| "kind: PersistentVolumeClaim\n"
#| "apiVersion: v1\n"
#| "metadata:\n"
#| "  name: my-first-linstor-volume\n"
#| "  annotations:\n"
#| "    # This line matches the PersistentVolumeClaim with our StorageClass\n"
#| "    # and therefore our provisioner.\n"
#| "    volume.beta.kubernetes.io/storage-class: linstor-basic-storage-class\n"
#| "spec:\n"
#| "  accessModes:\n"
#| "    - ReadWriteOnce\n"
#| "  resources:\n"
#| "    requests:\n"
#| "      storage: 500Mi\n"
msgid ""
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: my-first-linstor-volume\n"
"spec:\n"
"  storageClassName: linstor-basic-storage-class\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 500Mi\n"
"----\n"
msgstr ""
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: my-first-linstor-volume\n"
"  annotations:\n"
"    # This line matches the PersistentVolumeClaim with our StorageClass\n"
"    # and therefore our provisioner.\n"
"    volume.beta.kubernetes.io/storage-class: linstor-basic-storage-class\n"
"spec:\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 500Mi\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1644
#, fuzzy, no-wrap
#| msgid "We can create the _PersistentVolumeClaim_ with the following command:"
msgid ""
"You can create the _PersistentVolumeClaim_ with the following command:\n"
"\n"
"----\n"
msgstr "我们可以使用以下命令创建 _PersistentVolumeClaim_ ："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1646
#, fuzzy, no-wrap
#| msgid "kubectl create -f my-first-linstor-volume-pvc.yaml\n"
msgid ""
"kubectl create -f my-first-linstor-volume-pvc.yaml\n"
"----\n"
msgstr "kubectl create -f my-first-linstor-volume-pvc.yaml\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1657
#, no-wrap
msgid ""
"This will create a _PersistentVolumeClaim_, but no volume will be created just yet.\n"
"The storage class we used specified `volumeBindingMode: WaitForFirstConsumer`, which\n"
"means that the volume is only created once a workload starts using it. This ensures\n"
"that the volume is placed on the same node as the workload.\n"
"\n"
"For our example, we create a simple Pod, which mounts or volume by referencing the\n"
"_PersistentVolumeClaim_.\n"
".my-first-linstor-volume-pod.yaml\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1678
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: v1\n"
#| "kind: Pod\n"
#| "metadata:\n"
#| "  name: fedora\n"
#| "  namespace: default\n"
#| "spec:\n"
#| "  containers:\n"
#| "  - name: fedora\n"
#| "    image: fedora\n"
#| "    command: [/bin/bash]\n"
#| "    args: [\"-c\", \"while true; do sleep 10; done\"]\n"
#| "    volumeMounts:\n"
#| "    - name: my-first-linstor-volume\n"
#| "      mountPath: /data\n"
#| "    ports:\n"
#| "    - containerPort: 80\n"
#| "  volumes:\n"
#| "  - name: my-first-linstor-volume\n"
#| "    persistentVolumeClaim:\n"
#| "      claimName: \"my-first-linstor-volume\"\n"
msgid ""
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: fedora\n"
"  namespace: default\n"
"spec:\n"
"  containers:\n"
"  - name: fedora\n"
"    image: fedora\n"
"    command: [/bin/bash]\n"
"    args: [\"-c\", \"while true; do sleep 10; done\"]\n"
"    volumeMounts:\n"
"    - name: my-first-linstor-volume\n"
"      mountPath: /data\n"
"    ports:\n"
"    - containerPort: 80\n"
"  volumes:\n"
"  - name: my-first-linstor-volume\n"
"    persistentVolumeClaim:\n"
"      claimName: \"my-first-linstor-volume\"\n"
"----\n"
msgstr ""
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: fedora\n"
"  namespace: default\n"
"spec:\n"
"  containers:\n"
"  - name: fedora\n"
"    image: fedora\n"
"    command: [/bin/bash]\n"
"    args: [\"-c\", \"while true; do sleep 10; done\"]\n"
"    volumeMounts:\n"
"    - name: my-first-linstor-volume\n"
"      mountPath: /data\n"
"    ports:\n"
"    - containerPort: 80\n"
"  volumes:\n"
"  - name: my-first-linstor-volume\n"
"    persistentVolumeClaim:\n"
"      claimName: \"my-first-linstor-volume\"\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1682
#, fuzzy, no-wrap
#| msgid "We can create the _Pod_ with the following command:"
msgid ""
"You can create the _Pod_ with the following command:\n"
"\n"
"----\n"
msgstr "我们可以使用以下命令创建 _Pod_ ："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1684
#, fuzzy, no-wrap
#| msgid "kubectl create -f my-first-linstor-volume-pod.yaml\n"
msgid ""
"kubectl create -f my-first-linstor-volume-pod.yaml\n"
"----\n"
msgstr "kubectl create -f my-first-linstor-volume-pod.yaml\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1695
#, fuzzy, no-wrap
#| msgid "To remove a volume, please ensure that no pod is using it and then delete the _PersistentVolumeClaim_ via `kubectl`. For example, to remove the volume that we just made, run the following two commands, noting that the _Pod_ must be unscheduled before the _PersistentVolumeClaim_ will be removed:"
msgid ""
"Running `kubectl describe pod fedora` can be used to confirm that _Pod_\n"
"scheduling and volume attachment succeeded. Examining the _PersistentVolumeClaim_,\n"
"we can see that it is now bound to a volume.\n"
"\n"
"To remove a volume, verify that no pod is using it and then delete the\n"
"_PersistentVolumeClaim_ using the `kubectl` command. For example, to remove the volume that we\n"
"just made, run the following two commands, noting that the _Pod_ must be\n"
"unscheduled before the _PersistentVolumeClaim_ will be removed:\n"
"\n"
"----\n"
msgstr "要删除卷，请确保没有pod正在使用它，然后通过 `kubectl` 删除 `PersistentVolumeClaim` 。例如，要删除我们刚刚创建的卷，请运行以下两个命令，注意在删除 _PersistentVolumeClaim_ 之前必须取消调度该 _Pod_ ："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1701
#, fuzzy, no-wrap
#| msgid "kubectl delete pvc my-first-linstor-volume # remove the PersistentVolumeClaim, the PersistentVolume, and the LINSTOR Volume.\n"
msgid ""
"kubectl delete pod fedora # unschedule the pod.\n"
"\n"
"kubectl get pod -w # wait for pod to be unscheduled\n"
"\n"
"kubectl delete pvc my-first-linstor-volume # remove the PersistentVolumeClaim, the PersistentVolume, and the LINSTOR Volume.\n"
"----\n"
msgstr "kubectl delete pvc my-first-linstor-volume # remove the PersistentVolumeClaim, the PersistentVolume, and the LINSTOR Volume.\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1704
msgid "[[s-kubernetes-sc-parameters]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1704
#, fuzzy, no-wrap
#| msgid "Available storage plugins"
msgid "Available Parameters in a Storage Class"
msgstr "可用的存储插件"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1711
#, no-wrap
msgid ""
"The following storage class contains all currently available parameters to configure the provisioned storage.\n"
"\n"
"NOTE: `linstor.csi.linbit.com/` is an optional, but recommended prefix for LINSTOR CSI specific parameters.\n"
"\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1743
#, no-wrap
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  name: full-example\n"
"provisioner: linstor.csi.linbit.com\n"
"parameters:\n"
"  # CSI related parameters\n"
"  csi.storage.k8s.io/fstype: xfs\n"
"  # LINSTOR parameters\n"
"  linstor.csi.linbit.com/autoPlace: \"2\"\n"
"  linstor.csi.linbit.com/placementCount: \"2\"\n"
"  linstor.csi.linbit.com/resourceGroup: \"full-example\"\n"
"  linstor.csi.linbit.com/storagePool: \"my-storage-pool\"\n"
"  linstor.csi.linbit.com/disklessStoragePool: \"DfltDisklessStorPool\"\n"
"  linstor.csi.linbit.com/layerList: \"drbd storage\"\n"
"  linstor.csi.linbit.com/placementPolicy: \"AutoPlaceTopology\"\n"
"  linstor.csi.linbit.com/allowRemoteVolumeAccess: \"true\"\n"
"  linstor.csi.linbit.com/encryption: \"true\"\n"
"  linstor.csi.linbit.com/nodeList: \"diskful-a diskful-b\"\n"
"  linstor.csi.linbit.com/clientList: \"diskless-a diskless-b\"\n"
"  linstor.csi.linbit.com/replicasOnSame: \"zone=a\"\n"
"  linstor.csi.linbit.com/replicasOnDifferent: \"rack\"\n"
"  linstor.csi.linbit.com/disklessOnRemaining: \"false\"\n"
"  linstor.csi.linbit.com/doNotPlaceWithRegex: \"tainted.*\"\n"
"  linstor.csi.linbit.com/fsOpts: \"-E nodiscard\"\n"
"  linstor.csi.linbit.com/mountOpts: \"noatime\"\n"
"  linstor.csi.linbit.com/postMountXfsOpts: \"extsize 2m\"\n"
"  # Linstor properties\n"
"  property.linstor.csi.linbit.com/*: <x>\n"
"  # DRBD parameters\n"
"  DrbdOptions/*: <x>\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1746
msgid "[[s-kubernetes-file-system]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1746
#, no-wrap
msgid "`csi.storage.k8s.io/fstype`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1754
msgid ""
"The `csi.storage.k8s.io/fstype` parameter sets the file system type to "
"create for `volumeMode: FileSystem` PVCs. Currently supported are: * `ext4` "
"(default)  * `xfs` [[s-kubernetes-autoplace]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1754
#, fuzzy, no-wrap
#| msgid "autoPlace"
msgid "`autoPlace`"
msgstr "autoPlace"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1770
msgid ""
"`autoPlace` is an integer that determines the amount of replicas a volume of "
"this _StorageClass_ will have. For instance, `autoPlace: \"3\"` will produce "
"volumes with three-way replication. If neither `autoPlace` nor `nodeList` "
"are set, volumes will be <<s-autoplace-linstor,automatically placed>> on one "
"node.  IMPORTANT: If you use this option, you must not use <<s-kubernetes-"
"nodelist,`nodeList`>>.  IMPORTANT: You have to use quotes, otherwise "
"Kubernetes will complain about a malformed _StorageClass_.  TIP: This option "
"(and all options which affect auto-placement behavior) modifies the number "
"of LINSTOR nodes on which the underlying storage for volumes will be "
"provisioned and is orthogonal to which _kubelets_ those volumes will be "
"accessible from."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1770
#, fuzzy, no-wrap
#| msgid "Manual placement"
msgid "`placementCount`"
msgstr "手动放置"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1774
#, fuzzy
#| msgid ""
#| "If you use this option, you must not use <<s-kubernetes-autoplace,"
#| "autoPlace>>."
msgid "`placementCount` is an alias for <<s-kubernetes-autoplace,`autoPlace`>>"
msgstr "如果使用此选项，则不能使用<<s-kubernetes-autoplace,autoPlace>>。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1774
#, fuzzy, no-wrap
#| msgid "Resource groups"
msgid "`resourceGroup`"
msgstr "资源组"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1780
msgid ""
"The <<s-linstor-resource-groups, LINSTOR Resource Group (RG)>> to associate "
"with this StorageClass. If not set, a new RG will be created for each new "
"PVC.  [[s-kubernetes-storagepool]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1780
#, fuzzy, no-wrap
#| msgid "storagePool"
msgid "`storagePool`"
msgstr "storagePool"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1791
#, fuzzy
#| msgid ""
#| "Only nodes configured with this same _storage pool_ with be considered "
#| "for <<s-kubernetes-autoplace,autoplacement>>. Likewise, for "
#| "_StorageClasses_ using <<s-kubernetes-nodelist,nodeList>> all nodes "
#| "specified in that list must have this _storage pool_ configured on them."
msgid ""
"`storagePool` is the name of the LINSTOR <<s-storage_pools,storage pool>> "
"that will be used to provide storage to the newly-created volumes.  CAUTION: "
"Only nodes configured with this same _storage pool_ with be considered for "
"<<s-kubernetes-autoplace,auto-placement>>. Likewise, for _StorageClasses_ "
"using <<s-kubernetes-nodelist,`nodeList`>> all nodes specified in that list "
"must have this _storage pool_ configured on them.  [[s-kubernetes-"
"disklessstoragepool]]"
msgstr ""
"只有配置了相同 _storage pool_ 的节点才被考虑用于<<s-kubernetes-autoplace,"
"autoplacement>>。同样，对于使用<<s-kubernetes-nodelist,nodeList>>该列表中指定"
"的所有节点，都必须在其上配置此 _storage pool_。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1791
#, fuzzy, no-wrap
#| msgid "disklessStoragePool"
msgid "`disklessStoragePool`"
msgstr "disklessStoragePool"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1797
#, fuzzy
#| msgid ""
#| "`disklessStoragePool` is an optional parameter that only effects LINSTOR "
#| "volumes assigned disklessly to _kubelets_ i.e., as clients. If you have a "
#| "custom _diskless storage pool_ defined in LINSTOR, you'll specify that "
#| "here."
msgid ""
"`disklessStoragePool` is an optional parameter that only affects LINSTOR "
"volumes that are assigned as \"diskless\" to _kubelets_, that is, as "
"clients. If you have a custom diskless storage pool defined in LINSTOR, you "
"will specify that here."
msgstr ""
"`disklessStoragePool` 是一个可选参数，它只影响作为客户端无磁盘分配给 "
"_kubelets_ 的LINSTOR卷。如果在LINSTOR中定义了自定义 _diskless storage pool_，"
"请在此处指定。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1797
#, no-wrap
msgid "`layerList`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1803
msgid ""
"A comma-separated list of layers to use for the created volumes. The "
"available layers and their order are described towards the end of <<s-"
"linstor-without-drbd, this section>>. Defaults to `drbd,storage` [[s-"
"kubernetes-placementpolicy]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1803
#, fuzzy, no-wrap
#| msgid "Manual placement"
msgid "`placementPolicy`"
msgstr "手动放置"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1819
msgid ""
"Select from one of the available volume schedulers: * `AutoPlaceTopology`, "
"the default: Use topology information from Kubernetes together with user "
"provided constraints (see <<s-kubernetes-replicasonsame>> and <<s-kubernetes-"
"replicasondifferent>>).  * `AutoPlace` Use the LINSTOR auto-placement "
"feature, influenced by <<s-kubernetes-replicasonsame>> and <<s-kubernetes-"
"replicasondifferent>> * `FollowTopology`: Use CSI Topology information to "
"place at least one volume in each \"preferred\" zone. Only usable if CSI "
"Topology is enabled.  * `Manual`: Use only the nodes listed in `nodeList` "
"and `clientList`.  * `Balanced`: **EXPERIMENTAL** Place volumes across "
"failure domains, using the least used storage pool on each selected node.  "
"[[s-kubernetes-params-allow-remote-volume-access]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1819
#, no-wrap
msgid "`allowRemoteVolumeAccess`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1832
#, no-wrap
msgid ""
"Control on which nodes a volume is accessible. The value for this option can take two different forms:\n"
"\n"
"- A simple `\"true\"` or `\"false\"` allows access from all nodes, or only those nodes with\n"
"  diskful resources.\n"
"\n"
"- Advanced rules, which allow more granular rules on which nodes can access the volume.\n"
"+\n"
"The current implementation can grant access to the volume for nodes that share the same labels. For example, if you want\n"
"to allow access from all nodes in the same region and zone as a diskful resource, you could use:\n"
"+\n"
"[source,yaml]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1838
#, no-wrap
msgid ""
"parameters:\n"
"  linstor.csi.linbit.com/allowRemoteVolumeAccess: |\n"
"    - fromSame:\n"
"      - topology.kubernetes.io/region\n"
"      - topology.kubernetes.io/zone\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1843
msgid ""
"+ You can specify multiple rules. The rules are additive, a node only need "
"to match one rule to be assignable.  [[s-kubernetes-encryption]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1843
#, fuzzy, no-wrap
#| msgid "encryption"
msgid "`encryption`"
msgstr "encryption"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1850
#, fuzzy
#| msgid ""
#| "`encryption` is an optional parameter that determines whether to encrypt "
#| "volumes. LINSTOR must be <<s-linstor-encrypted-Volumes,configured for "
#| "encryption>> for this to work properly."
msgid ""
"`encryption` is an optional parameter that determines whether to encrypt "
"volumes. LINSTOR must be <<s-linstor-encrypted-volumes,configured for "
"encryption>> for this to work properly.  [[s-kubernetes-nodelist]]"
msgstr ""
"`encryption` 是一个可选参数，用于确定是否加密卷。LINSTOR必须<<s-linstor-"
"encrypted-Volumes,configured for encryption>>才能正常工作。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1850
#, fuzzy, no-wrap
#| msgid "nodeList"
msgid "`nodeList`"
msgstr "节点列表"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1863
#, fuzzy
#| msgid ""
#| "`nodeList` is a list of nodes for volumes to be assigned to. This will "
#| "assign the volume to each node and it will be replicated among all of "
#| "them. This can also be used to select a single node by hostname, but it's "
#| "more flexible to use <<s-kubernetes-replicasonsame,replicasOnSame>> to "
#| "select a single node."
msgid ""
"`nodeList` is a list of nodes for volumes to be assigned to. This will "
"assign the volume to each node and it will be replicated among all of them. "
"This can also be used to select a single node by hostname, but it's more "
"flexible to use <<s-kubernetes-replicasonsame,replicasOnSame>> to select a "
"single node.  IMPORTANT: If you use this option, you must not use <<s-"
"kubernetes-autoplace,`autoPlace`>>.  TIP: This option determines on which "
"LINSTOR nodes the underlying storage for volumes will be provisioned and is "
"orthogonal from which _kubelets_ these volumes will be accessible."
msgstr ""
"`nodeList` 是要分配给卷的节点列表。这将把卷分配给每个节点，并在所有节点之间进"
"行复制。这也可以用于按主机名选择单个节点，但使用<<s-kubernetes-"
"replicasonsame,replicasOnSame>>选择单个节点更灵活。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1863
#, fuzzy, no-wrap
#| msgid "DRBD clients"
msgid "`clientList`"
msgstr "DRBD客户端"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1868
msgid ""
"`clientList` is a list of nodes for diskless volumes to be assigned to. Use "
"in conjunction with <<s-kubernetes-nodelist>>.  [[s-kubernetes-"
"replicasonsame]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1868
#, fuzzy, no-wrap
#| msgid "replicasOnSame"
msgid "`replicasOnSame`"
msgstr "replicasOnSame"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1910
msgid ""
"// These should link to the linstor documentation about node properties, but "
"those // do not exist at the time of this commit.  `replicasOnSame` is a "
"list of `key` or `key=value` items used as auto-placement selection labels "
"when <<s-kubernetes-autoplace,`autoPlace`>> is used to determine where to "
"provision storage. These labels correspond to LINSTOR node properties.  "
"NOTE: The operator periodically synchronizes all labels from Kubernetes "
"Nodes, so you can use them as keys for scheduling constraints.  Let's "
"explore this behavior with examples assuming a LINSTOR cluster such that "
"`node-a` is configured with the following auxiliary property `zone=z1` and "
"`role=backups`, while `node-b` is configured with only `zone=z1`.  If we "
"configure a _StorageClass_ with `autoPlace: \"1\"` and `replicasOnSame: "
"\"zone=z1 role=backups\"`, then all volumes created from that _StorageClass_ "
"will be provisioned on `node-a`, since that is the only node with all of the "
"correct key=value pairs in the LINSTOR cluster. This is the most flexible "
"way to select a single node for provisioning.  IMPORTANT: This guide assumes "
"LINSTOR CSI version 0.10.0 or newer. All properties referenced in "
"`replicasOnSame` and `replicasOnDifferent` are interpreted as auxiliary "
"properties. If you are using an older version of LINSTOR CSI, you need to "
"add the `Aux/` prefix to all property names. So `replicasOnSame: "
"\"zone=z1\"` would be `replicasOnSame: \"Aux/zone=z1\"` Using `Aux/` "
"manually will continue to work on newer LINSTOR CSI versions.  If we "
"configure a _StorageClass_ with `autoPlace: \"1\"` and `replicasOnSame: "
"\"zone=z1\"`, then volumes will be provisioned on either `node-a` or `node-"
"b` as they both have the `zone=z1` aux prop.  If we configure a "
"_StorageClass_ with `autoPlace: \"2\"` and `replicasOnSame: \"zone=z1 "
"role=backups\"`, then provisioning will fail, as there are not two or more "
"nodes that have the appropriate auxiliary properties.  If we configure a "
"_StorageClass_ with `autoPlace: \"2\"` and `replicasOnSame: \"zone=z1\"`, "
"then volumes will be provisioned on both `node-a` and `node-b` as they both "
"have the `zone=z1` aux prop.  You can also use a property key without "
"providing a value to ensure all replicas are placed on nodes with the same "
"property value, with caring about the particular value. Assuming there are 4 "
"nodes, `node-a1` and `node-a2` are configured with `zone=a`. `node-b1` and "
"`node-b2` are configured with `zone=b`. Using `autoPlace: \"2\"` and "
"`replicasOnSame: \"zone\"` will place on either `node-a1` and `node-a2` OR "
"on `node-b1` and `node-b2`.  [[s-kubernetes-replicasondifferent]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1910
#, fuzzy, no-wrap
#| msgid "replicasOnDifferent"
msgid "`replicasOnDifferent`"
msgstr "replicasOnDifferent"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1931
msgid ""
"`replicasOnDifferent` takes a list of properties to consider, same as <<s-"
"kubernetes-replicasonsame,replicasOnSame>>.  There are two modes of using "
"`replicasOnDifferent`: * Preventing volume placement on specific nodes: + If "
"a value is given for the property, the nodes which have that property-value "
"pair assigned will be considered last.  + Example: `replicasOnDifferent: "
"\"no-csi-volumes=true\"` will place no volume on any node with property `no-"
"csi-volumes=true` unless there are not enough other nodes to fulfill the "
"`autoPlace` setting.  * Distribute volumes across nodes with different "
"values for the same key: + If no property value is given, LINSTOR will place "
"the volumes across nodes with different values for that property if "
"possible.  + Example: Assuming there are 4 nodes, `node-a1` and `node-a2` "
"are configured with `zone=a`. `node-b1` and `node-b2` are configured with "
"`zone=b`. Using a _StorageClass_ with `autoPlace: \"2\"` and "
"`replicasOnDifferent: \"zone\"`, LINSTOR will create one replica on either "
"`node-a1` or `node-a2` _and_ one replica on either `node-b1` or `node-b2`."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1931
#, no-wrap
msgid "`disklessOnRemaining`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1935
msgid ""
"Create a diskless resource on _all_ nodes that were not assigned a diskful "
"resource."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1935
#, no-wrap
msgid "`doNotPlaceWithRegex`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1940
msgid ""
"Do not place the resource on a node which has a resource with a name "
"matching the regular expression.  [[s-kubernetes-fsops]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1940
#, fuzzy, no-wrap
#| msgid "fsOpts"
msgid "`fsOpts`"
msgstr "fsOpts"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1948
#, fuzzy
#| msgid ""
#| "`fsOpts` is an optional parameter that passes options to the volume's "
#| "filesystem at creation time."
msgid ""
"`fsOpts` is an optional parameter that passes options to the volume's file "
"system at creation time.  IMPORTANT: These values are specific to your "
"chosen <<s-kubernetes-file-system, file system>>.  [[s-kubernetes-mountops]]"
msgstr "`fsOpts` 是一个可选参数，在创建时将选项传递给卷的文件系统。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1948
#, fuzzy, no-wrap
#| msgid "mountOpts"
msgid "`mountOpts`"
msgstr "mountOpts"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1952
#, fuzzy
#| msgid ""
#| "`mountOpts` is an optional parameter that passes options to the volume's "
#| "filesystem at mount time."
msgid ""
"`mountOpts` is an optional parameter that passes options to the volume's "
"file system at mount time."
msgstr "`mountOpts` 是一个可选参数，在装载时将选项传递给卷的文件系统。"

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1952
#, fuzzy, no-wrap
#| msgid "mountOpts"
msgid "`postMountXfsOpts`"
msgstr "mountOpts"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1957
msgid ""
"Extra arguments to pass to `xfs_io`, which gets called before right before "
"first use of the volume.  [[s-kubernetes-storage-class-properties]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1957
#, no-wrap
msgid "`property.linstor.csi.linbit.com/*`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1964
#, no-wrap
msgid ""
"Parameters starting with `property.linstor.csi.linbit.com/` are translated to LINSTOR properties that are set on the\n"
"<<s-linstor-resource-groups,Resource Group>> associated with the StorageClass.\n"
"\n"
"For example, to set `DrbdOptions/auto-quorum` to `disabled`, use:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1966
#, no-wrap
msgid ""
"property.linstor.csi.linbit.com/DrbdOptions/auto-quorum: disabled\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1970
msgid ""
"The full list of options is available https://app.swaggerhub.com/apis-docs/"
"Linstor/Linstor/1.7.0#/developers/resourceDefinitionModify[here]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1970
#, no-wrap
msgid "`DrbdOptions/*: <x>`"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1978
msgid ""
"NOTE: This option is deprecated, use the more general <<s-kubernetes-storage-"
"class-properties, `property.linstor.csi.linbit.com/*`>> form.  Advanced DRBD "
"options to pass to LINSTOR. For example, to change the replication protocol, "
"use `DrbdOptions/Net/protocol: \"A\"`.  [[s-kubernetes-snapshots]]"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:1978
#, no-wrap
msgid "Snapshots"
msgstr "快照"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1987
msgid ""
"Snapshots create a copy of the volume content at a particular point in time. "
"This copy remains untouched when you make modifications to the volume "
"content. This, for example, enables you to create backups of your data "
"before performing modifications or deletions on your data.  Because a backup "
"is useless unless you have a way to restore it, this section describes how "
"to create a snapshot, and how to restore it, for example, in the case of "
"accidental deletion of your data.  The next subsection contains instructions "
"around snapshots within Operator v2 deployments. If you have deployed LINBIT "
"SDS in Kubernetes by using Operator v1, skip ahead to the <<s-kubernetes-add-"
"snaphot-support-v1>> subsection.  [[s-kubernetes-snapshots]]"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:1987
#, fuzzy, no-wrap
#| msgid "Restoring a snapshot"
msgid "Working With Snapshots"
msgstr "还原快照"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:1998
#, no-wrap
msgid ""
"Before you can add snapshot support within a LINBIT SDS deployment, you need to meet the following environment prerequisites:\n"
"\n"
"- Your cluster has a storage pool supporting snapshots. LINSTOR supports snapshots for `LVM_THIN`, `FILE_THIN`, `ZFS` and `ZFS_THIN` pools.\n"
"\n"
"- You have a `StorageClass`, `PersistentVolumeClaim`, and `Deployment` that uses a storage pool\n"
"  that supports snapshots.\n"
"\n"
"- Your cluster has a CSI snapshotter (link:https://github.com/kubernetes-csi/external-snapshotter/[`snapshot-controller`]) deployed. To verify if it is already deployed, you can enter the following command:\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2000
#, no-wrap
msgid ""
"$ kubectl api-resources --api-group=snapshot.storage.k8s.io -oname\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2004
#, no-wrap
msgid ""
"+\n"
"Output should be similar to the following if a snapshot controller is already deployed:\n"
"+\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2008
#, no-wrap
msgid ""
"volumesnapshotclasses.snapshot.storage.k8s.io\n"
"volumesnapshotcontents.snapshot.storage.k8s.io\n"
"volumesnapshots.snapshot.storage.k8s.io\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2013
#, no-wrap
msgid ""
"+\n"
"If output from the command is empty, you can deploy a snapshot controller by entering the following commands:\n"
"+\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2016
#, no-wrap
msgid ""
"$ kubectl apply -k https://github.com/kubernetes-csi/external-snapshotter//client/config/crd\n"
"$ kubectl apply -k https://github.com/kubernetes-csi/external-snapshotter//deploy/kubernetes/snapshot-controller\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2019
msgid "[[s-kubernetes-snapshot-creating]]"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2025
#, no-wrap
msgid ""
"To create a volume snapshot, you first need to create a volume snapshot class (link:https://kubernetes.io/docs/concepts/storage/volume-snapshot-classes/[`VolumeSnapshotClass`]). This volume snapshot class will specify the `linstor.csi.linbit.com` provisioner, and sets the clean-up policy for the snapshots to `Delete`. This means that deleting the Kubernetes resources will also delete the snapshots in LINSTOR.\n"
"\n"
"You can create a volume snapshot class by entering the following command:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2034
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
#| "kind: VolumeSnapshot\n"
#| "metadata:\n"
#| "  name: my-first-linstor-snapshot\n"
#| "spec:\n"
#| "  snapshotClassName: my-first-linstor-snapshot-class\n"
#| "  source:\n"
#| "    name: my-first-linstor-volume\n"
#| "    kind: PersistentVolumeClaim\n"
msgid ""
"$ kubectl apply -f - <<EOF\n"
"apiVersion: snapshot.storage.k8s.io/v1\n"
"kind: VolumeSnapshotClass\n"
"metadata:\n"
"  name: linbit-sds-snapshots\n"
"driver: linstor.csi.linbit.com\n"
"deletionPolicy: Delete\n"
"EOF\n"
"----\n"
msgstr ""
"apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: my-first-linstor-snapshot\n"
"spec:\n"
"  snapshotClassName: my-first-linstor-snapshot-class\n"
"  source:\n"
"    name: my-first-linstor-volume\n"
"    kind: PersistentVolumeClaim\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2038
#, no-wrap
msgid ""
"To create a snapshot, you create a link:https://kubernetes.io/docs/concepts/storage/volume-snapshots/#volumesnapshots[`VolumeSnapshot`] resource. The `VolumeSnapshot` resource needs to reference a snapshot-compatible `PersistentVolumeClaim` resource, and the `VolumeSnapshotClass` that you just created. For example, you could create a snapshot (named `data-volume-snapshot-1`) of a PVC named `data-volume` by entering the following command:\n"
"\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2049
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
#| "kind: VolumeSnapshot\n"
#| "metadata:\n"
#| "  name: my-first-linstor-snapshot\n"
#| "spec:\n"
#| "  snapshotClassName: my-first-linstor-snapshot-class\n"
#| "  source:\n"
#| "    name: my-first-linstor-volume\n"
#| "    kind: PersistentVolumeClaim\n"
msgid ""
"$ kubectl apply -f - <<EOF\n"
"apiVersion: snapshot.storage.k8s.io/v1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: data-volume-snapshot-1\n"
"spec:\n"
"  volumeSnapshotClassName: linbit-sds-snapshots\n"
"  source:\n"
"    persistentVolumeClaimName: data-volume\n"
"EOF\n"
"----\n"
msgstr ""
"apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: my-first-linstor-snapshot\n"
"spec:\n"
"  snapshotClassName: my-first-linstor-snapshot-class\n"
"  source:\n"
"    name: my-first-linstor-volume\n"
"    kind: PersistentVolumeClaim\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2052
msgid "[[s-kubernetes-snapshot-verifying-creation]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2052
#, fuzzy, no-wrap
#| msgid "Reconfiguring resources"
msgid "Verifying Snapshot Creation"
msgstr "重新配置资源"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2056
#, fuzzy, no-wrap
#| msgid "To enter the master passphrase (after controller restart) use the following command:"
msgid ""
"You can verify the creation of a snapshot by entering the following commands:\n"
"\n"
"----\n"
msgstr "要输入主密码（在controller重新启动后），请使用以下命令："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2060
#, no-wrap
msgid ""
"$ kubectl wait volumesnapshot --for=jsonpath='{.status.readyToUse}'=true data-volume-snapshot-1\n"
"volumesnapshot.snapshot.storage.k8s.io/data-volume-snapshot-1 condition met\n"
"$ kubectl get volumesnapshot data-volume-snapshot-1\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2065
#, no-wrap
msgid ""
"Output should show a table of information about the volume snapshot resource, similar to the following:\n"
"\n"
"[%autofit]\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2068
#, no-wrap
msgid ""
"NAME                     READYTOUSE   SOURCEPVC     SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS\n"
"data-volume-snapshot-1   true         data-volume                           1Gi           linbit-sds-snapshots\n"
"----\n"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2072
#, fuzzy, no-wrap
#| msgid "To enter the master passphrase (after controller restart) use the following command:"
msgid ""
"You can further verify the snapshot in LINSTOR, by entering the following command:\n"
"\n"
"----\n"
msgstr "要输入主密码（在controller重新启动后），请使用以下命令："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2074
#, fuzzy, no-wrap
#| msgid "kubectl exec linstor-op-cs-controller-0 -- linstor storage-pool list\n"
msgid ""
"$ kubectl -n linbit-sds exec deploy/linstor-controller -- linstor snapshot list\n"
"----\n"
msgstr "kubectl exec linstor-op-cs-controller-0 -- linstor storage-pool list\n"

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2078
#, fuzzy, no-wrap
#| msgid "``drbdsetup``'s status output should now contain information similar to the following:"
msgid ""
"Output should show a table similar to the following:\n"
"\n"
"----\n"
msgstr "``drbdsetup`` 的状态输出现在应该包含类似于以下内容的信息："

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2081
#, no-wrap
msgid ""
"+-----------------------------------------------------------------------------------------+\n"
"| ResourceName | SnapshotName   | NodeNames | Volumes  | CreatedOn           | State      |\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2084
#, no-wrap
msgid ""
"| pvc-[...]    | snapshot-[...] | kube-0    | 0: 1 GiB | 2023-02-13 15:36:18 | Successful |\n"
"+-----------------------------------------------------------------------------------------+\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2087
#, no-wrap
msgid "[[s-kubernetes-snapshots-restoring]]\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2090
msgid ""
"To restore a snapshot, you will need to create a new PVC to recover the "
"volume snapshot to. You will replace the existing PVC, named `data-volume` "
"in this example, with a new version based on the snapshot."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2092
msgid ""
"First, stop the deployment that uses the `data-volume` PVC. In this example, "
"the deployment is named `volume-logger`."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2098
msgid ""
"$ kubectl scale deploy/volume-logger --replicas=0 deployment.apps \"volume-"
"logger\" deleted $ kubectl rollout status deploy/volume-logger deployment "
"\"volume-logger\" successfully rolled out"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2101
#, no-wrap
msgid "Next, remove the PVC. You still have the snapshot resource, so this is a safe operation.\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2105
msgid ""
"$ kubectl delete pvc/data-volume persistentvolumeclaim \"data-volume\" "
"deleted"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2108
#, no-wrap
msgid "Next, create a new PVC by referencing a previously created snapshot. This will create a volume which uses the data from the referenced snapshot.\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2125
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: v1\n"
#| "kind: PersistentVolumeClaim\n"
#| "metadata:\n"
#| "  name: my-first-linstor-volume-from-snapshot\n"
#| "spec:\n"
#| "  storageClassName: linstor-basic-storage-class\n"
#| "  dataSource:\n"
#| "    name: my-first-linstor-snapshot\n"
#| "    kind: VolumeSnapshot\n"
#| "    apiGroup: snapshot.storage.k8s.io\n"
#| "  accessModes:\n"
#| "    - ReadWriteOnce\n"
#| "  resources:\n"
#| "    requests:\n"
#| "      storage: 500Mi\n"
msgid ""
"kubectl apply -f - <<EOF\n"
"apiVersion: v1\n"
"kind: PersistentVolumeClaim\n"
"metadata:\n"
"  name: data-volume\n"
"spec:\n"
"  storageClassName: linbit-sds-storage\n"
"  resources:\n"
"    requests:\n"
"      storage: 1Gi\n"
"  dataSource:\n"
"    apiGroup: snapshot.storage.k8s.io\n"
"    kind: VolumeSnapshot\n"
"    name: data-volume-snapshot-1\n"
"  accessModes:\n"
msgstr ""
"apiVersion: v1\n"
"kind: PersistentVolumeClaim\n"
"metadata:\n"
"  name: my-first-linstor-volume-from-snapshot\n"
"spec:\n"
"  storageClassName: linstor-basic-storage-class\n"
"  dataSource:\n"
"    name: my-first-linstor-snapshot\n"
"    kind: VolumeSnapshot\n"
"    apiGroup: snapshot.storage.k8s.io\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 500Mi\n"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2127
#, no-wrap
msgid ""
"ReadWriteOnce\n"
"EOF\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2130
#, no-wrap
msgid "Because you named the new volume, `data-volume`, the same as the previous volume, you can just scale up the `Deployment` again, and the new pod will start using the restored volume.\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2134
msgid ""
"$ kubectl scale deploy/volume-logger --replicas=1 deployment.apps/volume-"
"logger scaled"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2136
#, no-wrap
msgid "Storing Snapshots on S3 Storage"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2140
msgid ""
"LINSTOR can store snapshots on S3 compatible storage for disaster recovery. "
"This is integrated in Kubernetes using a special VolumeSnapshotClass:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2142 UG9/en/linstor-kubernetes.adoc:2417
#, fuzzy
#| msgid "Resource name"
msgid "[source,yaml]"
msgstr "资源名称"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2162
#, no-wrap
msgid ""
"kind: VolumeSnapshotClass\n"
"apiVersion: snapshot.storage.k8s.io/v1\n"
"metadata:\n"
"  name: linstor-csi-snapshot-class-s3\n"
"driver: linstor.csi.linbit.com\n"
"deletionPolicy: Retain\n"
"parameters:\n"
"  snap.linstor.csi.linbit.com/type: S3\n"
"  snap.linstor.csi.linbit.com/remote-name: backup-remote\n"
"  snap.linstor.csi.linbit.com/allow-incremental: \"false\"\n"
"  snap.linstor.csi.linbit.com/s3-bucket: snapshot-bucket\n"
"  snap.linstor.csi.linbit.com/s3-endpoint: s3.us-west-1.amazonaws.com\n"
"  snap.linstor.csi.linbit.com/s3-signing-region: us-west-1\n"
"  snap.linstor.csi.linbit.com/s3-use-path-style: \"false\"\n"
"  # Refer here to the secret that holds access and secret key for the S3 endpoint.\n"
"  # See below for an example.\n"
"  csi.storage.k8s.io/snapshotter-secret-name: linstor-csi-s3-access\n"
"  csi.storage.k8s.io/snapshotter-secret-namespace: storage\n"
"---\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2173
#, no-wrap
msgid ""
"kind: Secret\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: linstor-csi-s3-access\n"
"  namespace: storage\n"
"immutable: true\n"
"type: linstor.csi.linbit.com/s3-credentials.v1\n"
"stringData:\n"
"  access-key: access-key\n"
"  secret-key: secret-key\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2178
#, no-wrap
msgid ""
"Check <<s-shipping_snapshots-linstor, the LINSTOR snapshot guide>> on the exact meaning of the\n"
"`snap.linstor.csi.linbit.com/` parameters. The credentials used to log in are stored in a separate secret, as show in\n"
"the example above.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2181
#, no-wrap
msgid ""
"Referencing the above storage class when creating snapshots causes the snapshots to be automatically uploaded to the\n"
"configured S3 storage.\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2182
#, fuzzy, no-wrap
#| msgid "Restoring a snapshot"
msgid "Restoring From Remote Snapshots"
msgstr "还原快照"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2186
msgid ""
"Restoring from remote snapshots is an important step in disaster recovery. A "
"snapshot needs to be registered with Kubernetes before it can be used to "
"restore."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2188
msgid ""
"If the snapshot that should be restored is part of a backup to S3, the "
"LINSTOR \"remote\" needs to be configured first."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2193
#, no-wrap
msgid ""
"linstor remote create s3 backup-remote s3.us-west-1.amazonaws.com \\\n"
"  snapshot-bucket us-west-1 access-key secret-key\n"
"linstor backup list backup-remote\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2196
#, no-wrap
msgid "The snapshot you want to register needs to be one of the listed snapshots.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2199
#, no-wrap
msgid ""
"To register the snapshot with Kubernetes, you need to create two resources, one VolumeSnapshotContent referencing the\n"
"ID of the snapshot and one VolumeSnapshot, referencing the content.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2201
#, no-wrap
msgid "[source,yaml]\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2212
#, fuzzy, no-wrap
#| msgid ""
#| "apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
#| "kind: VolumeSnapshot\n"
#| "metadata:\n"
#| "  name: my-first-linstor-snapshot\n"
#| "spec:\n"
#| "  snapshotClassName: my-first-linstor-snapshot-class\n"
#| "  source:\n"
#| "    name: my-first-linstor-volume\n"
#| "    kind: PersistentVolumeClaim\n"
msgid ""
"apiVersion: snapshot.storage.k8s.io/v1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: example-backup-from-s3\n"
"  namespace: project\n"
"spec:\n"
"  source:\n"
"    volumeSnapshotContentName: restored-snap-content-from-s3\n"
"  volumeSnapshotClassName: linstor-csi-snapshot-class-s3\n"
"---\n"
msgstr ""
"apiVersion: snapshot.storage.k8s.io/v1alpha1\n"
"kind: VolumeSnapshot\n"
"metadata:\n"
"  name: my-first-linstor-snapshot\n"
"spec:\n"
"  snapshotClassName: my-first-linstor-snapshot-class\n"
"  source:\n"
"    name: my-first-linstor-volume\n"
"    kind: PersistentVolumeClaim\n"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2228
#, no-wrap
msgid ""
"apiVersion: snapshot.storage.k8s.io/v1\n"
"kind: VolumeSnapshotContent\n"
"metadata:\n"
"  name: restored-snap-content-from-s3\n"
"spec:\n"
"  deletionPolicy: Delete\n"
"  driver: linstor.csi.linbit.com\n"
"  source:\n"
"    snapshotHandle: snapshot-id\n"
"  volumeSnapshotClassName: linstor-csi-snapshot-class-s3\n"
"  volumeSnapshotRef:\n"
"    apiVersion: snapshot.storage.k8s.io/v1\n"
"    kind: VolumeSnapshot\n"
"    name: example-backup-from-s3\n"
"    namespace: project\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2232
#, no-wrap
msgid ""
"Once applied, the VolumeSnapshot should be shown as `ready`, at which point you can reference it as a `dataSource` in a\n"
"PVC.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2234
#, fuzzy, no-wrap
#| msgid "Volume Accessibility"
msgid "[[s-kubernetes-volume-accessibility-and-locality]]\n"
msgstr "卷可访问性"

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2234
#, fuzzy, no-wrap
#| msgid "Volume Accessibility"
msgid "Volume Accessibility and Locality"
msgstr "卷可访问性"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2240
msgid ""
"// This only covers DRBD volumes, section might change if linked docs are "
"updated.  LINSTOR volumes are typically accessible both locally and <<s-"
"drbd_clients,over the network>>. The CSI driver will ensure that the volume "
"is accessible on whatever node was selected for the consumer. The driver "
"also provides options to ensure volume locality (the consumer is placed on "
"the same node as the backing data) and restrict accessibility (only a subset "
"of nodes can access the volume over the network)."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2245
msgid ""
"Volume locality is achieved by setting `volumeBindingMode: "
"WaitForFirstConsumer` in the storage class. This tell Kubernetes and the CSI "
"driver to wait until the first consumer (Pod) referencing the PVC is "
"scheduled. The CSI driver then provisions the volume with backing data on "
"the same node as the consumer. In case a node without appropriate storage "
"pool was selected, a replacement node in the set of accessible nodes is "
"chosen (see below)."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2250
msgid ""
"Volume accessibility is controlled by the <<s-kubernetes-params-allow-remote-"
"volume-access,`allowRemoteVolumeAccess` parameter>>. Whenever the CSI plugin "
"needs to place a volume, this parameter is consulted to get the set of "
"\"accessible\" nodes. This means they can share volumes placed on them "
"through the network. This information is also propagated to Kubernetes using "
"label selectors on the PV."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2251
#, fuzzy, no-wrap
#| msgid "Volume Accessibility"
msgid "Volume Accessibility and Locality Examples"
msgstr "卷可访问性"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2255
msgid ""
"The following example show common scenarios where you want to optimize "
"volume accessibility and locality. It also includes examples of how to "
"spread volume replicas across zones in a cluster."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2256
#, no-wrap
msgid "Single-Zone Homogeneous Clusters"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2260
msgid ""
"The cluster only spans a single zone, so latency between nodes is low. The "
"cluster is homogeneous, that is, all nodes are configured similarly. All "
"nodes have their own local storage pool."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2263 UG9/en/linstor-kubernetes.adoc:2295
#: UG9/en/linstor-kubernetes.adoc:2329 UG9/en/linstor-kubernetes.adoc:2364
msgid ".example-storage-class.yaml [source,yaml]"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2274
#, no-wrap
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  name: linstor-storage\n"
"provisioner: linstor.csi.linbit.com\n"
"volumeBindingMode: WaitForFirstConsumer <1>\n"
"parameters:\n"
"  linstor.csi.linbit.com/storagePool: linstor-pool <2>\n"
"  linstor.csi.linbit.com/placementCount: \"2\" <3>\n"
"  linstor.csi.linbit.com/allowRemoteVolumeAccess: \"true\" <4>\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2278 UG9/en/linstor-kubernetes.adoc:2313
#: UG9/en/linstor-kubernetes.adoc:2347
#, no-wrap
msgid ""
"<1> Enable late volume binding. This places one replica on the same node as the first\n"
"consuming pod, if possible.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2280 UG9/en/linstor-kubernetes.adoc:2315
#: UG9/en/linstor-kubernetes.adoc:2349
#, fuzzy, no-wrap
#| msgid "To list your storage-pools you can use:"
msgid "<2> Set the storage pool(s) to use.\n"
msgstr "要列出您可以使用的存储池，请执行以下操作："

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2282 UG9/en/linstor-kubernetes.adoc:2317
#: UG9/en/linstor-kubernetes.adoc:2351
#, no-wrap
msgid "<3> Ensure that the data is replicated, so that at least 2 nodes store the data.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2285
#, no-wrap
msgid ""
"<4> Allow using the volume even on nodes without replica. Since all nodes are connected\n"
"equally, performance impact should be manageable.\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2286
#, no-wrap
msgid "Multi-Zonal Homogeneous Clusters"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2292
msgid ""
"As before, in our homogeneous cluster all nodes are configured similarly "
"with their own local storage pool. The cluster spans now multiple zones, "
"with increased latency across nodes in different zones. To ensure low "
"latency, we want to restrict access to the volume with a local replica to "
"only those zones that do have a replica. At the same time, we want to spread "
"our data across multiple zones."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2306 UG9/en/linstor-kubernetes.adoc:2340
#, no-wrap
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  name: linstor-storage\n"
"provisioner: linstor.csi.linbit.com\n"
"volumeBindingMode: WaitForFirstConsumer <1>\n"
"parameters:\n"
"  linstor.csi.linbit.com/storagePool: linstor-pool <2>\n"
"  linstor.csi.linbit.com/placementCount: \"2\" <3>\n"
"  linstor.csi.linbit.com/allowRemoteVolumeAccess: | <4>\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2307 UG9/en/linstor-kubernetes.adoc:2341
#, no-wrap
msgid "fromSame:\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2308 UG9/en/linstor-kubernetes.adoc:2342
#, no-wrap
msgid "topology.kubernetes.io/zone\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2309
#, no-wrap
msgid "linstor.csi.linbit.com/replicasOnDifferent: topology.kubernetes.io/zone <5>\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2320 UG9/en/linstor-kubernetes.adoc:2354
#, no-wrap
msgid ""
"<4> Allow using the volume on nodes in the same zone as a replica, under the assumption that\n"
"zone internal networking is fast and low latency.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2322
#, no-wrap
msgid "<5> Spread the replicas across different zones.\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2323
#, no-wrap
msgid "Multi-Region Clusters"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2326
msgid ""
"If your cluster spans multiple regions, you do not want to incur the latency "
"penalty to replicate your data across regions. To accomplish this, you can "
"configure your storage class to just replicate data in the same zone."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2343
#, no-wrap
msgid "linstor.csi.linbit.com/replicasOnSame: topology.kubernetes.io/region <5>\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2356
#, no-wrap
msgid "<5> Restrict replicas to only a single region.\n"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2357
#, no-wrap
msgid "Cluster with External Storage"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2361
msgid ""
"Our cluster now only consists of compute nodes without local storage. Any "
"volume access has to occur through remote volume access."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2374
#, no-wrap
msgid ""
"apiVersion: storage.k8s.io/v1\n"
"kind: StorageClass\n"
"metadata:\n"
"  name: linstor-storage\n"
"provisioner: linstor.csi.linbit.com\n"
"parameters:\n"
"  linstor.csi.linbit.com/storagePool: linstor-pool <1>\n"
"  linstor.csi.linbit.com/placementCount: \"1\" <2>\n"
"  linstor.csi.linbit.com/allowRemoteVolumeAccess: \"true\" <3>\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2377
#, fuzzy, no-wrap
#| msgid "To list your storage-pools you can use:"
msgid "<1> Set the storage pool(s) to use.\n"
msgstr "要列出您可以使用的存储池，请执行以下操作："

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2380
#, no-wrap
msgid ""
"<2> Assuming we only have one storage host, we can only place a single volume without\n"
"additional replicas.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2382
#, no-wrap
msgid "<3> Our worker nodes need to be allowed to connect to the external storage host.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2384
#, no-wrap
msgid "[[s-kubernetes-affinity-controller]]\n"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2384
#, no-wrap
msgid "LINSTOR Affinity Controller"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2388
msgid ""
"Volume Accessibility is controlled by the https://kubernetes.io/docs/"
"concepts/scheduling-eviction/assign-pod-node/#node-affinity[node affinity] "
"of the PersistentVolume (PV). This affinity is static, that is once defined "
"it cannot be changed."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2392
msgid ""
"This can be an issue if you want to use a strict affinity: Your PV is pinned "
"to specific nodes, but you might want to remove or add nodes. While LINSTOR "
"can move the volume (for example: this happens automatically if you remove a "
"node in Kubernetes), the PV affinity is not updated to reflect this."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2395
msgid ""
"This is where the LINSTOR Affinity Controller comes in: it watches PVs and "
"compares their affinity with the volumes' states in LINSTOR. If they go out "
"of sync, the PV is replaced with an updated version."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2398
msgid ""
"The LINSTOR Affinity Controller is packaged in a Helm chart. If you install "
"it in the same namespace as the Operator, simply run:"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2402
#, fuzzy
#| msgid ""
#| "# zypper install linstor-controller linstor-satellite  linstor-client\n"
msgid ""
"$ helm repo update $ helm install linstor-affinity-controller linstor/"
"linstor-affinity-controller"
msgstr ""
"# zypper install linstor-controller linstor-satellite  linstor-client\n"

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2405
#, no-wrap
msgid "Additional options for the chart are available at the https://github.com/piraeusdatastore/linstor-affinity-controller[upstream project].\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2407
#, no-wrap
msgid "[[s-kubernetes-scheduler]]\n"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2407
#, no-wrap
msgid "Volume Locality Optimization Using LINSTOR Scheduler"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2412
msgid ""
"LINBIT maintains an open source plugin for the Kubernetes scheduler. The "
"scheduler will take the current placement of volumes into account and "
"optimize for data locality. If possible, the pod will be assigned to a node "
"that also hosts replicas of attached volumes, reducing latency for read "
"operations."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2415
msgid ""
"The scheduler is available as a separate chart https://artifacthub.io/"
"packages/helm/piraeus-charts/linstor-scheduler[from artifacthub.io].  The "
"chart will deploy a new scheduler, which you can later use when creating pod "
"resources:"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2425
#, no-wrap
msgid ""
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: busybox\n"
"spec:\n"
"  schedulerName: linstor-scheduler <1>\n"
"  containers:\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2429
#, no-wrap
msgid ""
"name: busybox\n"
"image: busybox\n"
"command: [\"tail\", \"-f\", \"/dev/null\"]\n"
"volumeMounts:\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2431
#, fuzzy, no-wrap
#| msgid "my-first-linstor-volume-pod.yaml"
msgid ""
"name: my-first-linstor-volume\n"
"mountPath: /data\n"
msgstr "my-first-linstor-volume-pod.yaml"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2432
#, no-wrap
msgid "ports:\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2433
#, no-wrap
msgid "containerPort: 80\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2434
#, fuzzy, no-wrap
#| msgid "Volumes"
msgid "volumes:\n"
msgstr "卷"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2436
#, fuzzy, no-wrap
#| msgid "my-first-linstor-volume-pod.yaml"
msgid ""
"name: my-first-linstor-volume\n"
"persistentVolumeClaim:\n"
msgstr "my-first-linstor-volume-pod.yaml"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2437
#, no-wrap
msgid "claimName: \"test-volume\"\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2440
#, no-wrap
msgid "<1> Add the name of the scheduler to your pod.\n"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2442
#, no-wrap
msgid "[[s-kubernetes-drbd-module-loader-configuring-v2]]\n"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2442
#, no-wrap
msgid "Configuring the DRBD Module Loader in Operator v2 Deployments"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2444
msgid ""
"// https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/how-to/"
"drbd-loader.md"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2448
msgid ""
"NOTE: To follow the steps in this section, you should be familiar with "
"editing link:https://github.com/piraeusdatastore/piraeus-operator/blob/v2/"
"docs/reference/linstorsatelliteconfiguration."
"md#linstorsatelliteconfiguration[`LinstorSatelliteConfiguration`] resources."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2453
msgid ""
"The DRBD module loader is the component responsible for making the DRBD "
"kernel module available, in addition to loading other useful kernel modules "
"for LINBIT SDS in Kubernetes. This section describes how you can configure "
"various aspects of the DRBD kernel module loader, within a LINSTOR Operator "
"v2 deployment."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2455
msgid ""
"Besides the DRBD kernel module, these modules are also loaded if available:"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2468
#, no-wrap
msgid ""
"[cols=\"1,1\"]\n"
"|Module | Purpose\n"
"\n"
"| `libcrc32c` | dependency for DRBD\n"
"| `nvmet_rdma`, `nvme_rdma` | LINSTOR NVME layer\n"
"| `loop` | LINSTOR when using loop devices as backing disks\n"
"| `dm_writecache` | LINSTOR writecache layer\n"
"| `dm_cache` | LINSTOR cache layer\n"
"| `dm_thin_pool` | LINSTOR thin-provisioned storage\n"
"| `dm_snapshot` | LINSTOR Snapshots\n"
"| `dm_crypt` | LINSTOR encrypted volumes\n"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2471
#, fuzzy, no-wrap
#| msgid "Loading the new Kernel module"
msgid "Disabling the DRBD Module Loader"
msgstr "加载新的内核模块"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2477
msgid ""
"In some circumstances it might be necessary to disable the DRBD module "
"loader entirely. For example, if you are using an immutable operating "
"system, and DRBD and other modules are loaded as part of the host "
"configuration."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2479
msgid ""
"To disable the DRBD module loader completely, apply the following YAML "
"configuration to your deployment:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2499
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: no-loader\n"
"spec:\n"
"  patches:\n"
"    - target:\n"
"        kind: Pod\n"
"        name: satellite\n"
"      patch: |\n"
"        apiVersion: v1\n"
"        kind: Pod\n"
"        metadata:\n"
"          name: satellite\n"
"        spec:\n"
"          initContainers:\n"
"          - name: drbd-module-loader\n"
"            $patch: delete\n"
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2502
#, no-wrap
msgid "Selecting a Different DRBD Module Loader Version"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2505
msgid ""
"By default, the Operator will try to find a DRBD module loader that matches "
"the host operating system. The Operator determines the host distribution by "
"inspecting the `.status.nodeInfo.osImage` field of the Kubernetes `Node` "
"resource. A user-defined image can be used if the automatic mapping does not "
"succeed or if you have different module loading requirements."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2507
msgid ""
"The following YAML configuration overrides the chosen DRBD module loader "
"image with a user-defined image `example.com/drbd-loader:v9`:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2527
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: custom-drbd-module-loader-image\n"
"spec:\n"
"  patches:\n"
"    - target:\n"
"        kind: Pod\n"
"        name: satellite\n"
"      patch: |\n"
"        apiVersion: v1\n"
"        kind: Pod\n"
"        metadata:\n"
"          name: satellite\n"
"        spec:\n"
"          initContainers:\n"
"          - name: drbd-module-loader\n"
"            image: example.com/drbd-loader:v9\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2530
msgid ""
"`drbd.io`, available to LINBIT customers only, maintains the following "
"module loader container images:"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2542
#, no-wrap
msgid ""
"| Image | Distribution\n"
"\n"
"| `drbd.io/drbd9-amzn2:v9.2.5` | Amazon Linux 2\n"
"| `drbd.io/drbd9-bionic:v9.2.5` | Ubuntu 18.04\n"
"| `drbd.io/drbd9-focal:v9.2.5` | Ubuntu 20.04\n"
"| `drbd.io/drbd9-jammy:v9.2.5` | Ubuntu 22.04\n"
"| `drbd.io/drbd9-rhel7:v9.2.5` | Red Hat Enterprise Linux 7\n"
"| `drbd.io/drbd9-rhel8:v9.2.5` | Red Hat Enterprise Linux 8\n"
"| `drbd.io/drbd9-rhel9:v9.2.5` | Red Hat Enterprise Linux 9\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2545
msgid ""
"If you need to create a module loader image for your own distribution, you "
"can refer to link:https://github.com/piraeusdatastore/piraeus/tree/master/"
"dockerfiles/drbd-driver-loader[the container source files] which are "
"available in the upstream Piraeus project."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2547
#, no-wrap
msgid "Changing How the Module Loader Loads the DRBD Kernel Module"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2550
msgid ""
"By default, the DRBD module loader will try to build the kernel module from "
"source. The module loader can also be configured to load the module from a "
"DEB or RPM package included in the image, or skip loading DRBD entirely."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2552
msgid ""
"To change the behavior of the DRBD module loader, set the `LB_HOW` "
"environment variable to an appropriate value shown in the following table:"
msgstr ""

#. type: Table
#: UG9/en/linstor-kubernetes.adoc:2560
#, no-wrap
msgid ""
"| `LB_HOW` | Module Loader Behavior\n"
"\n"
"| `compile` | The default value. Builds the DRBD module from source and tries to load all optional modules from the host.\n"
"| `shipped_modules` | Searches for `.rpm` or `.deb` packages at `/pkgs` and inserts contained the DRBD modules. Optional modules are loaded from the host if available.\n"
"| `deps_only` | Only tries to load the optional modules. No DRBD module will be loaded.\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2563
msgid ""
"After setting the `LB_HOW` environment variable, apply the following YAML "
"configuration to your deployment. Based on the name within the metadata "
"section, the example below would be used with an `LB_HOW` environment "
"variable that was set to `deps_only`."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2585
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: no-drbd-module-loader\n"
"spec:\n"
"  patches:\n"
"    - target:\n"
"        kind: Pod\n"
"        name: satellite\n"
"      patch: |\n"
"        apiVersion: v1\n"
"        kind: Pod\n"
"        metadata:\n"
"          name: satellite\n"
"        spec:\n"
"          initContainers:\n"
"          - name: drbd-module-loader\n"
"            env:\n"
"            - name: LB_HOW\n"
"              value: deps_only\n"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2588
#, no-wrap
msgid "Using the Host Network for DRBD Replication in Operator v2 Deployments"
msgstr ""

#.  https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/how-to/drbd-host-networking.md
#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2592
msgid ""
"Instructions in this section will describe how you can use the host network "
"for DRBD replication traffic."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2594
msgid ""
"By default, DRBD will use the container network to replicate volume data. "
"This ensures replication works on a wide range of clusters without further "
"configuration. It also enables use of `NetworkPolicy` to block unauthorized "
"access to DRBD traffic. Since the network interface of the pod is tied to "
"the lifecycle of the pod, it also means DRBD will temporarily disrupt "
"replication when the LINSTOR satellite pod is restarted."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2596
msgid ""
"In contrast, using the host network for DRBD replication will cause "
"replication to work independently of the LINSTOR satellite pod. The host "
"network might also offer better performance than the container network. As a "
"downside, you will have to manually ensure connectivity between nodes on the "
"relevant ports."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2600
msgid ""
"To follow the steps in this section, you should be familiar with editing "
"link:https://github.com/piraeusdatastore/piraeus-operator/blob/v2/docs/"
"reference/linstorsatelliteconfiguration."
"md#linstorsatelliteconfiguration[`LinstorSatelliteConfiguration`] resources."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2602
#, fuzzy, no-wrap
#| msgid "Configuring DRBD"
msgid "Configuring DRBD Replication to Use the Host Network"
msgstr "配置DRBD"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2605
msgid ""
"Switching from the default container network to the host network for DRBD "
"replication is possible at any time. Existing DRBD resources will then be "
"reconfigured to use the host network interface."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2607
msgid ""
"To configure the host network for the LINSTOR satellite, apply the following "
"YAML configuration to your deployment:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2625
#, no-wrap
msgid ""
"apiVersion: piraeus.io/v1\n"
"kind: LinstorSatelliteConfiguration\n"
"metadata:\n"
"  name: host-network\n"
"spec:\n"
"  patches:\n"
"    - target:\n"
"        kind: Pod\n"
"        name: satellite\n"
"      patch: |\n"
"        apiVersion: v1\n"
"        kind: Pod\n"
"        metadata:\n"
"          name: satellite\n"
"        spec:\n"
"          hostNetwork: true\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2628
msgid ""
"After the satellite pods are recreated, they will use the host network. Any "
"existing DRBD resources are reconfigured to use a new IP address on the host "
"network rather than an IP address on the container network."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2630
#, fuzzy, no-wrap
#| msgid "Configuring DRBD"
msgid "Configuring DRBD Replication to Use the Container Network"
msgstr "配置DRBD"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2633
msgid ""
"Switching back from host network to container network involves manually "
"resetting the configured peer addresses used by DRBD. You can do this by "
"rebooting every node, or by manually resetting the addresses by using the "
"`drbdadm` CLI command on each node. Each method is described below."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2635
msgid ""
"[[s-kubernetes-drbd-replication-switching-from-host-to-container-network-"
"node-rebooting-v2]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2635
#, no-wrap
msgid "Rebooting Nodes to Switch DRBD Replication from the Host to the Container Network"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2638
msgid ""
"First, you need to remove the `LinstorSatelliteConfiguration` that set "
"`hostNetwork: true`. You can do this by entering the following `kubectl` "
"command:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2642 UG9/en/linstor-kubernetes.adoc:2682
#, no-wrap
msgid ""
"$ kubectl delete linstorsatelliteconfigurations.piraeus.io host-network\n"
"linstorsatelliteconfiguration.piraeus.io \"host-network\" deleted\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2645
msgid ""
"Next, reboot each cluster node, either serially, one by one, or else all at "
"once. In general, replication will not work between rebooted nodes and non-"
"rebooted nodes. The non-rebooted nodes will continue to use the host network "
"addresses, which are generally not reachable from the container network."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2647
msgid ""
"After all nodes have restarted, all resources will be configured to use the "
"container network, and all DRBD connections should be connected again."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2649
msgid ""
"[[s-kubernetes-drbd-replication-switching-from-host-to-container-network-"
"node-drbdadm-v2]]"
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2649
#, no-wrap
msgid "Using the DRBD Administration Tool to Switch DRBD Replication from the Host to the Container Network"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2652
msgid ""
"During this procedure, ensure that no new volumes or snapshots are created, "
"otherwise the migration to the container network might not be applied to all "
"resources."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2654
msgid ""
"First, you need to temporarily stop all DRBD replication and suspend all "
"DRBD volume I/O operations by using the `drbdadm suspend-io all` command. "
"Enter the command once on each LINSTOR satellite pod."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2659
#, no-wrap
msgid ""
"$ kubectl exec node1.example.com -- drbdadm suspend-io all\n"
"$ kubectl exec node2.example.com -- drbdadm suspend-io all\n"
"$ kubectl exec node3.example.com -- drbdadm suspend-io all\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2662
msgid "Next, disconnect all DRBD connections on all nodes."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2667
#, no-wrap
msgid ""
"$ kubectl exec node1.example.com -- drbdadm disconnect --force all\n"
"$ kubectl exec node2.example.com -- drbdadm disconnect --force all\n"
"$ kubectl exec node3.example.com -- drbdadm disconnect --force all\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2670
msgid ""
"Next, you can safely reset all DRBD connection paths. This frees the "
"connection on each node to be moved to the container network."
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2675
#, no-wrap
msgid ""
"$ kubectl exec node1.example.com -- drbdadm del-path all\n"
"$ kubectl exec node2.example.com -- drbdadm del-path all\n"
"$ kubectl exec node3.example.com -- drbdadm del-path all\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2678
msgid ""
"Finally, remove the `LinstorSatelliteConfiguration` resource configuration "
"that set `hostNetwork: true`. This will result in the creation of new "
"LINSTOR satellite pods that use the container network."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2685
msgid ""
"After the pods are recreated and the LINSTOR satellites are `Online`, the "
"DRBD resource will be reconfigured and resume I/O operations."
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2687
#, fuzzy, no-wrap
#| msgid "Interacting with LINSTOR in Kubernetes"
msgid "Evacuating a Node in Kubernetes"
msgstr "在Kubernetes中与LINSTOR互动"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2692
msgid ""
"If you want to evacuate a LINSTOR node of its resources, so that they are "
"placed onto other nodes within your cluster, the process is detailed in <<s-"
"linstor-node-evacuate>>. However, before evacuating a LINSTOR node in "
"Kubernetes, you need to take an additional action."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2694
msgid ""
"First move the node's workload to another node. You can do this by entering "
"the command:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2697
#, no-wrap
msgid "# kubectl drain --ignore-daemonsets <node_name>\n"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2701
msgid ""
"After verifying that your cluster is running as expected, you can continue "
"to follow the steps in <<s-linstor-node-evacuate>>."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2704
msgid ""
"If you are planning on evacuating more than one node, enter the following "
"command on all the nodes that you will be evacuating:"
msgstr ""

#. type: delimited block -
#: UG9/en/linstor-kubernetes.adoc:2707
#, no-wrap
msgid "# linstor node set-property n1.k8s-mwa.at.linbit.com AutoplaceTarget false\n"
msgstr ""

#. type: Title ===
#: UG9/en/linstor-kubernetes.adoc:2713
#, fuzzy, no-wrap
#| msgid "Configuring the Nodes"
msgid "Monitoring With Prometheus"
msgstr "配置节点"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2715
msgid ""
"You can use https://prometheus.io/[Prometheus] to monitor LINSTOR components."
msgstr ""

#. type: Title ====
#: UG9/en/linstor-kubernetes.adoc:2717
#, no-wrap
msgid "Monitoring with Prometheus in Operator v1 Deployments"
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2720
msgid ""
"In Operator v1 deployments, the operator will set up monitoring containers "
"along the existing components and make them available as a `Service`."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2724
msgid ""
"If you use the https://prometheus-operator.dev/[Prometheus Operator], the "
"LINSTOR Operator will also set up the `ServiceMonitor` instances. The "
"metrics will automatically be collected by the Prometheus instance "
"associated to the operator, assuming https://prometheus-operator.dev/docs/"
"kube/monitoring-other-namespaces/[watching the Piraeus namespace is enabled]."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2726
msgid ""
"To disable exporting of metrics, set `operator.satelliteSet.monitoringImage` "
"to an empty value."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2728
#, fuzzy, no-wrap
#| msgid "LINBIT LINSTOR Controller Appliance"
msgid "LINSTOR Controller Monitoring in Operator v1 Deployments"
msgstr "LINBIT LINSTOR Controller设备"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2732
msgid ""
"The LINSTOR controller exports cluster-wide metrics. Metrics are exported on "
"the existing controller service, using the path https://linbit.com/drbd-user-"
"guide/linstor-guide-1_0-en/#s-linstor-monitoring[`/metrics`]."
msgstr ""

#. type: Title =====
#: UG9/en/linstor-kubernetes.adoc:2734
#, fuzzy, no-wrap
#| msgid "DRBD resource configuration"
msgid "DRBD Resource Monitoring in Operator v1 Deployments"
msgstr "DRBD资源配置"

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2739
msgid ""
"All satellites are bundled with a secondary container that uses https://"
"github.com/LINBIT/drbd-reactor/[`drbd-reactor`] to export metrics directly "
"from DRBD. The metrics are available on port 9942, for convenience a "
"headless service named `<linstorsatelliteset-name>-monitoring` is provided."
msgstr ""

#. type: Plain text
#: UG9/en/linstor-kubernetes.adoc:2741
msgid ""
"If you want to disable the monitoring container, set `monitoringImage` to "
"`\"\"` in your `LinstorSatelliteSet` resource."
msgstr ""
