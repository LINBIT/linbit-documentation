[[ch-drbd-reactor]]
== DRBD Reactor

indexterm2:[DRBD Reactor] is a daemon that monitors DRBD events and reacts to them.
DRBD Reactor has various potential uses, from monitoring DRBD resources and metrics, to creating
failover clusters to providing highly available services that you would usually need to
configure using complex cluster managers.

[[s-drdb-reactor-installing]]
=== Installing DRBD Reactor

DRBD Reactor can be installed from source files found within
https://github.com/LINBIT/drbd-reactor[the project's GitHub repository].  See the instructions
there for details and any prerequisites.

ifndef::drbd-only[]
Alternatively, LINBIT customers can install DRBD Reactor from prebuilt packages, available from
LINBIT's `drbd-9` packages repository.
endif::drbd-only[]

=== DRBD Reactor's Components

Because DRBD Reactor has many different uses, it was split into two components: a core component
and a plug-in component.

[[s-drdb-reactor-core]]
==== DRBD Reactor Core

DRBD Reactor’s core component is responsible for collecting DRBD events, preparing them, and
sending them to the DRBD Reactor plug-ins.

The core can be reloaded with an all new or an additional, updated configuration. It can stop
plug-in instances no longer required and start new plug-in threads without losing DRBD events.
Last but not least, the core has to ensure that plug-ins receive an initial and complete DRBD
state.

[[s-drdb-reactor-plug-ins]]
==== DRBD Reactor Plug-ins

Plug-ins provide DRBD Reactor with its functionality and there are different plug-ins for
different uses. A plug-in receives messages from the core component and acts upon DRBD resources
based on the message content and according to the plug-in’s type and configuration.

Plug-ins can be instantiated multiple times, so there can be multiple instances of every plug-in
type. So, for example, numerous plug-in instances could provide high-availability in a cluster,
one per DRBD resource.

[[s-drdb-reactor-promoter-plug-in]]
==== The Promoter Plug-in

The promoter plug-in is arguably DRBD Reactor's most important and useful feature. You can use
it to create failover clusters hosting highly available services more easily than using other
more complex cluster resource managers (CRMs). If you want to get started quickly, you can
finish reading this section, then skip to <<s-drbd-reactor-promoter-plug-in-configuring>>. You
can then try the instructions in the <<s-drbd-reactor-creating-a-ha-file-system-mount>> section
for an example exercise.

The promoter plug-in monitors events on DRBD resources and executes systemd units. This plug-in
allows DRBD Reactor to provide failover functionality to a cluster to create high-availability
deployments. You can use DRBD Reactor and its promoter plug-in as a replacement for other CRMs,
such as Pacemaker, in many scenarios where its lightness and its configuration simplicity offer
advantages.

For example, you can use the promoter plug-in to configure fully automatic recovery of isolated
primary nodes. Furthermore, there is no need for a separate communication layer (such as
Corosync), because DRBD and DRBD Reactor (used as the CRM) will always agree on the quorum
status of nodes.

A disadvantage to the promoter plug-in when compared to a CRM such as Pacemaker is that it is
not possible to create order constraints that are independent of colocations. For example, if a
web service and a database run on different nodes, Pacemaker can constrain the web service to
start after the database. DRBD Reactor and its promoter plug-in cannot.

===== How the Promoter Plug-in Works

The promoter plug-in’s main function is that if a DRBD device can be promoted, promote it to
_Primary_ and start a set of user-defined services. This could be a series of services, such
as:

. Promote the DRBD device.
. Mount the device to a mount point.
. Start a database that uses a database located at the mount point.

If a resource loses quorum, DRBD Reactor stops these services so that another node that still
has quorum (or the node that lost quorum when it has quorum again) can start the services.

The promoter plug-in also supports Open Cluster Framework (OCF) resource agents and failure
actions such as rebooting a node if a resource fails to demote, so that the resource can promote
on another node.

[[s-drdb-reactor-umh-plug-in]]
==== The User Mode Helper (UMH) Plug-in

Using this plug-in and its domain specific language (DSL), you can execute a script if an event
you define occurs. For example, you can run a script that sends a Slack message whenever a DRBD
resource loses connection.

This functionality has existed before in DRBD with “user-defined helper scripts” in “kernel
space”. However, DRBD Reactor, including the UMH plug-in, can be executed in “user space”. This
allows for easier container deployments and use with “read-only” host file systems such as those
found within container distributions.

Using UMH plug-ins also provides a benefit beyond what was previously possible using user
defined helper scripts: Now you can define your own rules for all the events that are possible
for a DRBD resource. You are no longer limited to only the few events that there are event
handlers in the kernel for.

UMH plug-in scripts can be of two types:

- *User-defined filters*. These are “one-shot” UMH scripts where an event happens that triggers
  the script.

- *Kernel called helper replacements*. This type of script is currently under development. These
  are UMH scripts that require communication to and from the kernel. An event triggers the
  script but an action within the script requires the kernel to communicate back to the script
  so that the script can take a next action, based on the failure or success of the kernel’s
  action. An example of such a script would be a `before-resync-target` activated script.

[[s-drdb-reactor-prometheus-plug-in]]
==== The Prometheus Monitoring Plug-in

This plug-in provides a https://prometheus.io/[Prometheus] compatible endpoint that exposes
various DRBD metrics, including out-of-sync bytes, resource roles (for example, _Primary_), and
connection states (for example, _Connected_). This information can then be used in every
monitoring solution that supports Prometheus endpoints. The full set of metrics and an example
Grafana dashboard are available at the
https://github.com/LINBIT/drbd-reactor/blob/master/doc/prometheus.md[DRBD Reactor GitHub
repository].

[[s-drbd-reactor-configuring]]
=== Configuring DRBD Reactor

Before you can run DRBD Reactor, you must configure it. Global configurations are made within a
main TOML configuration file, which should be created here: `/etc/drbd-reactor.toml`. The file
has to be a valid TOML (https://toml.io) file. Plug-in configurations should be made within
snippet files that can be placed into the default DRBD Reactor snippets directory,
`/etc/drbd-reactor.d`, or into another directory if specified in the main configuration file. An
https://github.com/LINBIT/drbd-reactor/blob/master/example/drbd-reactor.toml[example
configuration file] can be found in the `example` directory of the DRBD Reactor GitHub
repository.

For documentation purposes only, the example configuration file mentioned above contains example
plug-in configurations. However, for deployment, plug-in configurations should always be made
within snippet files.

[[s-drbd-reactor-core-configuring]]
==== Configuring DRBD Reactor's Core

DRBD Reactor’s core configuration file consists of global settings and log level settings.

Global settings include specifying a snippets directory, specifying a statistics update polling
time period, as well as specifying a path to a log file. You can also set the log level within
the configuration file to one of: trace, debug, info, warn, error, off. “Info” is the default
log level.

See the `drbd-reactor.toml` man page for the syntax of these settings.

[[s-drbd-reactor-plug-in-configuring]]
==== Configuring DRBD Reactor Plug-ins

You configure DRBD Reactor plug-ins by editing TOML formatted snippet files. Every plug-in can
specify an ID (`id`) in its configuration section. On a DRBD Reactor daemon reload, started
plug-ins that are still present in the new configuration keep running. Plug-ins without an ID
get stopped and restarted if still present in the new configuration.

IMPORTANT: For plug-ins without an ID, every DRBD Reactor service reload is a restart.

[[s-drbd-reactor-promoter-plug-in-configuring]]
==== Configuring the Promoter Plug-in

You will typically have one snippet file for each DRBD resource that you want DRBD Reactor and
the promoter plug-in to watch and manage.

Here is an example promoter plug-in configuration snippet:

----
[[promoter]]
[promoter.resources.my_drbd_resource] <1>
dependencies-as = "Requires" <2>
target-as = "Requires" <3>
start = ["path-to-my-file-system-mount.mount", "foo.service"] <4>
on-drbd-demote-failure = "reboot" <5>
secondary-force = true <6>
preferred-nodes = ["nodeA, "nodeB"] <7>
----

<1> "my_drbd_resource" specifies the name of the DRBD resource that DRBD Reactor and the
promoter plug-in should watch and manage.

<2> Specifies the systemd dependency type to generate inter-service dependencies as.

<3> Specifies the systemd dependency type to generate service dependencies in the final target
unit.

<4> `start` specifies what should be started when the watched DRBD resource is promotable. In
this example, the promoter plug-in would start a file system mount unit and a service unit.

<5> Specifies the action to take if a DRBD resource fails to demote, for example, after a loss
of quorum event. In such a case, an action should be taken on the node that fails to demote
that will trigger some "self-fencing" of the node and cause another node to promote. Actions
can be one of: reboot, reboot-force, reboot-immediate, poweroff, poweroff-force,
poweroff-immediate, exit, exit-force.

<6> If a node loses quorum, DRBD Reactor will try to demote the node to a secondary role. If
the resource was configured to suspend I/O operations upon loss of quorum, this setting
specifies whether or not to demote the node to a secondary role using `drbdadm`'s force
secondary feature. See the <<s-force-secondary>> section of the DRBD User's Guide for more
details. "true" is the default option if this setting is not specified. It is specified here
for illustrative purposes.

<7> If set, resources are started on the preferred nodes, in the specified order, if possible.

===== Using OCF Resource Agents with the Promoter Plug-in

You can also configure the promoter plug-in to use OCF resource agents in the `start` list of
services.

ifndef::de-brand[]
Please make sure to install the `resource-agents` package provided in LINBIT's customer repositories.
endif::de-brand[]

The syntax for specifying an OCF resource agent as a service within a `start` list is
`ocf:$vendor:$agent instance-id [key=value key=value ...]`. Here, `instance-id` is user-defined
and `key=value` pairs, if specified, are passed as environment variables to the created systemd
unit file. For example:

----
start = [
	"ocf:linbit:drbd drbd_backed_mysql \
		drbd_resource="mysql" \
	"ocf:heartbeat:IPaddr2 ip_mysql \
		ip=10.43.7.223 \
		cidr_netmask=16",
	"ocf:heartbeat:Filesystem mysql_data_mount \
		device=/dev/drbd/by-res/mysql/0 \
		directory=/var/lib/mysql \
		fstype=ext4",
]
----

IMPORTANT: The promoter plug-in expects OCF resource agents in the `/usr/lib/ocf/resource.d/`
directory.

[[s-drbd-reactor-umh-plug-in-configuring]]
==== Configuring the User Mode Helper (UMH) Plug-in

Configuration for this plug-in consists of:

- Rule type
- Command or script to execute
- User-defined environment variables (optional)
- Filters based on DRBD resource name, event type, or state changes

There are four different DRBD types a rule can be defined for: `resource`, `device`,
`peerdevice`, or `connection`.

For each rule type, you can configure a command or script to execute using `sh -c` as well as
any user-defined environment variables. User-defined environment variables are in addition to
the commonly set ones:

- HOME  “/”
- TERM  “Linux”
- PATH  “/sbin:/usr/sbin:/bin:/usr/bin”

You can also filter UMH rule types by DRBD resource name or event type (exists, create, destroy,
or change).

Finally, you can filter the plug-in’s action based on DRBD state changes. Filters should be
based upon both the old and the new (current) DRBD state, that are reported to the plug-in,
because you want the plug-in to react to changes. This is only possible if two states, old
and new, are filtered for, otherwise the plug-in might trigger randomly. For example, if you
only specified a new (current) DRBD role as a DRBD state to filter for, the plug-in might
trigger even when the new role is the same as as the old DRBD role.

Here is an example UMH plug-in configuration snippet for a `resource` rule:

----
[[umh]]
[[umh.resource]]
command = "slack.sh $DRBD_RES_NAME on $(uname -n) from $DRBD_OLD_ROLE to $DRBD_NEW_ROLE"
event-type = "Change"
resource-name = "my-resource"
old.role = { operator = "NotEquals", value = "Primary" }
new.role = "Primary"
----

This example UMH plug-in configuration is based on change event messages received from DRBD
Reactor’s daemon for the DRBD resource specified by the `resource-name` value `my-resource`.

If the resource’s old role was not _Primary_ and its new (current) role is _Primary_, then a
script named `slack.sh` runs with the arguments that follow. As the full path is not specified,
the script needs to reside within the commonly set `PATH` environment variable
(`/sbin:/usr/sbin:/bin:/usr/bin`) of the host machine (or container if run that way).
Presumably, the script sends a message to a Slack channel informing of the resource role change.
Variables specified in the command string value are substituted for based on specified values
elsewhere in the plug-in's configuration, for example, the value specified by `resource-name`
will be substituted for `$DRBD_RES_NAME` when the command runs.

NOTE: The example configuration above uses the specified operator "NotEquals" to evaluate
whether or not the `old.role` value of "Primary" was true. If you do not specify an operator,
then the default operator is "Equals", as in the `new.role = "Primary"` filter in the example
configuration.

There are more rules, fields, filter types, and variables that you can specify in your UMH
plug-in configurations. See the
https://github.com/LINBIT/drbd-reactor/blob/master/doc/umh.md[UMH documentation page] in the
DRBD Reactor GitHub repository for more details, explanations, examples, and caveats.

[[s-drbd-reactor-prometheus-plug-in-configuring]]
==== Configuring the Prometheus Plug-in

This plug-in provides a Prometheus compatible HTTP endpoint serving DRBD monitoring metrics,
such as the DRBD connection state, whether or not the DRBD device has quorum, number of bytes
out of sync, indication of TCP send buffer congestion, and many more. The
`drbd-reactor.prometheus` man page has a full list of metrics and more details.

[[s-drbd-reactorctl]]
=== Using the DRBD Reactor CLI Utility

You can use the DRBD Reactor CLI utility, `drbd-reactorctl`, to control the DRBD Reactor daemon
and its plug-ins.

IMPORTANT: This utility only operates on plug-in snippets. Any existing plug-in configurations
in the main configuration file (not advised nor supported) should be moved to snippet files
within the snippets directory.

With the `drbd-reactorctl` utility, you can:

- Get the status of the DRBD Reactor daemon and enabled plug-ins, by using the `drbd-reactorctl
  status` command.

- Edit an existing or create a new plug-in configuration, by using the `drbd-reactorctl edit -t
  <plug-in_type> <plug-in_file>` command.

- Display the TOML configuration of a given plug-in, by using the `drbd-reactorctl cat
  <plug-in_file>` command.

- Enable or disable a plug-in, by using the `drbd-reactorctl enable|disable <plug-in_file>`
  command.

- Evict a promoter plug-in resource from the node, by using the `drbd-reactorctl evict
  <plug-in_file>` command.

- Restart specified plug-ins (or the DRBD Reactor daemon, if no plug-ins specified) by using the
  `drbd-reactorctl restart <plug-in_file>` command. Remove an existing plug-in and restart the
  daemon, by using the `drbd-reactorctl rm <plug-in_file>` command.

- List the activated plug-ins, or optionally list disabled plug-ins, by using the
  `drbd-reactorctl ls [--disabled]` command.

For greater control of some of the above actions, there are additional options available. The
`drbd-reactorctl` man page has more details and syntax information.

[[s-alternative-to-pacemaker-drbd-reactorctl-commands]]
==== Pacemaker CRM Shell Commands and Their DRBD Reactor Client Equivalents

The following table shows some common CRM tasks and the corresponding Pacemaker CRM shell and
the equivalent DRBD Reactor client commands.

[cols="14h,~,~"]
|===
|CRM task|Pacemaker CRM shell command|DRBD Reactor client command

|Get status
|`crm_mon`
|`drbd-reactorctl status`

|Migrate away
|`crm resource migrate`
|`drbd-reactorctl evict`

|Unmigrate
|`crm resource unmigrate`
|Unnecessary
|===

A DRBD Reactor client command that is equivalent to `crm resource unmigrate` is unnecessary
because DRBD Reactor's promoter plug-in evicts a DRBD resource in the moment, but it does not
prevent the resource from failing back to the node it was evicted from later, should the
situation arise. In contrast, the CRM shell `migrate` command inserts a permanent constraint
into the cluster information base (CIB) that prevents the resource from running on the node
the command is run on. The CRM shell `unmigrate` command is a manual intervention that removes
the constraint and allows the resource to fail back to the node the command is run on. A
forgotten `unmigrate` command can have dire consequences the next time the node might be
needed to host the resource during an HA event.

NOTE: If you need to prevent failback to a particular node, you can evict it by using the DRBD
Reactor client with the `evict --keep-masked` command and flag. This prevents failback, until
the node reboots and the flag gets removed. You can remove the flag sooner than a reboot would,
by using the `drbd-reactorctl evict --unmask` command. This command would be the equivalent to
CRM shell's `unmigrate` command.

[[s-drbd-reactor-creating-a-ha-file-system-mount]]
=== Using DRBD Reactor’s Promoter Plug-in to Create a Highly Available File System Mount

In this example, you will use DRBD Reactor and the promoter plug-in to create a highly available
file system mount within a cluster.

Prerequisites:

- A directory `/mnt/test` created on all of your cluster nodes

- A DRBD configured resource named _ha-mount_ that is backed by a DRBD device, `/dev/drbd1000`,
  on all nodes

- The Cluster Labs "Filesystem" OCF resource agent, available through
  https://github.com/ClusterLabs/resource-agents/blob/main/heartbeat/Filesystem[Cluster Lab's
  `resource-agents` GitHub] repository, should be present in the `/usr/lib/ocf/resource.d/`
  directory

The DRBD resource, _ha-mount_, should have the following settings configured in its DRBD
resource configuration file:

----
resource ha-mount {
  options {
    auto-promote no;
    quorum majority;
    on-no-quorum suspend-io;
    ...
  }
...
}
----

First, make one of your nodes _Primary_ for the _ha-mount_ resource.

----
# drbdadm primary ha-mount
----

Then create a file system on the DRBD backed device. The ext4 file system is used in this
example.

----
# mkfs.ext4 /dev/drbd1000
----

Make the node _Secondary_ because after further configurations, DRBD Reactor and the Promoter
plug-in will control promoting nodes.

----
# drbdadm secondary ha-mount
----

On all nodes that should be able to mount the DRBD backed device, create a systemd unit file:

----
# cat << EOF > /etc/systemd/system/mnt-test.mount
[Unit]
Description=Mount /dev/drbd1000 to /mnt/test

[Mount]
What=/dev/drbd1000
Where=/mnt/test
Type=ext4
EOF
----

IMPORTANT: The systemd unit file name must match the mount location value given by the “Where=”
directive, using systemd escape logic. In the example above, `mnt-test.mount` matches the mount
location given by `Where=/mnt/test`. You can use the command `systemd-escape -p --suffix=mount
/my/mount/point` to convert your mount point to a systemd unit file name.

Next, on the same nodes as the previous step, create a configuration file for the DRBD Reactor
promoter plug-in:

----
# cat << EOF > /etc/drbd-reactor.d/ha-mount.toml
[[promoter]]
id = "ha-mount"
[promoter.resources.ha-mount]
start = '''
["ocf:heartbeat:Filesystem fs_test device=/dev/drbd1000 
directory=/mnt/test fstype=ext4 run_fsck=no"]
'''
on-drbd-demote-failure = "reboot"
EOF
----

This promoter plug-in configuration uses a start list of services that specifies an OCF resource
agent, for the file system found at our HA mount point. By using this particular resource agent,
you can circumvent situations where systemd might not know about certain users and processes
that might hold the mount point open and prevent it from unmounting. Otherwise, if only the
systemd unit file for the mount point was specified in the promoter plug-in's start list of
services, the mount point might be held open indefinitely in some cases.

To apply the configurations, enable and start the DRBD Reactor service on all nodes. If the DRBD
Reactor service is already running, reload it instead.

----
# systemctl enable drbd-reactor.service --now
----

Next, verify which cluster node is in the _Primary_ role for the _ha-mount_ resource and has the
backing device mounted.

----
# drbd-reactorctl status ha-mount
----

Test a simple failover situation on the _Primary_ node by using the DRBD Reactor CLI utility to
disable the _ha-mount_ configuration.

----
# drbd-reactorctl disable --now ha-mount
----

Run the DRBD Reactor status command again to verify that another node is now in the _Primary_
role and has the file system mounted.

After testing failover, you can enable the configuration on the node you disabled it on earlier.

----
# drbd-reactorctl enable ha-mount
----

As a next step, you may want to read the
https://linbit.com/drbd-user-guide/linstor-guide-1_0-en/#s-linstor_ha[LINSTOR User's Guide
section on creating a highly available LINSTOR cluster]. There, DRBD Reactor is used to manage
the LINSTOR Controller as a service so that it is highly available within your cluster.

[[s-drbd-reactor-configuring-prometheus-monitoring]]
=== Configuring the DRBD Reactor Prometheus Plug-in

DRBD Reactor’s Prometheus monitoring plug-in acts as a Prometheus compatible endpoint for DRBD
resources and exposes various DRBD metrics. You can find a list of the available metrics in
https://github.com/LINBIT/drbd-reactor/blob/master/doc/prometheus.md[the documentation folder]
in the project’s GitHub repository.

Prerequisites:

- Prometheus is installed with its service enabled and running.

- Grafana is installed with its service enabled and running.

To enable the Prometheus plug-in, create a simple configuration file snippet on all DRBD Reactor
nodes that you are monitoring.

----
# cat << EOF > /etc/drbd-reactor.d/prometheus.toml
[[prometheus]]
enums = true
address = "0.0.0.0:9942"
EOF
----

Reload the DRBD Reactor service on all nodes that you are monitoring.

----
# systemctl reload drbd-reactor.service
----

Add the following DRBD Reactor monitoring endpoint to your Prometheus configuration file’s
`scrape_configs` section. Replace “node-x” in the `targets` lines below with either hostnames or
IP addresses for your DRBD Reactor monitoring endpoint nodes. Hostnames must be resolvable from
your Prometheus monitoring node.

----
  - job_name: drbd_reactor_endpoint
    static_configs:
      - targets: ['node-0:9942']
        labels:
          instance: 'node-0'
      - targets: ['node-1:9942']
        labels:
          instance: 'node-1'
      - targets: ['node-2:9942']
        labels:
          instance: 'node-2'
       [...]
----

Then, assuming it is already enabled and running, reload the Prometheus service by entering
`sudo systemctl reload prometheus.service`.

Next, you can open your Grafana server’s URL with a web browser. If the Grafana server
service is running on the same node as your Prometheus monitoring service, the URL would look
like: `http://<node_IP_address_or_hostname>:3000`.

You can then log into the Grafana server web UI, add a Prometheus data source, and then add or
import a Grafana dashboard that uses your Prometheus data source. An example dashboard is
available at the https://grafana.com/grafana/dashboards/14339[Grafana Labs dashboards
marketplace]. An example dashboard is also available as a downloadable JSON file
https://raw.githubusercontent.com/LINBIT/drbd-reactor/master/example/grafana-dashboard.json[here],
at the DRBD Reactor GitHub project site.

