[[ch-olvm-linstor]]
== LINSTOR storage domains in Oracle Virtualization

indexterm:[oVirt]
Oracle Virtualization is an Oracle Linux-based "enterprise-grade server virtualization solution that provides KVM virtualization and management capabilities" according to the link:https://www.oracle.com/virtualization/[Oracle website].
Oracle Linux Virtualization Manager (OLVM) is the management platform within the Oracle Virtualization solution.

This chapter describes using LINSTOR(R) to provision persistent, replicated, and high-performance block storage for link:https://docs.oracle.com/en/virtualization/oracle-linux-virtualization-manager/index.html[Oracle Linux Virtualization Manager].

[[s-olvm-linstor-overview]]
=== Introduction to Oracle Linux Virtualization Manager

OLVM is a virtualization management platform based on link:https://www.ovirt.org/[oVirt].
It can configure, manage and monitor Kernel-based Virtual Machine (KVM) hosts running on Oracle Linux.

In OLVM, data domains provide centralized storage for virtual machine disk images, ISO files, and snapshots.
OLVM supports multiple _types_ of data domains, also called storage domains, which you can integrate with LINSTOR:

- *iSCSI or NFS*: <<ch-linstor-gateway,LINSTOR Gateway>> lets you create and manage highly available iSCSI targets and NFS exports backed by LINSTOR.
- https://www.ovirt.org/develop/release-management/features/storage/cinderlib-integration.html[*_Managed block storage_*]: An OLVM storage domain where each virtual disk is provisioned as its own volume, rather than from a shared storage pool.
This enables LINSTOR-managed volumes to attach directly to virtual machines in OLVM, improving performance and avoiding the limitations of iSCSI and NFS storage.

[[s-olvm-linstor-gateway]]
=== Preparing LINSTOR Gateway for OLVM

With LINSTOR Gateway, you can create iSCSI targets and NFS exports to use as data domains in OLVM.
All volume access is routed through the LINSTOR Gateway host(s) exporting the volume(s).
Volume access includes all I/O from any running virtual machines including any other processes actively using the data domain.

As prerequisites, you will need:

* An operational <<s-installation,LINSTOR Cluster>>
* A completed <<ch-linstor-gateway,LINSTOR Gateway>> installation

You can deploy LINSTOR (and LINSTOR Gateway) on the same nodes as OLVM (hyperconverged), or on separate nodes outside of your OLVM environment (non-hyperconverged).

[IMPORTANT]
====
- The `vdsmd.service` in OLVM manages NFS processes on KVM hosts, making NFS deployments managed by LINSTOR Gateway problematic in non-hyperconverged environments.
- In hyperconverged deployments, use LINSTOR Gateway to provision *_iSCSI data domains only_*.
====

[[s-olvm-linstor-gateway-data-domains]]
=== Creating OLVM data domains with LINSTOR Gateway

Use the `linstor-gateway` command to create iSCSI or NFS exports.
Choose a virtual IP (VIP) address that is reachable from your OLVM environment.
This is how clients will reach your iSCSI targets or NFS exports.

The following example creates an iSCSI target with a 100 GiB LUN, using a VIP address of `192.168.0.100`:

----
linstor-gateway iscsi create iqn.2019-08.com.linbit:data-domain 192.168.0.100/24 100G
----

After entering the iSCSI create command, output will show that LINSTOR Gateway successfully created your iSCSI target:

----
Created iSCSI target 'iqn.2019-08.com.linbit:data-domain'
----

The following example creates an NFS export of 100 GiB, available at `192.168.0.101:/srv/gateway-exports/nfs-data`:

----
linstor-gateway nfs create nfs-data 192.168.0.101/24 100G
----

After entering the NFS create command, output will show that LINSTOR Gateway successfully created your NFS export:

----
Created export 'nfs-data' at 192.168.0.101:/srv/gateway-exports/nfs-data
----

Data domains must be added to OLVM through the Administration Portal, available at `https://*engine-fqdn*/ovirt-engine/`.

In OLVM, go to *Storage* and then click *Domains*. In the *Storage Domains* pane, click *New Domain* and then follow these steps:

. Select *iSCSI* or *NFS* from the *Storage Type* drop-down list.
. Choose a name for the new data domain.
. Enter the required connection parameters to complete the configuration.
. Click *OK*.

[[s-olvm-linstor-gateway-hosted-engine]]
==== Using LINSTOR Gateway to deploy the OLVM self-hosted engine

LINSTOR Gateway iSCSI targets can be used to create the data domain for the link:https://docs.oracle.com/en/virtualization/oracle-linux-virtualization-manager/getstart/getstarted-hosted-engine-deploy.html[OLVM self-hosted engine].

IMPORTANT: The iSCSI data domain must be a dedicated iSCSI target for exclusive use by the self-hosted engine VM.

// iSCSI for self hosted engine - "must be at least 74 GiB"
// https://docs.redhat.com/en/documentation/red_hat_virtualization/4.2/html/self-hosted_engine_guide/deploying_the_self-hosted_engine_using_the_cli_deploy
Create an iSCSI target with at least 74 GiB to use for the self-hosted engine VM storage.
The following example creates a 100 GiB volume exported as `iqn.2019-08.com.linbit:olvm-engine`, available at the VIP address `192.168.0.200`.
Change the VIP address and iSCSI target name to appropriate values for your environment.

----
linstor-gateway iscsi create iqn.2019-08.com.linbit:engine-data 192.168.0.200/24 100G
----

During the OLVM self-hosted engine deployment, you will be asked to provide details for the storage of the self-hosted engine VM.
You only need to provide the storage type `iscsi` and the VIP address `192.168.0.200`.
All other information will be discovered automatically.

----
Please specify the storage you would like to use (glusterfs, iscsi, fc,
nfs)[nfs]: iscsi
Please specify the iSCSI portal IP address: 192.168.0.200
  Please specify the iSCSI portal port [3260]:
  Please specify the iSCSI discover user:
  Please specify the iSCSI discover password:
  Please specify the iSCSI portal login user:
  Please specify the iSCSI portal login password:
  The following targets have been found:
    [1] iqn.2019-08.com.linbit:engine-data
        TPGT: 1, portals:
            192.168.0.200:3260
  Please select a target (1) [1]: 1
  Please select the destination LUN (1) [1]:
----

After the setup completes, the iSCSI target is added as an iSCSI data domain to OLVM.

=== Creating managed block storage data domains with LINSTOR

IMPORTANT: Before adding managed block storage to OLVM, you must first add an iSCSI or NFS master data domain.

LINSTOR provides a Cinderlib driver for OLVM that enables the use of managed block storage (MBS) data domains.

When using managed block storage domains with OLVM and LINSTOR:

* Each virtual disk image maps one-to-one to a unique LINSTOR resource.
* The OLVM volume UUID is included in the corresponding LINSTOR resource name.

[WARNING]
====
* *The Cinderlib integration in OLVM is deprecated and never progressed beyond _Technology Preview_ status.*
* MBS data domains do not support all OLVM features, including VM templates.
* While the Cinderlib integration can provide higher performance, as it is the only native storage driver interface between LINSTOR and OLVM, it should be used with caution.
* Consider using the Cinderlib integration only for larger deployments (for example, more than three nodes with local storage pools).
For smaller deployments, iSCSI data domains are recommended.
====

Using managed block storage requires additional configuration in OLVM and LINSTOR:

* All KVM hosts, including the OLVM engine host, must be registered with LINBIT with `ovirt` and `drbd-9` repositories enabled.
* All KVM hosts must be a LINSTOR cluster node, with each host configured as a LINSTOR satellite node.
* The Cinderlib integration must be enabled in OLVM.
This feature is disabled if you do not explicitly enable it during the OLVM engine deployment process.
To enable it after deploying the OLVM engine, run `engine-setup` on the engine host:
+
----
engine-setup --reconfigure-optional-components
----
+
Enter _Yes_ when prompted:
+
----
--== PRODUCT OPTIONS ==--

Configure Cinderlib integration (Currently in tech preview) (Yes, No) [No]: Yes
----
+
* You need to install the `linstor-cinder` package on the engine host:
+
----
$ dnf install -y --enablerepo=ovirt linstor-cinder
----

The managed block storage data domain must be added through the OLVM Administration Portal, available at `https://*engine-fqdn*/ovirt-engine/`.

In OLVM, go to *Storage* and then click *Domains*. In the *Storage Domains* pane, click *New Domain*, and then take the following steps to add a managed block storage data domain:

. Select *Managed Block Storage* from the *Domain Function* drop-down list.
. Name the new data domain `linstor-cinder`.
. Use the following driver options:
+
[%autowidth,cols="m,m,",opts="header"]
|===
|Property|Value|Description
|volume_driver|linstor_cinder.LinstorDrbdDriver| Specifies the use of the LINSTOR Cinder driver for managed block storage.
|linstor_uris| linstor://**linstor-controller-ip-address**|URL of the LINSTOR controller endpoint(s).
Separate multiple endpoints by using a comma (`,`).
|linstor_default_resource_group_name|DfltRscGrp|<<s-linstor-resource-groups,LINSTOR resource group>> to use.
Volumes created in this data domain will inherit all settings from the resource group.
|===
+
TIP: `DfltRscGrp` is the default resource group in LINSTOR.
In most cases, you should create <<s-linstor-resource-groups,resource groups>>, for example, `rg_cinder`, to better align LINSTOR with your OLVM environment's storage needs.

NOTE: In OLVM, you can only create VMs with managed block storage volumes through the Administration Portal.  
The VM Portal does not support creating new volumes in managed block storage data domains.

// Note about VM snapshots?

// Keep the empty line before this comment, otherwise the next chapter is folded into this
