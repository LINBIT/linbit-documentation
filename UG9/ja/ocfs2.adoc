[[ch-ocfs2]]
== DRBDとOCFS2の使用

indexterm:[OCFS2]indexterm:[Oracle Cluster File System]この章では、共有Oracle
Cluster File Systemバージョン2 (OCFS2)を格納するブロックデバイスとしてDRBDリソースを設定する方法を説明します。


[IMPORTANT]
===============================
全クラスタファイルシステムには fencingが_必要_ です。DRBDリソース経由だけでなくSTONITHもです。問題のあるノードは _必ず_
killされる必要があります。

次のような設定がよいでしょう。

	net {
		fencing resource-and-stonith;
	}
	handlers {
		# Make sure the other node is confirmed
		# dead after this!
		outdate-peer "/sbin/kill-other-node.sh";
	}

これらは _非揮発性_ のキャッシュである必要があります。 GFS2に関するものであり、OCFS2についてではありませんが、
https://fedorahosted.org/cluster/wiki/DRBD_Cookbook が参考になるでしょう。
===============================



[[s-ocfs2-primer]]
=== OCFS2の基礎

Oracle Cluster File Systemバージョン2 (OCFS2)は、Oracle
Corporationが開発した同時アクセス共有ストレージファイルシステムです。前バージョンのOCFSはOracleデータベースペイロード専用に設計されていましたが、OCFS2はほとんどのPOSIXセマンティクスを実装する汎用ファイルシステムです。OCFS2の最も一般的なユースケースは、もちろんOracle
Real Application Cluster (RAC)ですが、OCFS2は負荷分散NFSクラスタなどでも使用できます。

本来、OCFS2は従来の共有ストレージデバイス用に設計されたものですが、<<s-dual-primary-mode,dual-Primary
DRBD>>でも問題なく使用できます。OCFS2が通常実行されるSANデバイスとは異なり、DRBDはローカルストレージに対して読み書きを行うため、ファイルシステムからデータを読み取るアプリケーションの読み取り待ち時間が短縮できるというメリットがあります。さらに、DRBDの場合は、単一のファイルシステムイメージを単に共有するのではなく、各ファイルシステムイメージにさらにコピーを追加するため、OCFS2に冗長性が加わります。

<<ch-gfs,GFS>>など他の共有クラスタファイルシステムと同様に、OCFS2で複数のノードが読み取り/書き込みモードで同じストレージデバイスに同時にアクセスできます。データが破損するおそれはありません。これには、クラスタノードからの同時アクセスを管理するDLM
(Distributed Lock
Manager)が使用されます。DLM自体は、システムに存在する実際のOCFS2ファイルシステムとは別個の仮想ファイルシステム(
`ocfs2_dlmfs` )を使用します。

OCFS2は組み込みクラスタ通信層を使用して、クラスタメンバシップおよびファイルシステムのマウントとマウント解除操作を管理したり、これらのタスクを<<ch-pacemaker,Pacemaker>>クラスタインフラストラクチャに委ねることができます。

OCFS2は、SUSE Linux Enterprise Server
(OCFS2が主にサポートされる共有クラスタファイルシステム)、CentOS、Debian GNU/LinuxおよびUbuntu Server
Editionで利用できます。また、OracleはRed Hat Enterprise Linux
(RHEL)用のパッケージも提供しています。この章の説明は、SUSE Linux Enterprise
ServerシステムでOCFS2を実行することを前提にしています。

[[s-ocfs2-create-resource]]
=== OCFS2用のDRBDリソースの作成

OCFS2は共有クラスタファイルシステムで、すべてのクラスタノードからストレージに対して同時に読み取り/書き込みアクセスが行われることを前提としています。したがって、OCFS2ファイルシステムを格納するために使用するDRBDリソースは、<<s-dual-primary-mode,デュアルプライマリモード>>で設定する必要があります。また、<<s-automatic-split-brain-recovery-configuration,スプリットブレインからの自動回復のための機能>>を利用することをおすすめします。そのためには、以下の設定をリソース設定ファイルindexterm:[drbd.conf]に加えてください。

[source, drbd]
----------------------------
resource <resource> {
  net {
    # allow-two-primaries yes;
    after-sb-0pri discard-zero-changes;
    after-sb-1pri discard-secondary;
    after-sb-2pri disconnect;
    ...
  }
  ...
}
----------------------------

[WARNING]
===============================
回復ポリシーを設定することは、事実上、自動データロス設定を行うことです。十分にご理解のうえご使用ください。
===============================


最初の構成の際に `allow-two-primaries` オプションを `yes`
にするのはお勧めできません。これは、最初のリソース同期が完了してから有効にしてください。

これらのオプションを<<ch-configure,新規に設定したリソース>>に追加したら、<<s-first-time-up,通常通りにリソースを初期化>>できます。indexterm:[drbd.conf]リソースの
`allow-two-primaries` オプションを `yes`
にすると、両方のノードのリソースをプライマリロールに<<s-switch-resource-roles,昇格>>することができます。

NOTE: DRBD9.1では3ノード以上で `プライマリ` にすることが可能になる予定です。DRBD9.0ではプライマリは2つまでですが、複数のノードを
`セカンダリ` にして冗長性を高めることができます。


[[s-ocfs2-create]]
=== OCFS2ファイルシステムの作成

OCFS対応の `mkfs` コマンドを使って、OCFS2ファイルシステムを作成します。
----------------------------
# mkfs -t ocfs2 -N 2 -L ocfs2_drbd0 /dev/drbd0
mkfs.ocfs2 1.4.0
Filesystem label=ocfs2_drbd0
Block size=1024 (bits=10)
Cluster size=4096 (bits=12)
Volume size=205586432 (50192 clusters) (200768 blocks)
7 cluster groups (tail covers 4112 clusters, rest cover 7680 clusters)
Journal size=4194304
Initial number of node slots: 2
Creating bitmaps: done
Initializing superblock: done
Writing system files: done
Writing superblock: done
Writing backup superblock: 0 block(s)
Formatting Journals: done
Writing lost+found: done
mkfs.ocfs2 successful
----------------------------

2ノードスロットOCFS2ファイルシステムが `/dev/drbd0` に作成され、ファイルシステムのラベルが `ocfs2_drbd0`
に設定されます。`mkfs` の呼び出し時に、その他のオプションを指定することもできます。詳細は `mkfs.ocfs2`
システムマニュアルページを参照ください。

[[s-ocfs2-pacemaker]]
=== PacemakerによるOCFS2の管理

[[s-ocfs2-pacemaker-drbd]]
==== PacemakerにデュアルプライマリDRBDリソースを追加する

既存の<<s-ocfs2-create-resource,デュアルプライマリDRBDリソース>>は、次の `crm`
設定でPacemakerリソース管理に追加することができます。

[source, drbd]
----------------------------
primitive p_drbd_ocfs2 ocf:linbit:drbd \
  params drbd_resource="ocfs2"
ms ms_drbd_ocfs2 p_drbd_ocfs2 \
  meta master-max=2 clone-max=2 notify=true
----------------------------

IMPORTANT: メタ変数 `master-max=2`
に注意してください。これはPacemakerのマスター/スレーブのデュアルマスターモードを有効にします。その場合、
`allow-two-primaries` も `yes`
にDRBD設定で設定されている必要があります。設定していない場合にはリソースの検証中に設定エラーが発生します。

[[s-ocfs2-pacemaker-mgmtdaemons]]
==== OCFS2をPacemakerで管理するには

OCFS2とロックマネージャ(DLM)の分散カーネルを管理するために、Pacemakerは、3つの異なるリソースエージェントを使用します。

* `ocf:pacemaker:controld` -- PacemakerのDLMに対してのインタフェース

* `ocf:ocfs2:o2cb` -- PacemakerのOCFS2クラスタ管理へのインタフェース

* `ocf:heartbeat:Filesystem` -- Pacemakerのクローンとして構成したときにクラスタファイルシステムをサポートする
  汎用ファイルシステム管理リソース

次の `crm` 設定のように _リソースグループのクローン_
を作成することによって、OCFS2の管理に必要なPacemakerリソースをすべてのノードで起動できます。

[source, drbd]
----------------------------
primitive p_controld ocf:pacemaker:controld
primitive p_o2cb ocf:ocfs2:o2cb
group g_ocfs2mgmt p_controld p_o2cb
clone cl_ocfs2mgmt g_ocfs2mgmt meta interleave=true
----------------------------

この構成がコミットされると、Pacemakerは、クラスタ内のすべてのノードで `controld` と `o2cb`
のリソースタイプのインスタンスを起動します。

[[s-ocfs2-pacemaker-fs]]
==== PacemakerにOCFS2ファイルシステムを追加する

PacemakerはOCF2ファイルシステムにアクセスするのに、従来の `ocf:heartbeat:Filesystem`
リソースエージェントを使います。これはクローンモードであっても同様です。Pacemakerの管理下にOCFS2ファイルシステムを配置するには、次の
`crm` 設定を使用します。

[source, drbd]
----------------------------
primitive p_fs_ocfs2 ocf:heartbeat:Filesystem \
  params device="/dev/drbd/by-res/ocfs2/0" directory="/srv/ocfs2" \
         fstype="ocfs2" options="rw,noatime"
clone cl_fs_ocfs2 p_fs_ocfs2
----------------------------

NOTE: この例ではボリュームリソースが1つの場合を前提にしています。

[[s-ocfs2-pacemaker-constraints]]
==== OCFS2ファイルシステムを管理するPacemakerの制約の追加

すべてのOCFS2関連のリソースとクローンを結びつけるには、Pacemaker構成に以下の制約を加えてください。

[source, drbd]
----------------------------
order o_ocfs2 ms_drbd_ocfs2:promote cl_ocfs2mgmt:start cl_fs_ocfs2:start
colocation c_ocfs2 cl_fs_ocfs2 cl_ocfs2mgmt ms_drbd_ocfs2:Master
----------------------------

[[s-ocfs2-legacy]]
=== Pacemakerを使わないOCFS2管理

IMPORTANT: OCFS2
DLMをサポートしない旧バージョンのPacemakerしか使えない場合、この節が参考になります。この節は以前の方式を使っている方の参照のためにだけ残してあります。新規インストールの場合には<<s-ocfs2-pacemaker,Pacemaker>>方式を使ってください。

[[s-ocfs2-enable]]
==== OCFS2をサポートするようにクラスタを設定する

[[s-ocfs2-create-cluster-conf]]
===== 設定ファイルの作成

OCFS2は主要な設定ファイルとして `/etc/ocfs2/cluster.conf` を使用します。

OCFS2クラスタを作成する際には、必ず、両方のホストを設定ファイルに追加してください。クラスタの相互接続通信には、通常はデフォルトポート(7777)が適切です。他のポート番号を選択する場合は、DRBD
(および他の設定済みTCP/IP)が使用する既存のポートと衝突しないポートを選択する必要があります。

`cluster.conf` ファイルを直接編集したくない場合は、 `ocfs2console`
というグラフィカルな構成ユーティリティを使用することもできます。通常はこちらのほうが便利です。いずれの場合も
`/etc/ocfs2/cluster.conf` ファイルの内容はおおよそ次のようになります。

[source, drbd]
----------------------------
node:
    ip_port = 7777
    ip_address = 10.1.1.31
    number = 0
    name = alice
    cluster = ocfs2

node:
    ip_port = 7777
    ip_address = 10.1.1.32
    number = 1
    name = bob
    cluster = ocfs2

cluster:
    node_count = 2
    name = ocfs2
----------------------------


クラスタ構成を設定したら、`scp` を使用して構成をクラスタの両方のノードに配布します。

[[s-configure-o2cb-driver]]
===== O2CBドライバの設定 

[[s-suse_linux_enterprise_systems]]
====== SUSE Linux Enterprisesシステム

SLESでは、 `o2cb` の起動スクリプトの `configure` オプションを利用することができます。

----------------------------
# /etc/init.d/o2cb configure
Configuring the O2CB driver.

This will configure the on-boot properties of the O2CB driver.
The following questions will determine whether the driver is loaded on
boot.  The current values will be shown in brackets ('[]').  Hitting
<ENTER> without typing an answer will keep that current value.  Ctrl-C
will abort.

Load O2CB driver on boot (y/n) [y]:
Cluster to start on boot (Enter "none" to clear) [ocfs2]:
Specify heartbeat dead threshold (>=7) [31]:
Specify network idle timeout in ms (>=5000) [30000]:
Specify network keepalive delay in ms (>=1000) [2000]:
Specify network reconnect delay in ms (>=2000) [2000]:
Use user-space driven heartbeat? (y/n) [n]:
Writing O2CB configuration: OK
Loading module "configfs": OK
Mounting configfs filesystem at /sys/kernel/config: OK
Loading module "ocfs2_nodemanager": OK
Loading module "ocfs2_dlm": OK
Loading module "ocfs2_dlmfs": OK
Mounting ocfs2_dlmfs filesystem at /dlm: OK
Starting O2CB cluster ocfs2: OK
----------------------------

[[s-_debian_gnu_linux_systems]]
======Debian GNU/Linuxシステム Debianの場合は、 `/etc/init.d/o2cb` の `configure`
オプションは使用できません。代わりに、 `ocfs2-tools` パッケージを再設定してドライバを有効にします。

----------------------------
# dpkg-reconfigure -p medium -f readline ocfs2-tools
Configuring ocfs2-tools
Would you like to start an OCFS2 cluster (O2CB) at boot time? yes
Name of the cluster to start at boot time: ocfs2
The O2CB heartbeat threshold sets up the maximum time in seconds that a node
awaits for an I/O operation. After it, the node "fences" itself, and you will
probably see a crash.

It is calculated as the result of: (threshold - 1) x 2.

Its default value is 31 (60 seconds).

Raise it if you have slow disks and/or crashes with kernel messages like:

o2hb_write_timeout: 164 ERROR: heartbeat write timeout to device XXXX after NNNN
milliseconds
O2CB Heartbeat threshold: `31`
		Loading filesystem "configfs": OK
Mounting configfs filesystem at /sys/kernel/config: OK
Loading stack plugin "o2cb": OK
Loading filesystem "ocfs2_dlmfs": OK
Mounting ocfs2_dlmfs filesystem at /dlm: OK
Setting cluster stack "o2cb": OK
Starting O2CB cluster ocfs2: OK
----------------------------

[[s-ocfs2-use]]
==== OCFS2ファイルシステムの使用

クラスタ構成を完了して、ファイルシステムを作成すると、他のファイルシステムと同様にマウントすることができます。
----------------------------
# mount -t ocfs2 /dev/drbd0 /shared
----------------------------

dmesg コマンドで表示されるカーネルログに次のような行が見つかるはずです。

[source, drbd]
----------------------------
ocfs2: Mounting device (147,0) on (node 0, slot 0) with ordered data mode.
----------------------------

その時点から、両方のノードでOCFS2ファイルシステムに読み取り/書き込みモードでアクセスできるようになります。
