[[ch-configure]]
=== DRBDの設定

[[s-prepare-storage]]
==== 下位レベルストレージの準備

DRBDをインストールしたら、両方のクラスタノードにほぼ同じ容量の記憶領域を用意する必要があります。これがDRBDリソースの _下位レベルデバイス_
になります。システムの任意のブロックデバイスを下位レベルデバイスとして使用できます。たとえば、次のようなものがあります。

* ハードドライブのパーティション(または物理ハードドライブ全体)

* ソフトウェアRAIDデバイス

* LVM論理ボリュームまたはLinuxデバイスマッパインフラストラクチャによって構成されるその他のブロックデバイス

* システム内のその他のブロックデバイス

リソースを _スタッキング(積み重ね)_
することもできます。つまり、DRBDデバイスを他のDRBDデバイスの下位レベルのデバイスとして利用することができます。リソースの積み重ねにはいくつかの注意点があります。詳しくは<<s-three-nodes>>を参照ください。

NOTE: ループデバイスをDRBDの下位レベルデバイスとして使用することもできますが、デッドロックの問題があるためお勧めできません。

DRBDリソースを作成する前に、そのストレージ領域を空にしておく _必要はありません_
。DRBDを使用して、非冗長のシングルサーバシステムから、2ノードのクラスタシステムを作成することは一般的なユースケースですが、いくつか重要な注意点があります。(その場合には<<s-metadata>>を参照ください)

本ガイドの説明は、次のようなとてもシンプルな構成を前提としています。

* 両ホストには使用可能な(現在未使用の) `/dev/sda7` というパーティションがある。

* <<s-internal-meta-data,内部メタデータ>>を使用する。

[[s-prepare-network]]
==== ネットワーク構成の準備

必須要件ではありませんが、DRBDによるレプリケーションの実行には、専用接続を使用することをお勧めします。この書き込みには、ギガビットイーサネット同士をケーブルで直結した接続が最適です。DRBDをスイッチを介して使用する場合には、冗長コンポーネントと
_bonding_ ドライバ( _active-backup_ モードで)の使用を推奨します。

一般に、ルータを介してDRBDレプリケーションを行うことはお勧めできません。スループットと待ち時間の両方に悪影響を及ぼし、パフォーマンスが大幅に低下します。

ローカルファイアウォールの要件として重要な点は、通常、DRBDは7788以上のTCPポートを使用し、それぞれのTCPリソースが個別のTCPポート上で待機するということです。DRBDは
_2つ_ のTCP接続を使用します。これらの接続が許可されるようにファイアウォールを設定する必要があります。

SELinuxやAppArmorなどのMAC (Mandatory Access
Control)スキーマが有効な場合は、ファイアウォール以外のセキュリティ要件も考慮する場合があります。DRBDが正しく機能するように、
必要に応じてローカルセキュリティポリシーを調整してください。

また、DRBDに使用するTCPポートを別のアプリケーションが使用していないことも確認してください。

現時点では1つのDRBDリソースに複数のTCPコネクション・ペアを設定することはできません。DRBD接続に負荷分散や冗長性が必要な場合は、イーサネットレベルで簡単に実現できます(この場合も
_bonding_ ドライバを使用してください)。

本ガイドの説明は、次のようなとてもシンプルな構成を前提としています。

* 2つのDRBDホストそれぞれに、現在使用されていないネットワークインタフェース `eth1` が存在する(IPアドレスはそれぞれ `10.1.1.31`
  と `10.1.1.32` )。

* どちらのホストでも他のサービスがTCPポート7788〜7799を使用していない。

* ローカルファイアウォール設定は、これらのポートを介したホスト間のインバウンドとアウトバウンドの両方のTCP接続を許可する。


[[s-configure-resource]]
==== リソースの設定

DRBDのすべての機能は、設定ファイル `/etc/drbd.conf` で制御されます。通常、この設定ファイルは、次のような内容となっています。

-------------------------------------
include "/etc/drbd.d/global_common.conf";
include "/etc/drbd.d/*.res";
-------------------------------------

通例では、`/etc/drbd.d/global_common.conf` にはDRBD設定の <<s-drbdconf-global,
`global`>> と <<s-drbdconf-common, `common`>> セクションが含まれます。また、 `.res` ファイルには各
<<s-drbdconf-resource, `リソース`>> セクションが含まれます。

`drbd.conf` に `include`
ステートメントを使用せずにすべての設定を記載することも可能です。しかし、設定の見やすさの観点から、複数のファイルに分割することをお勧めします。

いずれにしても `drbd.conf` や、その他の設定ファイルは、すべてのクラスタノードで `正確に同じ` である必要があります。

DRBDのソースtarファイルの `scripts`
サブディレクトリに、サンプル設定ファイルがあります。バイナリインストールパッケージの場合、サンプル設定ファイルは直接 `/etc`
にインストールされるか、 `/usr/share/doc/packages/drbd` などのパッケージ固有の文書ディレクトリにインストールされます。

このセクションは、DRBDを稼働させるために理解しておく必要のある設定ファイルの項目についての説明です。設定ファイルの構文と内容の詳細については
`drbd.conf` マニュアルページを参照ください。


[[s-drbdconf-example]]
===== 設定例

本ガイドでの説明は、前章であげた例をもとにする最小限の構成を前提にしています。

.シンプルなDRBD構成例 (`/etc/drbd.d/global_common.conf`)
-------------------------------------
global {
  usage-count yes;
}
common {
  net {
    protocol C;
  }
}
-------------------------------------

.シンプルなDRBDリソースの構成例 (`/etc/drbd.d/r0.res`)
-------------------------------------
resource r0 {
  on alice {
    device    /dev/drbd1;
    disk      /dev/sda7;
    address   10.1.1.31:7789;
    meta-disk internal;
  }
  on bob {
    device    /dev/drbd1;
    disk      /dev/sda7;
    address   10.1.1.32:7789;
    meta-disk internal;
  }
}
-------------------------------------

この例では、DRBDが次のように設定されます。

* DRBDの使用状況の統計をオプトインとして含める(<<fp-usage-count>>参照)。

* 特に他の指定がない限り完全に同期したレプリケーションを使用するようにリソースを設定する(<<s-replication-protocols,プロトコルC>>)。

* クラスタには2つのノード `alice` と `bob` がある。

* `r0` という名前のリソース(名前は自由に設定可能)があり `/dev/sda7`
  を下位レベルデバイスとして使用し、また、<<s-internal-meta-data,内部メタデータ>>を構成する。

* リソースはネットワーク接続にTCPポート7789を使用し、それぞれIPアドレス10.1.1.31と10.1.1.32にバインドされる(これが暗黙的に使用するネットワークコネクションを定義する)。

暗黙的に、上記の設定はリソースの1つのボリュームを作成し、番号 `ゼロ(0)`
が付与されます。1つのリソースに複数のボリュームを設定する場合には、次のようにします(両ノードで下位デバイスとして同レベルでストレージブロックデバイスを使用する場合)。

.複数ボリュームのDRBDリソース構成例(`/etc/drbd.d/r0.res`)
-------------------------------------
resource r0 {
  volume 0 {
    device    /dev/drbd1;
    disk      /dev/sda7;
    meta-disk internal;
  }
  volume 1 {
    device    /dev/drbd2;
    disk      /dev/sda8;
    meta-disk internal;
  }
  on alice {
    address   10.1.1.31:7789;
  }
  on bob {
    address   10.1.1.32:7789;
  }
}
-------------------------------------

NOTE: ボリュームは既存のデバイスの動作中にも追加できます。<<s-lvm-add-pv>>をご参照ください。

[[s-drbdconf-global]]
===== `global` セクション

このセクションは設定の中で1回しか使用できません。通常この設定は `/etc/drbd.d/global_common.conf`
ファイルに記述します。設定ファイルが1つの場合は、設定ファイルの一番上に記述します。このセクションで使用できるオプションはわずかですが、ほとんどのユーザーの場合、必要なのは次の1つだけです。

[[fp-usage-count]]
.`usage-count`
DRBDプロジェクトはさまざまなバージョンのDRBDの使用状況について統計を取ります。これは、システムに新規のDRBDバージョンがインストールされるたびに、HTTPサーバに接続することにより実行されます。これを無効にするには、
`usage-count no;` を指定します。デフォルトは `usage-count ask;` で、
DRBDをアップグレードするたびにプロンプトが表示されます。

DRBDの使用状況の統計は公開されています。http://usage.drbd.orgを参照ください。


[[s-drbdconf-common]]
===== `common` セクション

このセクションで、各リソースに継承される設定を簡単に定義できます。通常この設定は `/etc/drbd.d/global_common.conf`
に指定します。ここで定義するオプションは、リソースごとに定義することもできます。

`common`
セクションは必須ではありませんが、複数のリソースを使用する場合は、記述することを強くお勧めします。これにより、オプションを繰り返し使用することによって設定が複雑になることを回避できます。

上の例では `net { protocol C; }` が `common` セクションで指定されているため、設定されているすべてのリソース( `r0`
含む)がこのオプションを継承します。ただし、明示的に別の `protocol`
オプションが指定されている場合は除きます。使用可能なその他の同期プロトコルについては、<<s-replication-protocols>>を参照してください。

[[s-drbdconf-resource]]
===== `resource` セクション

各リソースの設定ファイルは、通常 `/etc/drbd.d/resource.res`
という名前にします。定義するDRBDリソースは、設定ファイルでresource
nameを指定して名前を付ける必要があります。通常は文字または数字、アンダースコアのみを使用します。

各リソースには各クラスタノードに最低2つの `on <host>` サブセクションも必要です。その他すべての設定は `common`
セクション(記述した場合)から継承されるか、DRBDのデフォルト設定から取得されます。

さらに、オプションの値が両方のホストで等しい場合は、直接 `resource`
セクションで指定することができます。このため、設定例は次のように短くすることができます。

-------------------------------------
resource r0 {
  device    /dev/drbd1;
  disk      /dev/sda7;
  meta-disk internal;
  on alice {
    address   10.1.1.31:7789;
  }
  on bob {
    address   10.1.1.32:7789;
  }
}
-------------------------------------


[[s-drbdconf-conns]]
==== ネットワークコネクションの定義

現時点では、DRBD9の通信リンクはフルメッシュである必要があります。つまり、全リソース全ノードが他の全ノードに直接のコネクションを持っている必要があります(当然、自ノードに対しては不要です)。

ホスト2台のシンプルな構成の場合、使い勝手と後方互換性のため、`drbdadm` は(1つの)ネットワークコネクションを自身で挿入します。

必要なネットワークコネクション数はホスト数の二次関数です。"従来の"2ノードでは1コネクションが必要でしたが、3つのホストでは3対、4つのホストでは6対、5つのホストでは10対のコネクションが…というように必要になってきます。32ノードであれば496対のコネクションが必要になります。

[[eq-connection-mesh]]
._N_ 個のホストの時のコネクション数
image::images/connection-mesh.svg[]


以下は3つのホストでの設定ファイルの例です。
-------------------------------------
resource r0 {
  device    /dev/drbd1;
  disk      /dev/sda7;
  meta-disk internal;
  on alice {
    address   10.1.1.31:7000;
    node-id   0;
  }
  on bob {
    address   10.1.1.32:7001;
    node-id   1;
  }
  on charlie {
    address   10.1.1.33:7002;
    node-id   2;
  }
  connection {
    host alice   port 7010;
    host bob     port 7001;
  }
  connection {
    host alice   port 7020;
    host charlie port 7002;
  }
  connection {
    host bob     port 7012;
    host charlie port 7021;
  }

}
-------------------------------------

`on host` セクションの `address`
値でのポート番号は任意指定です。ただし各コネクションごとに異なるポート番号を指定する必要があります。

[NOTE]
==================
プレリリース版では、コネクションメッシュ全体を定義する必要があります。

今後のリリースで、DRBDはハンドシェイク中にどの対向ノードと通信しているかを判定できるようになり、各ノード1ポートで済む予定です。
==================

`connection-mesh` オプションを使うと、上記と同じ3ノード構成を以下のように設定できます。
-------------------------------------
resource r0 {
  device    /dev/drbd1;
  disk      /dev/sda7;
  meta-disk internal;
  on alice {
    address   10.1.1.31:7000;
    node-id   0;
  }
  on bob {
    address   10.1.1.32:7001;
    node-id   1;
  }
  on charlie {
    address   10.1.1.33:7002;
    node-id   2;
  }
  connection-mesh {
    hosts alice bob charlie;
    net {
        use-rle no;
    }
  }

}

-------------------------------------


サーバに十分なネットワークカードがあれば、サーバ間をクロスケーブルで直結できます。
1つ4ポートのイーサネットカードであれば、4ノードのフルメッシュにするために1つの管理インターフェースと3つの他サーバへの接続を行うことができます。

この場合には直接接続に異なるIPアドレスを指定することができます。

--------------------------------
resource r0 {
  ...
  connection {
    host alice   address 10.1.2.1 port 7010;
    host bob     address 10.1.2.2 port 7001;
  }
  connection {
    host alice   address 10.1.3.1 port 7020;
    host charlie address 10.1.3.2 port 7002;
  }
  connection {
    host bob     address 10.1.4.1 port 7021;
    host charlie address 10.1.4.2 port 7012;
  }
}
--------------------------------

管理とデバッグを容易にするため、エンドポイントごとに異なるポートを使用することをお勧めします。 `tcpdump`
使用の際にパケットの追跡が容易になります。

以下の例は2サーバのみで使用するものです。4ノードでの例は<<s-4node-example>>を参照ください。


[[s-configuring-transports]]
==== トランスポートプロトコルの設定
DRBDは複数のネットワーク転送プロトコルに対応しています。 トランスポートプロトコルの設定はリソースの各コネクションごとに設定できます。

[[s-tcp_ip]]
===== TCP/IP
---------------------
resource <resource> {
  net {
    transport "tcp";
  }
  ...
}
---------------------
デフォルトは `tcp` です。トランスポートオプションを設定していない場合は `TCP` トランスポートが使用されます。

`tcp` トランスポートオプションでは次のnetオプションが設定できます。 `sndbuf-size` 、 `rcvbuf-size` 、
`connect-int` 、 ` sock-check-timeo` 、 `ping-timeo` 、 `timeout` 。

[[s-rdma]]
===== RDMA
---------------------
resource <resource> {
  net {
    transport "rdma";
  }
  ...
}
---------------------
`rdma` トランスポートでは次のnetオプションが設定できます。 `sndbuf-size` 、 `rcvbuf-size` 、
`max_buffers` 、 `connect-int` 、 `sock-check-timeo` 、 `ping-timeo` 、
`timeout` 。

`rdma` トランスポートはゼロコピーレシーブ転送です。その関係で、 `max_buffers` の設定オプションはすべての
`rcvbuf-size` を保持するのに十分なサイズにする必要があります。

NOTE: `rcvbuf-size` はバイト単位で設定しますが、 `max_buffers` はページ単位で設定します。パフォーマンス最適化のためには、
`max_buffers` はすべての `rcvbuf-size` と、下位デバイスとの間の全通信量を合わせたものよりも大きい必要があります。

TIP: InfiniBand HCAで `rdma`
トランスポートを使っている場合、IPoIBも設定する必要があります。IPアドレスはデータ転送では使用しませんが、コネクションを確立する際に正しいアダプタとポートを見つけるために使用します。

CAUTION: 設定オプションの `sndbuf-size` と `rcvbuf-size`
はコネクションが確立される時に考慮されます。つまり、接続が確立している時は変更する事ができますが、その変更が反映されるのは、再接続後になります。

[[s-performance_considerations_for_rdma]]
===== RDMAのパフォーマンスにおける考慮事項

擬似ファイル/sys/kernel/debug/drbd/<リソース>/connections/<対向ノード>/transportを見れば、使用可能な受信識別子(rx_desc)と送信識別子(tx_desc)の数を監視できます。識別子が枯渇した場合には
`sndbuf-size` または `rcvbuf-size` を増やす必要があります。

[[s-first-time-up]]
==== リソースを初めて有効にする

すでに述べた手順に従って最初のリソース設定を完了したら、リソースを稼働させます。

両方のノードに対して、次の手順を行います。

さきほどの構成例( `resource r0{ … }` )では、 `<resource>` は `r0` となります。

.メタデータを作成する
この手順は、最初にデバイスを作成するときにのみ必要です。これにより、DRBDのメタデータを初期化します。

-------------------------------------
# drbdadm create-md <resource>
v09 Magic number not found
Writing meta data...
initialising activity log
NOT initializing bitmap
New drbd meta data block sucessfully created.
-------------------------------------

メタデータに割り当てられるビットマップスロットの数はリソースのホストの数に依存します。 デフォルトではリソース設定のホストの数をカウントします。
メタデータの作成前にすべてのホストが指定されていれば、そのまま動作します。後から追加ノード用のビットマップを付け足すことも可能ですが、手動での作業が必要になります。


.リソースを有効にする
これにより、リソースとその下位デバイス(マルチボリュームリソースの場合は、すべてのデバイス)とを結びつけます。また、対向ノードのリソースと接続します。
-------------------------------------
# drbdadm up <resource>
-------------------------------------

.`drbdadm status` でステータスを確認する
`drbdsetup` のステータス出力は次のような情報を表示します。

-------------------------------------
# drbdadm status r0
r0 role:Secondary
  disk:Inconsistent
  bob role:Secondary
    disk:Inconsistent
-------------------------------------

NOTE: この時点では `Inconsistent/Inconsistent` のディスク状態になっているはずです。

これで、DRBDがディスクリソースとネットワークリソースに正しく割り当てられ、稼働できるようになりました。次に、どちらのノードをデバイスの初期同期のソースとして使用するか指定する必要があります。

[[s-initial-full-sync]]
==== デバイスの初期同期

DRBDを完全に機能させるには、さらに次の2つの手順が必要です。

.同期元を選択する
新しく初期化した空のディスクを使用する場合は、任意のディスクを同期元にできます。いずれかのノードにすでに重要なデータが格納されている場合は、
_十分注意して、必ず_
そのノードを同期元として選択してください。デバイスの初期同期の方向が誤っていると、データを失うおそれがあります。慎重に行ってください。


.初期フル同期を開始する
この手順は、最初のリソース設定の際に、同期ソースとして選択した1つのノードに対してのみ実行します。次のコマンドで実行します。

-------------------------------------
# drbdadm primary --force <resource>
-------------------------------------

このコマンドを指定すると、初期フル同期が開始します。 `drbdadm status`
で同期の進行状況を監視できます。デバイスのサイズによっては、同期に時間がかかる場合があります。

この時点で、初期同期が完了していなくてもDRBDデバイスは完全に稼働します(ただし、パフォーマンスは多少低いです)。空のディスクから開始した場合は、デバイスにファイルシステムを作成してもかまいません。これを下位ブロックデバイスとして使用し、マウントして、アクセス可能なブロックデバイスとしてさまざまな操作を実行することができます。

リソースに対して一般的な管理タスクを行う場合は、<<p-work>>に進んでください。

[[s-using-truck-based-replication]]
==== トラックベースのレプリケーションの使用

リモートノードに同期するデータを前もってロードし、デバイスの初期同期をスキップする場合は、次の手順を行います。

初期設定済みで `プライマリ`
に昇格し、相手ノードとの接続を切断した状態のDRBDリソースが必要です。つまり、デバイスの設定が完了し、両方のノードに同一の `drbd.conf`
のコピーが存在し
<<s-initial-full-sync,最初のリソース昇格>>をローカルノードで実行するコマンドを発行した後、リモートノードがまだ接続されていない状態です。


* ローカルノードで次のコマンドを実行します。
+
--
-------------------------------------
# drbdadm new-current-uuid --clear-bitmap <resource>/<volume>
-------------------------------------
または
-------------------------------------
# drbdsetup new-current-uuid --clear-bitmap <minor>
-------------------------------------
--

* リソースのデータ _およびそのメタデータ_ の正確に同一のコピーを作成します。 たとえば、ホットスワップ可能な
  RAID-1ドライブの一方を抜き取ります。この場合は、もちろん 新しいドライブをセットしてRAIDセットを再構築しておくべきでしょう。
  抜き取ったドライブは、正確なコピーとして
  リモートサイトに移動できます。別の方法としては、ローカルのブロックデバイスがスナップショットコピーをサポートする場合
  (LVMの上位でDRBDを使用する場合など)は、 `dd` を使用してスナップショットのビット単位のコピーを作ってもかまいません。


* ローカルノードで次のコマンドを実行します。
+
--
-------------------------------------
# drbdadm new-current-uuid <resource>
-------------------------------------
または `drbdsetup` コマンドを使用します。

この2回目のコマンドには `--clear-bitmap` がありません。
--

* 対向ホストの設置場所にコピーを物理的に移動します。

* コピーをリモートノードに追加します。ここでも物理ディスクを接続するか、リモートノードの既存のストレージに移動したデータのビット単位のコピーを追加します。レプリケートしたデータだけでなく、関連するDRBDメタデータも必ず復元するかコピーしてください。そうでない場合、ディスクの移動を正しく行うことができません。

* 新しいノードでメタデータのノードIDを修正し、2つのノード間で対抗ノードの情報を交換する必要があります。リソース `r0` ボリューム `0`
  上でnode idを2から1に変更するには、次の行を参照ください。
+
--

これはボリュームが未使用中のときに実行する必要があります。

-----------
V=r0/0
NODE_FROM=2
NODE_TO=1

drbdadm -- --force dump-md $V > /tmp/md_orig.txt
sed -e "s/node-id $NODE_FROM/node-id $NODE_TO/" \
	-e "s/^peer.$NODE_FROM. /peer-NEW /" \
	-e "s/^peer.$NODE_TO. /peer[$NODE_FROM] /" \
	-e "s/^peer-NEW /peer[$NODE_TO] /" \
	< /tmp/md_orig.txt > /tmp/md.txt

drbdmeta --force $(drbdadm sh-minor $V) v09 $(drbdadm sh-ll-dev $V) internal restore-md /tmp/md.txt
-----------

.NOTE
バージョン 8.9.7 以前の `drbdmeta` 順不同の対抗ノードセクションを扱えません。エディタを用いてブロックを交換する必要があります。

--

* リモートノードで次のコマンドを実行します。
+
-------------------------------------
# drbdadm up <resource>
-------------------------------------

2つのホストを接続しても、デバイスのフル同期は開始されません。代わりに、
`drbdadm{nbsp}--clear-bitmap{nbsp}new-current-uuid`
の呼び出し以降に変更されたブロックのみを対象とする自動同期が開始されます。

以降、データの変更が _全くない_
場合でも、セカンダリで<<s-activity-log,アクティビティログ>>を含む領域がロールバックされるため、同期が短時間行われることがあります。これは<<p-checksum-sync,チェックサムベースの同期>>を使用することで緩和されます。

この手順は、リソースが通常のDRBDリソースの場合でもスタックリソースの場合でも使用できます。スタックリソースの場合は、 `-S` または
`--stacked` オプションを `drbdadm` に追加します。


[[s-4node-example]]
==== 4ノードでの構成例

以下は4ノードクラスタの例です。

なお、 `connection` セクション(および個別のポート)はDRBD9.0.0では必須ではありません。略式の書式があります。

-------------------------------------
resource r0 {
  device      /dev/drbd0;
  disk        /dev/vg/r0;
  meta-disk   internal;

  on store1 {
    address   10.1.10.1:7100;
    node-id   1;
  }
  on store2 {
    address   10.1.10.2:7100;
    node-id   2;
  }
  on store3 {
    address   10.1.10.3:7100;
    node-id   3;
  }
  on store4 {
    address   10.1.10.4:7100;
    node-id   4;
  }

  # All connections involving store1
  connection {
    host store1  port 7012;
    host store2  port 7021;
  }
  connection {
    host store1  port 7013;
    host store3  port 7031;
  }
  connection {
    host store1  port 7014;
    host store4  port 7041;
  }

  # All remaining connections involving store2
  connection {
    host store2  port 7023;
    host store3  port 7032;
  }
  connection {
    host store2  port 7024;
    host store4  port 7042;
  }

  # All remaining connections involving store3
  connection {
    host store3  port 7034;
    host store4  port 7043;
  }

  # store4 already done.
}
-------------------------------------


[[s-connection-mesh]]
上記と同様の設定は以下のように記述することができます。
----------------------
resource r0 {
  device      /dev/drbd0;
  disk        /dev/vg/r0;
  meta-disk   internal;

  on store1 {
    address   10.1.10.1:7100;
    node-id   1;
  }
  on store2 {
    address   10.1.10.2:7100;
    node-id   2;
  }
  on store3 {
    address   10.1.10.3:7100;
    node-id   3;
  }
  on store4 {
    address   10.1.10.4:7100;
    node-id   4;
  }

  connection-mesh {
	hosts     store1 store2 store3 store4;
  }
}
----------------------

`connection-mesh` 設定を確認したい場合には `drbdadm dump <resource> -v` を実行します。


[[s-connection-mesh-distinct-interfaces]]
別の例として、4ノードに直接接続でフルメッシュにできるだけのインターフェースがある場合には、footnote:[例:3つのノード間接続用と最低1つの外部接続/管理用インターフェース]インターフェースにIPアドレスを指定することができます。

---------------------------
resource r0 {
  ...

  # store1 has crossover links like 10.99.1x.y
  connection {
    host store1  address 10.99.12.1 port 7012;
    host store2  address 10.99.12.2 port 7021;
  }
  connection {
    host store1  address 10.99.13.1  port 7013;
    host store3  address 10.99.13.3  port 7031;
  }
  connection {
    host store1  address 10.99.14.1  port 7014;
    host store4  address 10.99.14.4  port 7041;
  }

  # store2 has crossover links like 10.99.2x.y
  connection {
    host store2  address 10.99.23.2  port 7023;
    host store3  address 10.99.23.3  port 7032;
  }
  connection {
    host store2  address 10.99.24.2  port 7024;
    host store4  address 10.99.24.4  port 7042;
  }

  # store3 has crossover links like 10.99.3x.y
  connection {
    host store3  address 10.99.34.3  port 7034;
    host store4  address 10.99.34.4  port 7043;
  }
}
---------------------------

IPアドレスやポート番号の付け方には注意してください。別のリソースであれば同じIPアドレスを使用することができますが、 71xy、72xy
のようにずらしてください。
